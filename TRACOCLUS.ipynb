{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "import seaborn as sns\n",
    "from scipy.stats import entropy\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from timeit import default_timer as timer\n",
    "import sys, os, shutil, gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ''' Version of the packages in this work.'''\n",
    "# # print(\"Pandas version: \",pd.__version__)\n",
    "# print(\"Pandas version: 0.25.1\")\n",
    "# # print(\"Numpy version: \",np.__version__)\n",
    "# print(\"Numpy version: 1.16.4\")\n",
    "# # print(\"Sys python version: \",sys.version)\n",
    "# print(\"Sys python version: 3.7.1 | package by conda-forge [MSC v.1900 64 bit (AMD64)]\")\n",
    "# print(\"IPython: 7.8.0\")\n",
    "# print(\"IPython genutils: 0.2.0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#toy example dataset\n",
    "# input_test2.dat and input_test2.dat\n",
    "\n",
    "#synthetic datasets\n",
    "# synthetic-1_fimi.dat, synthetic-2_fimi.dat and synthetic-3_fimi.dat\n",
    "\n",
    "experiment = 'Toy' # Syn: run the synthetic data analysis; Real: run the real data analysis; \n",
    "                   # Toy: run the toy example.\n",
    "toy_number = \"2\" # sufix of a given toy dataset [1,1-1,2]\n",
    "\n",
    "find_overlap = False # True: find overlapped co-clusters; False: Find no overlapped co-clusters\n",
    "VERBOSE = True # True: print results as a verbose mode; False: print the main results\n",
    "num_of_sim = 1 # number of simulations to perform\n",
    "k = -1 #max number of co-cluster that could be found. -1: default [driven by cost function]\n",
    "e_obj = 0.4 # maximum error tolerance for object. -1: default [accept the maximum error]\n",
    "e_att = .8 # maximum error tolerance for attribute. -1: default [accept the maximum error]\n",
    "\n",
    "if VERBOSE: print('--->Verbose mode ON.<---')\n",
    "\n",
    "print(\"Executing TRACOCLUS method\")\n",
    "if experiment == 'Syn':\n",
    "    path = \"./data/synthetic/fimi/\"\n",
    "    syn_datasets = [path+\"synthetic-1_fimi.dat\",path+\"synthetic-2_fimi.dat\",path+\"synthetic-3_fimi.dat\"]\n",
    "    path_method = \"OutputAnalysis\\ococlus\"\n",
    "    check_path(path_method)\n",
    "\n",
    "    for ds in range(len(syn_datasets)):\n",
    "        ds_name = \"Syn-\"+str(ds+1)\n",
    "        print(\"\\nDataset: \"+ds_name)\n",
    "        res = os.mkdir(path_method+\"\\\\\"+ds_name)\n",
    "\n",
    "        for run in range(num_of_sim):\n",
    "            print(\"Run-\"+str(run+1))\n",
    "\n",
    "            df_fimi = pd.read_csv(syn_datasets[ds], header=None, names=[\"transation\"])\n",
    "            D,co_clusters = OCoClus(df_fimi,k,e_obj,e_att) # Calling OCoClus main method\n",
    "\n",
    "            print(\"\")\n",
    "            Rec_error(D,co_clusters)\n",
    "#             print(co_clusters)\n",
    "            \n",
    "            omega_format = build_clustering_output_omega(co_clusters)\n",
    "            OCoClus_clustering_xm = xmeasures_format(omega_format)# save to XMEASURES format C++ version\n",
    "            df_gt = pd.DataFrame(OCoClus_clustering_xm)\n",
    "            path = path_method+\"/\"+ds_name\n",
    "            df_gt.to_csv(path.replace(\"\\\\\",\"/\")+\"/run_\"+str(run+1)+\"_res_ococlus_\"+ds_name+\"_co.cnl\", \n",
    "                         header= False,index=False, encoding='utf8')\n",
    "            del omega_format, df_gt, OCoClus_clustering_xm\n",
    "            gc.collect()\n",
    "elif experiment == 'Real':\n",
    "    k = 10\n",
    "    print('Real data clustering.')\n",
    "    path = \"./data/real_application/\"\n",
    "    real_datasets = [path+\"cal500_fimi.dat\",path+\"covid19_fimi.dat\"]\n",
    "    path_method = \"OutputAnalysis\\ococlus\"\n",
    "    check_path(path_method)\n",
    "    \n",
    "    for ds in range(len(real_datasets)):\n",
    "        ds_name = real_datasets[ds].replace(\"/\",\"_\").split(\"_\")[4].capitalize()\n",
    "        print(\"\\nDataset: \"+ds_name)\n",
    "        res = os.mkdir(path_method+\"\\\\\"+ds_name)\n",
    "        \n",
    "        df_fimi = pd.read_csv(real_datasets[ds], header=None, names=[\"transation\"])\n",
    "        D,co_clusters = OCoClus(df_fimi,k,e_obj,e_att) # Calling OCoClus main method\n",
    "        writeFileOutput(co_clusters,ds_name,method='OCoClus',fileName='OCoClusResult_'+ds_name)\n",
    "        \n",
    "    print('DONE!')\n",
    "elif experiment == 'Toy':\n",
    "    print('Toy example')\n",
    "    VERBOSE = False\n",
    "#     input_data_pd = pd.read_csv(\"./data/toy_example/toy\"+toy_number+\"_traj.dat\", header=None, names=[\"transation\"])\n",
    "#     input_data_pd = pd.read_csv(\"./data/toy_example/toy\"+toy_number+\"_traj.dat\", header=None, names=[\"transation\"])\n",
    "    input_data_pd = pd.read_csv(\"./data/real_application/foursquare_NY/fs_ny_week_sequences.dat\", header=None, names=[\"transation\"])\n",
    "#     print(input_data_pd)\n",
    "    D,co_clusters = TRACOCLUS(input_data_pd,k,e_obj,e_att)\n",
    "    print(co_clusters)\n",
    "    #Compute the measures\n",
    "#     print(\"\")\n",
    "#     Rec_error(D,co_clusters)\n",
    "else:\n",
    "    print('ERROR! Choose a valid option for the experiment analysis.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation (Omega index, overlapped F1, ONMI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "#!/bin/bash\n",
    "### omega index and f-score\n",
    "### ./xmeasures -o -fp -ku -O gt.txt cls2.txt\n",
    "# pwd\n",
    "# ls\n",
    "\n",
    "if [ -d \"xmeasures/OutputAnalysis/ococlus\" ] \n",
    "then\n",
    "#     echo \"Directory exists.\"\n",
    "    rm -R xmeasures/OutputAnalysis/ococlus\n",
    "else\n",
    "    echo \"Error: Directory does not exists.\"\n",
    "fi\n",
    "\n",
    "cp -R OutputAnalysis xmeasures\n",
    "cd xmeasures/\n",
    "\n",
    "#Method: [Ococlus]\n",
    "#ground-truth: [gt_xm_s1_co.cnl,gt_xm_s2_co.cnl,gt_xm_s3_co.cnl]\n",
    "for i in 1 2 3 # index of synthetic datasets\n",
    "# for i in 1\n",
    "do\n",
    "#     for file in OutputAnalysis/ococlus/Syn-${i}/*\n",
    "    for file in OutputAnalysis/ococlus/Syn-${i}/*\n",
    "    do\n",
    "    #     echo \" $(grep -c '' ${file})\"\n",
    "        res=$(grep -c '' ${file})\n",
    "    #     echo \"${file} lines equal to: ${res}\"\n",
    "\n",
    "        if [ ${res} != 0 ]\n",
    "        then \n",
    "            echo \" \"\n",
    "            echo \"File ${file} is not empty. It has ${res} lines.\"\n",
    "    #         echo \"Empty file\"\n",
    "            ./xmeasures -o -fp -ku -O ./gts/gt_xm_s${i}_trad.cnl ${file} &\n",
    "            echo \" \"\n",
    "        else\n",
    "              echo \"File ${file}\"\n",
    "              echo \"Empty file. SKIPPED!\"\n",
    "        fi\n",
    "#     # wait until all child processes are done\n",
    "#     wait\n",
    "    done\n",
    "    echo \" \"\n",
    "    # wait until all child processes are done\n",
    "    wait\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ONMI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "#!/bin/bash\n",
    "#### ONMI\n",
    "#### ./onmi file1 file2\n",
    "\n",
    "cd xmeasures\n",
    "\n",
    "#Method: [Ococlus]\n",
    "#ground-truth: [gt_xm_s1_trad.cnl,gt_xm_s2_trad.cnl,gt_xm_s3_trad.cnl]\n",
    "for i in 1 2 3 # index of synthetic datasets\n",
    "# for i in 1\n",
    "do\n",
    "    for file in OutputAnalysis/ococlus/Syn-${i}/*\n",
    "    do\n",
    "    #     echo \" $(grep -c '' ${file})\"\n",
    "        res=$(grep -c '' ${file})\n",
    "    #     echo \"${file} lines equal to: ${res}\"\n",
    "\n",
    "        if [ ${res} != 0 ]\n",
    "        then \n",
    "            echo \" \"\n",
    "            echo \"File ${file} is not empty. It has ${res} lines.\"\n",
    "    #         echo \"Empty file\"\n",
    "            ./onmi ./gts/gt_xm_s${i}_trad.cnl ${file} &\n",
    "            echo \" \"\n",
    "        else\n",
    "              echo \"File ${file}\"\n",
    "              echo \"Empty file. SKIPPED!\"\n",
    "        fi\n",
    "#     # wait until all child processes are done\n",
    "#     wait\n",
    "    done\n",
    "    echo \" \"\n",
    "    # wait until all child processes are done\n",
    "    wait\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TraCoClus algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the main algorithm of TraCoClus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "er = '0-3-1-4-0-1'\n",
    "er2 = er.split('-')\n",
    "print(er2)\n",
    "# print(er2.nunique())\n",
    "def change_vect_cont(queue):\n",
    "    queue[0] = 'Q'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_vect = [1,2,8,4]\n",
    "change_vect_cont(my_vect)\n",
    "print(my_vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "# %matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_tested_atts = np.log2(10)\n",
    "vec_log_num = [1,10,20,30,40,50,60,70,80,90,100]#,250,500]#,750,1000]#,1500,2000,3000,5000,7500,10000]\n",
    "base = [2,10]\n",
    "df_log_base_diff = pd.DataFrame(columns = ['Input x','Log Result','Log Base'])\n",
    "popupalte_df_dict = {'Input x':0,'Log Result':0,'Log Base':''}\n",
    "\n",
    "for base_i in base:\n",
    "    popupalte_df_dict['Log Base'] = 'Log_'+str(base_i)\n",
    "    for num in vec_log_num:\n",
    "        popupalte_df_dict['Input x'] = num\n",
    "#         if base_i == 2:\n",
    "#         popupalte_df_dict['Log Result'] = np.log2(num)    \n",
    "        popupalte_df_dict['Log Result'] = np.log(num)/np.log(base_i)\n",
    "#         else:\n",
    "#             popupalte_df_dict['Log Result'] = np.log10(num)\n",
    "        df_log_base_diff = df_log_base_diff.append(popupalte_df_dict, ignore_index=True)\n",
    "df_log_base_diff.head()\n",
    "sns.lineplot(data=df_log_base_diff, x=\"Input x\", y=\"Log Result\", hue=\"Log Base\", style=\"Log Base\",\n",
    "             markers=True, dashes=False)\n",
    "# plt.show()\n",
    "# print(max_tested_atts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = {'a':1,'b':2,'c':3,'d':4}\n",
    "list_values = a.values()\n",
    "print(np.mean(list(list_values)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fs_ny_top_users_10.dat\n",
      "######################################\n",
      "Number of trajectories: 352\n",
      "Number of unique check-ins: 310\n",
      "########################################\n",
      "Number of the most frequent elements:  58\n",
      "Searching for candidate:  1\n",
      "\n",
      "Searching for candidate:  2\n",
      "\n",
      "Searching for candidate:  3\n",
      "\n",
      "Searching for candidate:  4\n",
      "\n",
      "Searching for candidate:  5\n",
      "\n",
      "Searching for candidate:  6\n",
      "\n",
      "Searching for candidate:  7\n",
      "\n",
      "Searching for candidate:  8\n",
      "\n",
      "Searching for candidate:  9\n",
      "\n",
      "Searching for candidate:  10\n",
      "\n",
      "Searching for candidate:  11\n",
      "\n",
      "Searching for candidate:  12\n",
      "\n",
      "Searching for candidate:  13\n",
      "\n",
      "Searching for candidate:  14\n",
      "\n",
      "Searching for candidate:  15\n",
      "\n",
      "Searching for candidate:  16\n",
      "\n",
      "Searching for candidate:  17\n",
      "\n",
      "Searching for candidate:  18\n",
      "\n",
      "Searching for candidate:  19\n",
      "\n",
      "Searching for candidate:  20\n",
      "\n",
      "Searching for candidate:  21\n",
      "\n",
      "Searching for candidate:  22\n",
      "\n",
      "Searching for candidate:  23\n",
      "\n",
      "Searching for candidate:  24\n",
      "\n",
      "Searching for candidate:  25\n",
      "\n",
      "Searching for candidate:  26\n",
      "\n",
      "Searching for candidate:  27\n",
      "\n",
      "Searching for candidate:  28\n",
      "\n",
      "Searching for candidate:  29\n",
      "\n",
      "Searching for candidate:  30\n",
      "\n",
      "Searching for candidate:  31\n",
      "\n",
      "Searching for candidate:  32\n",
      "\n",
      "Searching for candidate:  33\n",
      "\n",
      "Searching for candidate:  34\n",
      "\n",
      "Searching for candidate:  35\n",
      "\n",
      "Searching for candidate:  36\n",
      "\n",
      "Searching for candidate:  37\n",
      "\n",
      "Searching for candidate:  38\n",
      "\n",
      "Searching for candidate:  39\n",
      "\n",
      "Searching for candidate:  40\n",
      "\n",
      "Searching for candidate:  41\n",
      "\n",
      "Searching for candidate:  42\n",
      "\n",
      "Searching for candidate:  43\n",
      "\n",
      "Searching for candidate:  44\n",
      "\n",
      "Searching for candidate:  45\n",
      "\n",
      "Searching for candidate:  46\n",
      "\n",
      "Searching for candidate:  47\n",
      "\n",
      "Searching for candidate:  48\n",
      "\n",
      "Searching for candidate:  49\n",
      "\n",
      "Searching for candidate:  50\n",
      "\n",
      "Searching for candidate:  51\n",
      "\n",
      "Searching for candidate:  52\n",
      "\n",
      "Searching for candidate:  53\n",
      "\n",
      "Searching for candidate:  54\n",
      "\n",
      "Searching for candidate:  55\n",
      "\n",
      "Searching for candidate:  56\n",
      "\n",
      "Searching for candidate:  57\n",
      "\n",
      "Searching for candidate:  58\n",
      "\n",
      "Searching for candidate:  59\n",
      "\n",
      "Searching for candidate:  60\n",
      "\n",
      "Searching for candidate:  61\n",
      "\n",
      "Searching for candidate:  62\n",
      "\n",
      "Searching for candidate:  63\n",
      "\n",
      "Searching for candidate:  64\n",
      "\n",
      "Searching for candidate:  65\n",
      "\n",
      "Searching for candidate:  66\n",
      "\n",
      "Searching for candidate:  67\n",
      "\n",
      "Searching for candidate:  68\n",
      "\n",
      "Searching for candidate:  69\n",
      "\n",
      "Searching for candidate:  70\n",
      "\n",
      "Searching for candidate:  71\n",
      "\n",
      "Searching for candidate:  72\n",
      "\n",
      "Searching for candidate:  73\n",
      "\n",
      "Searching for candidate:  74\n",
      "\n",
      "Searching for candidate:  75\n",
      "\n",
      "Searching for candidate:  76\n",
      "\n",
      "Searching for candidate:  77\n",
      "\n",
      "Searching for candidate:  78\n",
      "\n",
      "Searching for candidate:  79\n",
      "\n",
      "Searching for candidate:  80\n",
      "\n",
      "Searching for candidate:  81\n",
      "\n",
      "Searching for candidate:  82\n",
      "\n",
      "Searching for candidate:  83\n",
      "\n",
      "Searching for candidate:  84\n",
      "\n",
      "Searching for candidate:  85\n",
      "\n",
      "Searching for candidate:  86\n",
      "\n",
      "Searching for candidate:  87\n",
      "\n",
      "Searching for candidate:  88\n",
      "\n",
      "Searching for candidate:  89\n",
      "\n",
      "Searching for candidate:  90\n",
      "\n",
      "Searching for candidate:  91\n",
      "\n",
      "Searching for candidate:  92\n",
      "\n",
      "Searching for candidate:  93\n",
      "\n",
      "Searching for candidate:  94\n",
      "\n",
      "Searching for candidate:  95\n",
      "\n",
      "Searching for candidate:  96\n",
      "\n",
      "Searching for candidate:  97\n",
      "\n",
      "Searching for candidate:  98\n",
      "\n",
      "Searching for candidate:  99\n",
      "\n",
      "Searching for candidate:  100\n",
      "\n",
      "Searching for candidate:  101\n",
      "\n",
      "Searching for candidate:  102\n",
      "\n",
      "Searching for candidate:  103\n",
      "\n",
      "Searching for candidate:  104\n",
      "\n",
      "Searching for candidate:  105\n",
      "\n",
      "Searching for candidate:  106\n",
      "\n",
      "Searching for candidate:  107\n",
      "\n",
      "Searching for candidate:  108\n",
      "\n",
      "Searching for candidate:  109\n",
      "\n",
      "Searching for candidate:  110\n",
      "\n",
      "Searching for candidate:  111\n",
      "\n",
      "Searching for candidate:  112\n",
      "\n",
      "Searching for candidate:  113\n",
      "\n",
      "Searching for candidate:  114\n",
      "\n",
      "Searching for candidate:  115\n",
      "\n",
      "Searching for candidate:  116\n",
      "\n",
      "Searching for candidate:  117\n",
      "\n",
      "Searching for candidate:  118\n",
      "\n",
      "Searching for candidate:  119\n",
      "\n",
      "Searching for candidate:  120\n",
      "\n",
      "Searching for candidate:  121\n",
      "\n",
      "Searching for candidate:  122\n",
      "\n",
      "Searching for candidate:  123\n",
      "\n",
      "Searching for candidate:  124\n",
      "\n",
      "Searching for candidate:  125\n",
      "\n",
      "Searching for candidate:  126\n",
      "\n",
      "Searching for candidate:  127\n",
      "\n",
      "Searching for candidate:  128\n",
      "\n",
      "Searching for candidate:  129\n",
      "\n",
      "Searching for candidate:  130\n",
      "\n",
      "Searching for candidate:  131\n",
      "\n",
      "Searching for candidate:  132\n",
      "\n",
      "Searching for candidate:  133\n",
      "\n",
      "Searching for candidate:  134\n",
      "\n",
      "Searching for candidate:  135\n",
      "\n",
      "Searching for candidate:  136\n",
      "\n",
      "Searching for candidate:  137\n",
      "\n",
      "Searching for candidate:  138\n",
      "\n",
      "Searching for candidate:  139\n",
      "\n",
      "Searching for candidate:  140\n",
      "\n",
      "Searching for candidate:  141\n",
      "\n",
      "Searching for candidate:  142\n",
      "\n",
      "Searching for candidate:  143\n",
      "\n",
      "Searching for candidate:  144\n",
      "\n",
      "Searching for candidate:  145\n",
      "\n",
      "Searching for candidate:  146\n",
      "\n",
      "Searching for candidate:  147\n",
      "\n",
      "Searching for candidate:  148\n",
      "\n",
      "Searching for candidate:  149\n",
      "\n",
      "Searching for candidate:  150\n",
      "\n",
      "Searching for candidate:  151\n",
      "\n",
      "Searching for candidate:  152\n",
      "\n",
      "Searching for candidate:  153\n",
      "\n",
      "Searching for candidate:  154\n",
      "\n",
      "Searching for candidate:  155\n",
      "\n",
      "Searching for candidate:  156\n",
      "\n",
      "Searching for candidate:  157\n",
      "\n",
      "Searching for candidate:  158\n",
      "\n",
      "Searching for candidate:  159\n",
      "\n",
      "Searching for candidate:  160\n",
      "\n",
      "Searching for candidate:  161\n",
      "\n",
      "Searching for candidate:  162\n",
      "\n",
      "Searching for candidate:  163\n",
      "\n",
      "Searching for candidate:  164\n",
      "\n",
      "Searching for candidate:  165\n",
      "\n",
      "Searching for candidate:  166\n",
      "\n",
      "Searching for candidate:  167\n",
      "\n",
      "Searching for candidate:  168\n",
      "\n",
      "Searching for candidate:  169\n",
      "\n",
      "Searching for candidate:  170\n",
      "\n",
      "Searching for candidate:  171\n",
      "\n",
      "Searching for candidate:  172\n",
      "\n",
      "Searching for candidate:  173\n",
      "\n",
      "Searching for candidate:  174\n",
      "\n",
      "Searching for candidate:  175\n",
      "\n",
      "Searching for candidate:  176\n",
      "\n",
      "Searching for candidate:  177\n",
      "\n",
      "Searching for candidate:  178\n",
      "\n",
      "Searching for candidate:  179\n",
      "\n",
      "Searching for candidate:  180\n",
      "\n",
      "Searching for candidate:  181\n",
      "\n",
      "Searching for candidate:  182\n",
      "\n",
      "Searching for candidate:  183\n",
      "\n",
      "Searching for candidate:  184\n",
      "\n",
      "Searching for candidate:  185\n",
      "\n",
      "Searching for candidate:  186\n",
      "\n",
      "Searching for candidate:  187\n",
      "\n",
      "Searching for candidate:  188\n",
      "\n",
      "Searching for candidate:  189\n",
      "\n",
      "Searching for candidate:  190\n",
      "\n",
      "Searching for candidate:  191\n",
      "\n",
      "Searching for candidate:  192\n",
      "\n",
      "Searching for candidate:  193\n",
      "\n",
      "Searching for candidate:  194\n",
      "\n",
      "\n",
      "Total clustering time:  483.29927090002457\n",
      "Process: sample; Metric: z_score; Co-cluster ref: rows; Z-score: -1\n",
      "Number of co-clusters:  193\n",
      "\n",
      "Overall entropy H: 2.1685486168417136\n",
      "Purity: 3.565340909090909\n",
      "AVG relative co-clusters: 2.20±1.89\n",
      "\n",
      "######################################\n",
      "Number of trajectories: 352\n",
      "Number of unique check-ins: 310\n",
      "########################################\n",
      "Number of the most frequent elements:  58\n",
      "Searching for candidate:  1\n",
      "\n",
      "Searching for candidate:  2\n",
      "\n",
      "Searching for candidate:  3\n",
      "\n",
      "Searching for candidate:  4\n",
      "\n",
      "Searching for candidate:  5\n",
      "\n",
      "Searching for candidate:  6\n",
      "\n",
      "Searching for candidate:  7\n",
      "\n",
      "Searching for candidate:  8\n",
      "\n",
      "Searching for candidate:  9\n",
      "\n",
      "Searching for candidate:  10\n",
      "\n",
      "Searching for candidate:  11\n",
      "\n",
      "Searching for candidate:  12\n",
      "\n",
      "Searching for candidate:  13\n",
      "\n",
      "Searching for candidate:  14\n",
      "\n",
      "Searching for candidate:  15\n",
      "\n",
      "Searching for candidate:  16\n",
      "\n",
      "Searching for candidate:  17\n",
      "\n",
      "Searching for candidate:  18\n",
      "\n",
      "Searching for candidate:  19\n",
      "\n",
      "Searching for candidate:  20\n",
      "\n",
      "Searching for candidate:  21\n",
      "\n",
      "Searching for candidate:  22\n",
      "\n",
      "Searching for candidate:  23\n",
      "\n",
      "Searching for candidate:  24\n",
      "\n",
      "Searching for candidate:  25\n",
      "\n",
      "Searching for candidate:  26\n",
      "\n",
      "Searching for candidate:  27\n",
      "\n",
      "Searching for candidate:  28\n",
      "\n",
      "Searching for candidate:  29\n",
      "\n",
      "Searching for candidate:  30\n",
      "\n",
      "Searching for candidate:  31\n",
      "\n",
      "Searching for candidate:  32\n",
      "\n",
      "Searching for candidate:  33\n",
      "\n",
      "Searching for candidate:  34\n",
      "\n",
      "Searching for candidate:  35\n",
      "\n",
      "Searching for candidate:  36\n",
      "\n",
      "Searching for candidate:  37\n",
      "\n",
      "Searching for candidate:  38\n",
      "\n",
      "Searching for candidate:  39\n",
      "\n",
      "Searching for candidate:  40\n",
      "\n",
      "Searching for candidate:  41\n",
      "\n",
      "Searching for candidate:  42\n",
      "\n",
      "Searching for candidate:  43\n",
      "\n",
      "Searching for candidate:  44\n",
      "\n",
      "Searching for candidate:  45\n",
      "\n",
      "Searching for candidate:  46\n",
      "\n",
      "Searching for candidate:  47\n",
      "\n",
      "Searching for candidate:  48\n",
      "\n",
      "Searching for candidate:  49\n",
      "\n",
      "Searching for candidate:  50\n",
      "\n",
      "Searching for candidate:  51\n",
      "\n",
      "Searching for candidate:  52\n",
      "\n",
      "Searching for candidate:  53\n",
      "\n",
      "Searching for candidate:  54\n",
      "\n",
      "Searching for candidate:  55\n",
      "\n",
      "Searching for candidate:  56\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching for candidate:  57\n",
      "\n",
      "Searching for candidate:  58\n",
      "\n",
      "Searching for candidate:  59\n",
      "\n",
      "Searching for candidate:  60\n",
      "\n",
      "Searching for candidate:  61\n",
      "\n",
      "Searching for candidate:  62\n",
      "\n",
      "Searching for candidate:  63\n",
      "\n",
      "Searching for candidate:  64\n",
      "\n",
      "Searching for candidate:  65\n",
      "\n",
      "Searching for candidate:  66\n",
      "\n",
      "Searching for candidate:  67\n",
      "\n",
      "Searching for candidate:  68\n",
      "\n",
      "Searching for candidate:  69\n",
      "\n",
      "Searching for candidate:  70\n",
      "\n",
      "Searching for candidate:  71\n",
      "\n",
      "Searching for candidate:  72\n",
      "\n",
      "Searching for candidate:  73\n",
      "\n",
      "Searching for candidate:  74\n",
      "\n",
      "Searching for candidate:  75\n",
      "\n",
      "Searching for candidate:  76\n",
      "\n",
      "Searching for candidate:  77\n",
      "\n",
      "Searching for candidate:  78\n",
      "\n",
      "Searching for candidate:  79\n",
      "\n",
      "Searching for candidate:  80\n",
      "\n",
      "Searching for candidate:  81\n",
      "\n",
      "Searching for candidate:  82\n",
      "\n",
      "Searching for candidate:  83\n",
      "\n",
      "Searching for candidate:  84\n",
      "\n",
      "Searching for candidate:  85\n",
      "\n",
      "Searching for candidate:  86\n",
      "\n",
      "Searching for candidate:  87\n",
      "\n",
      "Searching for candidate:  88\n",
      "\n",
      "Searching for candidate:  89\n",
      "\n",
      "Searching for candidate:  90\n",
      "\n",
      "Searching for candidate:  91\n",
      "\n",
      "Searching for candidate:  92\n",
      "\n",
      "Searching for candidate:  93\n",
      "\n",
      "Searching for candidate:  94\n",
      "\n",
      "Searching for candidate:  95\n",
      "\n",
      "Searching for candidate:  96\n",
      "\n",
      "Searching for candidate:  97\n",
      "\n",
      "Searching for candidate:  98\n",
      "\n",
      "Searching for candidate:  99\n",
      "\n",
      "Searching for candidate:  100\n",
      "\n",
      "Searching for candidate:  101\n",
      "\n",
      "Searching for candidate:  102\n",
      "\n",
      "Searching for candidate:  103\n",
      "\n",
      "Searching for candidate:  104\n",
      "\n",
      "Searching for candidate:  105\n",
      "\n",
      "Searching for candidate:  106\n",
      "\n",
      "Searching for candidate:  107\n",
      "\n",
      "Searching for candidate:  108\n",
      "\n",
      "Searching for candidate:  109\n",
      "\n",
      "Searching for candidate:  110\n",
      "\n",
      "Searching for candidate:  111\n",
      "\n",
      "Searching for candidate:  112\n",
      "\n",
      "Searching for candidate:  113\n",
      "\n",
      "Searching for candidate:  114\n",
      "\n",
      "Searching for candidate:  115\n",
      "\n",
      "Searching for candidate:  116\n",
      "\n",
      "Searching for candidate:  117\n",
      "\n",
      "Searching for candidate:  118\n",
      "\n",
      "Searching for candidate:  119\n",
      "\n",
      "Searching for candidate:  120\n",
      "\n",
      "Searching for candidate:  121\n",
      "\n",
      "Searching for candidate:  122\n",
      "\n",
      "Searching for candidate:  123\n",
      "\n",
      "Searching for candidate:  124\n",
      "\n",
      "Searching for candidate:  125\n",
      "\n",
      "Searching for candidate:  126\n",
      "\n",
      "Searching for candidate:  127\n",
      "\n",
      "Searching for candidate:  128\n",
      "\n",
      "Searching for candidate:  129\n",
      "\n",
      "Searching for candidate:  130\n",
      "\n",
      "Searching for candidate:  131\n",
      "\n",
      "Searching for candidate:  132\n",
      "\n",
      "Searching for candidate:  133\n",
      "\n",
      "Searching for candidate:  134\n",
      "\n",
      "Searching for candidate:  135\n",
      "\n",
      "Searching for candidate:  136\n",
      "\n",
      "Searching for candidate:  137\n",
      "\n",
      "Searching for candidate:  138\n",
      "\n",
      "Searching for candidate:  139\n",
      "\n",
      "Searching for candidate:  140\n",
      "\n",
      "Searching for candidate:  141\n",
      "\n",
      "Searching for candidate:  142\n",
      "\n",
      "Searching for candidate:  143\n",
      "\n",
      "Searching for candidate:  144\n",
      "\n",
      "Searching for candidate:  145\n",
      "\n",
      "Searching for candidate:  146\n",
      "\n",
      "Searching for candidate:  147\n",
      "\n",
      "Searching for candidate:  148\n",
      "\n",
      "Searching for candidate:  149\n",
      "\n",
      "Searching for candidate:  150\n",
      "\n",
      "Searching for candidate:  151\n",
      "\n",
      "Searching for candidate:  152\n",
      "\n",
      "Searching for candidate:  153\n",
      "\n",
      "Searching for candidate:  154\n",
      "\n",
      "Searching for candidate:  155\n",
      "\n",
      "Searching for candidate:  156\n",
      "\n",
      "Searching for candidate:  157\n",
      "\n",
      "Searching for candidate:  158\n",
      "\n",
      "Searching for candidate:  159\n",
      "\n",
      "Searching for candidate:  160\n",
      "\n",
      "Searching for candidate:  161\n",
      "\n",
      "Searching for candidate:  162\n",
      "\n",
      "Searching for candidate:  163\n",
      "\n",
      "Searching for candidate:  164\n",
      "\n",
      "Searching for candidate:  165\n",
      "\n",
      "Searching for candidate:  166\n",
      "\n",
      "Searching for candidate:  167\n",
      "\n",
      "Searching for candidate:  168\n",
      "\n",
      "Searching for candidate:  169\n",
      "\n",
      "Searching for candidate:  170\n",
      "\n",
      "Searching for candidate:  171\n",
      "\n",
      "Searching for candidate:  172\n",
      "\n",
      "Searching for candidate:  173\n",
      "\n",
      "Searching for candidate:  174\n",
      "\n",
      "Searching for candidate:  175\n",
      "\n",
      "Searching for candidate:  176\n",
      "\n",
      "Searching for candidate:  177\n",
      "\n",
      "Searching for candidate:  178\n",
      "\n",
      "Searching for candidate:  179\n",
      "\n",
      "Searching for candidate:  180\n",
      "\n",
      "Searching for candidate:  181\n",
      "\n",
      "Searching for candidate:  182\n",
      "\n",
      "Searching for candidate:  183\n",
      "\n",
      "Searching for candidate:  184\n",
      "\n",
      "Searching for candidate:  185\n",
      "\n",
      "Searching for candidate:  186\n",
      "\n",
      "Searching for candidate:  187\n",
      "\n",
      "Searching for candidate:  188\n",
      "\n",
      "Searching for candidate:  189\n",
      "\n",
      "Searching for candidate:  190\n",
      "\n",
      "Searching for candidate:  191\n",
      "\n",
      "Searching for candidate:  192\n",
      "\n",
      "Searching for candidate:  193\n",
      "\n",
      "Searching for candidate:  194\n",
      "\n",
      "\n",
      "Total clustering time:  439.92565900000045\n",
      "Process: sample; Metric: z_score; Co-cluster ref: rows; Z-score: 0\n",
      "Number of co-clusters:  71\n",
      "\n",
      "Overall entropy H: 1.580700840916014\n",
      "Purity: 2.346590909090909\n",
      "AVG relative co-clusters: 3.97±2.11\n",
      "\n",
      "######################################\n",
      "Number of trajectories: 352\n",
      "Number of unique check-ins: 310\n",
      "########################################\n",
      "Number of the most frequent elements:  58\n",
      "Searching for candidate:  1\n",
      "\n",
      "Searching for candidate:  2\n",
      "\n",
      "Searching for candidate:  3\n",
      "\n",
      "Searching for candidate:  4\n",
      "\n",
      "Searching for candidate:  5\n",
      "\n",
      "Searching for candidate:  6\n",
      "\n",
      "Searching for candidate:  7\n",
      "\n",
      "Searching for candidate:  8\n",
      "\n",
      "Searching for candidate:  9\n",
      "\n",
      "Searching for candidate:  10\n",
      "\n",
      "Searching for candidate:  11\n",
      "\n",
      "Searching for candidate:  12\n",
      "\n",
      "Searching for candidate:  13\n",
      "\n",
      "Searching for candidate:  14\n",
      "\n",
      "Searching for candidate:  15\n",
      "\n",
      "Searching for candidate:  16\n",
      "\n",
      "Searching for candidate:  17\n",
      "\n",
      "Searching for candidate:  18\n",
      "\n",
      "Searching for candidate:  19\n",
      "\n",
      "Searching for candidate:  20\n",
      "\n",
      "Searching for candidate:  21\n",
      "\n",
      "Searching for candidate:  22\n",
      "\n",
      "Searching for candidate:  23\n",
      "\n",
      "Searching for candidate:  24\n",
      "\n",
      "Searching for candidate:  25\n",
      "\n",
      "Searching for candidate:  26\n",
      "\n",
      "Searching for candidate:  27\n",
      "\n",
      "Searching for candidate:  28\n",
      "\n",
      "Searching for candidate:  29\n",
      "\n",
      "Searching for candidate:  30\n",
      "\n",
      "Searching for candidate:  31\n",
      "\n",
      "Searching for candidate:  32\n",
      "\n",
      "Searching for candidate:  33\n",
      "\n",
      "Searching for candidate:  34\n",
      "\n",
      "Searching for candidate:  35\n",
      "\n",
      "Searching for candidate:  36\n",
      "\n",
      "Searching for candidate:  37\n",
      "\n",
      "Searching for candidate:  38\n",
      "\n",
      "Searching for candidate:  39\n",
      "\n",
      "Searching for candidate:  40\n",
      "\n",
      "Searching for candidate:  41\n",
      "\n",
      "Searching for candidate:  42\n",
      "\n",
      "Searching for candidate:  43\n",
      "\n",
      "Searching for candidate:  44\n",
      "\n",
      "Searching for candidate:  45\n",
      "\n",
      "Searching for candidate:  46\n",
      "\n",
      "Searching for candidate:  47\n",
      "\n",
      "Searching for candidate:  48\n",
      "\n",
      "Searching for candidate:  49\n",
      "\n",
      "Searching for candidate:  50\n",
      "\n",
      "Searching for candidate:  51\n",
      "\n",
      "Searching for candidate:  52\n",
      "\n",
      "Searching for candidate:  53\n",
      "\n",
      "Searching for candidate:  54\n",
      "\n",
      "Searching for candidate:  55\n",
      "\n",
      "Searching for candidate:  56\n",
      "\n",
      "Searching for candidate:  57\n",
      "\n",
      "Searching for candidate:  58\n",
      "\n",
      "Searching for candidate:  59\n",
      "\n",
      "Searching for candidate:  60\n",
      "\n",
      "Searching for candidate:  61\n",
      "\n",
      "Searching for candidate:  62\n",
      "\n",
      "Searching for candidate:  63\n",
      "\n",
      "Searching for candidate:  64\n",
      "\n",
      "Searching for candidate:  65\n",
      "\n",
      "Searching for candidate:  66\n",
      "\n",
      "Searching for candidate:  67\n",
      "\n",
      "Searching for candidate:  68\n",
      "\n",
      "Searching for candidate:  69\n",
      "\n",
      "Searching for candidate:  70\n",
      "\n",
      "Searching for candidate:  71\n",
      "\n",
      "Searching for candidate:  72\n",
      "\n",
      "Searching for candidate:  73\n",
      "\n",
      "Searching for candidate:  74\n",
      "\n",
      "Searching for candidate:  75\n",
      "\n",
      "Searching for candidate:  76\n",
      "\n",
      "Searching for candidate:  77\n",
      "\n",
      "Searching for candidate:  78\n",
      "\n",
      "Searching for candidate:  79\n",
      "\n",
      "Searching for candidate:  80\n",
      "\n",
      "Searching for candidate:  81\n",
      "\n",
      "Searching for candidate:  82\n",
      "\n",
      "Searching for candidate:  83\n",
      "\n",
      "Searching for candidate:  84\n",
      "\n",
      "Searching for candidate:  85\n",
      "\n",
      "Searching for candidate:  86\n",
      "\n",
      "Searching for candidate:  87\n",
      "\n",
      "Searching for candidate:  88\n",
      "\n",
      "Searching for candidate:  89\n",
      "\n",
      "Searching for candidate:  90\n",
      "\n",
      "Searching for candidate:  91\n",
      "\n",
      "Searching for candidate:  92\n",
      "\n",
      "Searching for candidate:  93\n",
      "\n",
      "Searching for candidate:  94\n",
      "\n",
      "Searching for candidate:  95\n",
      "\n",
      "Searching for candidate:  96\n",
      "\n",
      "Searching for candidate:  97\n",
      "\n",
      "Searching for candidate:  98\n",
      "\n",
      "Searching for candidate:  99\n",
      "\n",
      "Searching for candidate:  100\n",
      "\n",
      "Searching for candidate:  101\n",
      "\n",
      "Searching for candidate:  102\n",
      "\n",
      "Searching for candidate:  103\n",
      "\n",
      "Searching for candidate:  104\n",
      "\n",
      "Searching for candidate:  105\n",
      "\n",
      "Searching for candidate:  106\n",
      "\n",
      "Searching for candidate:  107\n",
      "\n",
      "Searching for candidate:  108\n",
      "\n",
      "Searching for candidate:  109\n",
      "\n",
      "Searching for candidate:  110\n",
      "\n",
      "Searching for candidate:  111\n",
      "\n",
      "Searching for candidate:  112\n",
      "\n",
      "Searching for candidate:  113\n",
      "\n",
      "Searching for candidate:  114\n",
      "\n",
      "Searching for candidate:  115\n",
      "\n",
      "Searching for candidate:  116\n",
      "\n",
      "Searching for candidate:  117\n",
      "\n",
      "Searching for candidate:  118\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching for candidate:  119\n",
      "\n",
      "Searching for candidate:  120\n",
      "\n",
      "Searching for candidate:  121\n",
      "\n",
      "Searching for candidate:  122\n",
      "\n",
      "Searching for candidate:  123\n",
      "\n",
      "Searching for candidate:  124\n",
      "\n",
      "Searching for candidate:  125\n",
      "\n",
      "Searching for candidate:  126\n",
      "\n",
      "Searching for candidate:  127\n",
      "\n",
      "Searching for candidate:  128\n",
      "\n",
      "Searching for candidate:  129\n",
      "\n",
      "Searching for candidate:  130\n",
      "\n",
      "Searching for candidate:  131\n",
      "\n",
      "Searching for candidate:  132\n",
      "\n",
      "Searching for candidate:  133\n",
      "\n",
      "Searching for candidate:  134\n",
      "\n",
      "Searching for candidate:  135\n",
      "\n",
      "Searching for candidate:  136\n",
      "\n",
      "Searching for candidate:  137\n",
      "\n",
      "Searching for candidate:  138\n",
      "\n",
      "Searching for candidate:  139\n",
      "\n",
      "Searching for candidate:  140\n",
      "\n",
      "Searching for candidate:  141\n",
      "\n",
      "Searching for candidate:  142\n",
      "\n",
      "Searching for candidate:  143\n",
      "\n",
      "Searching for candidate:  144\n",
      "\n",
      "Searching for candidate:  145\n",
      "\n",
      "Searching for candidate:  146\n",
      "\n",
      "Searching for candidate:  147\n",
      "\n",
      "Searching for candidate:  148\n",
      "\n",
      "Searching for candidate:  149\n",
      "\n",
      "Searching for candidate:  150\n",
      "\n",
      "Searching for candidate:  151\n",
      "\n",
      "Searching for candidate:  152\n",
      "\n",
      "Searching for candidate:  153\n",
      "\n",
      "Searching for candidate:  154\n",
      "\n",
      "Searching for candidate:  155\n",
      "\n",
      "Searching for candidate:  156\n",
      "\n",
      "Searching for candidate:  157\n",
      "\n",
      "Searching for candidate:  158\n",
      "\n",
      "Searching for candidate:  159\n",
      "\n",
      "Searching for candidate:  160\n",
      "\n",
      "Searching for candidate:  161\n",
      "\n",
      "Searching for candidate:  162\n",
      "\n",
      "Searching for candidate:  163\n",
      "\n",
      "Searching for candidate:  164\n",
      "\n",
      "Searching for candidate:  165\n",
      "\n",
      "Searching for candidate:  166\n",
      "\n",
      "Searching for candidate:  167\n",
      "\n",
      "Searching for candidate:  168\n",
      "\n",
      "Searching for candidate:  169\n",
      "\n",
      "Searching for candidate:  170\n",
      "\n",
      "Searching for candidate:  171\n",
      "\n",
      "Searching for candidate:  172\n",
      "\n",
      "Searching for candidate:  173\n",
      "\n",
      "Searching for candidate:  174\n",
      "\n",
      "Searching for candidate:  175\n",
      "\n",
      "Searching for candidate:  176\n",
      "\n",
      "Searching for candidate:  177\n",
      "\n",
      "Searching for candidate:  178\n",
      "\n",
      "Searching for candidate:  179\n",
      "\n",
      "Searching for candidate:  180\n",
      "\n",
      "Searching for candidate:  181\n",
      "\n",
      "Searching for candidate:  182\n",
      "\n",
      "Searching for candidate:  183\n",
      "\n",
      "Searching for candidate:  184\n",
      "\n",
      "Searching for candidate:  185\n",
      "\n",
      "Searching for candidate:  186\n",
      "\n",
      "Searching for candidate:  187\n",
      "\n",
      "Searching for candidate:  188\n",
      "\n",
      "Searching for candidate:  189\n",
      "\n",
      "Searching for candidate:  190\n",
      "\n",
      "Searching for candidate:  191\n",
      "\n",
      "Searching for candidate:  192\n",
      "\n",
      "Searching for candidate:  193\n",
      "\n",
      "Searching for candidate:  194\n",
      "\n",
      "\n",
      "Total clustering time:  428.3114001000067\n",
      "Process: sample; Metric: z_score; Co-cluster ref: rows; Z-score: 1\n",
      "Number of co-clusters:  22\n",
      "\n",
      "Overall entropy H: 1.0230999684127997\n",
      "Purity: 1.0965909090909092\n",
      "AVG relative co-clusters: 6.42±2.23\n",
      "\n",
      "######################################\n",
      "Number of trajectories: 352\n",
      "Number of unique check-ins: 310\n",
      "########################################\n",
      "Number of the most frequent elements:  58\n",
      "Searching for candidate:  1\n",
      "\n",
      "Searching for candidate:  2\n",
      "\n",
      "Searching for candidate:  3\n",
      "\n",
      "Searching for candidate:  4\n",
      "\n",
      "Searching for candidate:  5\n",
      "\n",
      "Searching for candidate:  6\n",
      "\n",
      "Searching for candidate:  7\n",
      "\n",
      "Searching for candidate:  8\n",
      "\n",
      "Searching for candidate:  9\n",
      "\n",
      "Searching for candidate:  10\n",
      "\n",
      "Searching for candidate:  11\n",
      "\n",
      "Searching for candidate:  12\n",
      "\n",
      "Searching for candidate:  13\n",
      "\n",
      "Searching for candidate:  14\n",
      "\n",
      "Searching for candidate:  15\n",
      "\n",
      "Searching for candidate:  16\n",
      "\n",
      "Searching for candidate:  17\n",
      "\n",
      "Searching for candidate:  18\n",
      "\n",
      "Searching for candidate:  19\n",
      "\n",
      "Searching for candidate:  20\n",
      "\n",
      "Searching for candidate:  21\n",
      "\n",
      "Searching for candidate:  22\n",
      "\n",
      "Searching for candidate:  23\n",
      "\n",
      "Searching for candidate:  24\n",
      "\n",
      "Searching for candidate:  25\n",
      "\n",
      "Searching for candidate:  26\n",
      "\n",
      "Searching for candidate:  27\n",
      "\n",
      "Searching for candidate:  28\n",
      "\n",
      "Searching for candidate:  29\n",
      "\n",
      "Searching for candidate:  30\n",
      "\n",
      "Searching for candidate:  31\n",
      "\n",
      "Searching for candidate:  32\n",
      "\n",
      "Searching for candidate:  33\n",
      "\n",
      "Searching for candidate:  34\n",
      "\n",
      "Searching for candidate:  35\n",
      "\n",
      "Searching for candidate:  36\n",
      "\n",
      "Searching for candidate:  37\n",
      "\n",
      "Searching for candidate:  38\n",
      "\n",
      "Searching for candidate:  39\n",
      "\n",
      "Searching for candidate:  40\n",
      "\n",
      "Searching for candidate:  41\n",
      "\n",
      "Searching for candidate:  42\n",
      "\n",
      "Searching for candidate:  43\n",
      "\n",
      "Searching for candidate:  44\n",
      "\n",
      "Searching for candidate:  45\n",
      "\n",
      "Searching for candidate:  46\n",
      "\n",
      "Searching for candidate:  47\n",
      "\n",
      "Searching for candidate:  48\n",
      "\n",
      "Searching for candidate:  49\n",
      "\n",
      "Searching for candidate:  50\n",
      "\n",
      "Searching for candidate:  51\n",
      "\n",
      "Searching for candidate:  52\n",
      "\n",
      "Searching for candidate:  53\n",
      "\n",
      "Searching for candidate:  54\n",
      "\n",
      "Searching for candidate:  55\n",
      "\n",
      "Searching for candidate:  56\n",
      "\n",
      "Searching for candidate:  57\n",
      "\n",
      "Searching for candidate:  58\n",
      "\n",
      "Searching for candidate:  59\n",
      "\n",
      "Searching for candidate:  60\n",
      "\n",
      "Searching for candidate:  61\n",
      "\n",
      "Searching for candidate:  62\n",
      "\n",
      "Searching for candidate:  63\n",
      "\n",
      "Searching for candidate:  64\n",
      "\n",
      "Searching for candidate:  65\n",
      "\n",
      "Searching for candidate:  66\n",
      "\n",
      "Searching for candidate:  67\n",
      "\n",
      "Searching for candidate:  68\n",
      "\n",
      "Searching for candidate:  69\n",
      "\n",
      "Searching for candidate:  70\n",
      "\n",
      "Searching for candidate:  71\n",
      "\n",
      "Searching for candidate:  72\n",
      "\n",
      "Searching for candidate:  73\n",
      "\n",
      "Searching for candidate:  74\n",
      "\n",
      "Searching for candidate:  75\n",
      "\n",
      "Searching for candidate:  76\n",
      "\n",
      "Searching for candidate:  77\n",
      "\n",
      "Searching for candidate:  78\n",
      "\n",
      "Searching for candidate:  79\n",
      "\n",
      "Searching for candidate:  80\n",
      "\n",
      "Searching for candidate:  81\n",
      "\n",
      "Searching for candidate:  82\n",
      "\n",
      "Searching for candidate:  83\n",
      "\n",
      "Searching for candidate:  84\n",
      "\n",
      "Searching for candidate:  85\n",
      "\n",
      "Searching for candidate:  86\n",
      "\n",
      "Searching for candidate:  87\n",
      "\n",
      "Searching for candidate:  88\n",
      "\n",
      "Searching for candidate:  89\n",
      "\n",
      "Searching for candidate:  90\n",
      "\n",
      "Searching for candidate:  91\n",
      "\n",
      "Searching for candidate:  92\n",
      "\n",
      "Searching for candidate:  93\n",
      "\n",
      "Searching for candidate:  94\n",
      "\n",
      "Searching for candidate:  95\n",
      "\n",
      "Searching for candidate:  96\n",
      "\n",
      "Searching for candidate:  97\n",
      "\n",
      "Searching for candidate:  98\n",
      "\n",
      "Searching for candidate:  99\n",
      "\n",
      "Searching for candidate:  100\n",
      "\n",
      "Searching for candidate:  101\n",
      "\n",
      "Searching for candidate:  102\n",
      "\n",
      "Searching for candidate:  103\n",
      "\n",
      "Searching for candidate:  104\n",
      "\n",
      "Searching for candidate:  105\n",
      "\n",
      "Searching for candidate:  106\n",
      "\n",
      "Searching for candidate:  107\n",
      "\n",
      "Searching for candidate:  108\n",
      "\n",
      "Searching for candidate:  109\n",
      "\n",
      "Searching for candidate:  110\n",
      "\n",
      "Searching for candidate:  111\n",
      "\n",
      "Searching for candidate:  112\n",
      "\n",
      "Searching for candidate:  113\n",
      "\n",
      "Searching for candidate:  114\n",
      "\n",
      "Searching for candidate:  115\n",
      "\n",
      "Searching for candidate:  116\n",
      "\n",
      "Searching for candidate:  117\n",
      "\n",
      "Searching for candidate:  118\n",
      "\n",
      "Searching for candidate:  119\n",
      "\n",
      "Searching for candidate:  120\n",
      "\n",
      "Searching for candidate:  121\n",
      "\n",
      "Searching for candidate:  122\n",
      "\n",
      "Searching for candidate:  123\n",
      "\n",
      "Searching for candidate:  124\n",
      "\n",
      "Searching for candidate:  125\n",
      "\n",
      "Searching for candidate:  126\n",
      "\n",
      "Searching for candidate:  127\n",
      "\n",
      "Searching for candidate:  128\n",
      "\n",
      "Searching for candidate:  129\n",
      "\n",
      "Searching for candidate:  130\n",
      "\n",
      "Searching for candidate:  131\n",
      "\n",
      "Searching for candidate:  132\n",
      "\n",
      "Searching for candidate:  133\n",
      "\n",
      "Searching for candidate:  134\n",
      "\n",
      "Searching for candidate:  135\n",
      "\n",
      "Searching for candidate:  136\n",
      "\n",
      "Searching for candidate:  137\n",
      "\n",
      "Searching for candidate:  138\n",
      "\n",
      "Searching for candidate:  139\n",
      "\n",
      "Searching for candidate:  140\n",
      "\n",
      "Searching for candidate:  141\n",
      "\n",
      "Searching for candidate:  142\n",
      "\n",
      "Searching for candidate:  143\n",
      "\n",
      "Searching for candidate:  144\n",
      "\n",
      "Searching for candidate:  145\n",
      "\n",
      "Searching for candidate:  146\n",
      "\n",
      "Searching for candidate:  147\n",
      "\n",
      "Searching for candidate:  148\n",
      "\n",
      "Searching for candidate:  149\n",
      "\n",
      "Searching for candidate:  150\n",
      "\n",
      "Searching for candidate:  151\n",
      "\n",
      "Searching for candidate:  152\n",
      "\n",
      "Searching for candidate:  153\n",
      "\n",
      "Searching for candidate:  154\n",
      "\n",
      "Searching for candidate:  155\n",
      "\n",
      "Searching for candidate:  156\n",
      "\n",
      "Searching for candidate:  157\n",
      "\n",
      "Searching for candidate:  158\n",
      "\n",
      "Searching for candidate:  159\n",
      "\n",
      "Searching for candidate:  160\n",
      "\n",
      "Searching for candidate:  161\n",
      "\n",
      "Searching for candidate:  162\n",
      "\n",
      "Searching for candidate:  163\n",
      "\n",
      "Searching for candidate:  164\n",
      "\n",
      "Searching for candidate:  165\n",
      "\n",
      "Searching for candidate:  166\n",
      "\n",
      "Searching for candidate:  167\n",
      "\n",
      "Searching for candidate:  168\n",
      "\n",
      "Searching for candidate:  169\n",
      "\n",
      "Searching for candidate:  170\n",
      "\n",
      "Searching for candidate:  171\n",
      "\n",
      "Searching for candidate:  172\n",
      "\n",
      "Searching for candidate:  173\n",
      "\n",
      "Searching for candidate:  174\n",
      "\n",
      "Searching for candidate:  175\n",
      "\n",
      "Searching for candidate:  176\n",
      "\n",
      "Searching for candidate:  177\n",
      "\n",
      "Searching for candidate:  178\n",
      "\n",
      "Searching for candidate:  179\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching for candidate:  180\n",
      "\n",
      "Searching for candidate:  181\n",
      "\n",
      "Searching for candidate:  182\n",
      "\n",
      "Searching for candidate:  183\n",
      "\n",
      "Searching for candidate:  184\n",
      "\n",
      "Searching for candidate:  185\n",
      "\n",
      "Searching for candidate:  186\n",
      "\n",
      "Searching for candidate:  187\n",
      "\n",
      "Searching for candidate:  188\n",
      "\n",
      "Searching for candidate:  189\n",
      "\n",
      "Searching for candidate:  190\n",
      "\n",
      "Searching for candidate:  191\n",
      "\n",
      "Searching for candidate:  192\n",
      "\n",
      "Searching for candidate:  193\n",
      "\n",
      "Searching for candidate:  194\n",
      "\n",
      "\n",
      "Total clustering time:  432.78618659998756\n",
      "Process: sample; Metric: z_score; Co-cluster ref: cost; Z-score: -1\n",
      "Number of co-clusters:  193\n",
      "\n",
      "Overall entropy H: 2.1685486168417136\n",
      "Purity: 3.565340909090909\n",
      "AVG relative co-clusters: 2.20±1.89\n",
      "\n",
      "######################################\n",
      "Number of trajectories: 352\n",
      "Number of unique check-ins: 310\n",
      "########################################\n",
      "Number of the most frequent elements:  58\n",
      "Searching for candidate:  1\n",
      "\n",
      "Searching for candidate:  2\n",
      "\n",
      "Searching for candidate:  3\n",
      "\n",
      "Searching for candidate:  4\n",
      "\n",
      "Searching for candidate:  5\n",
      "\n",
      "Searching for candidate:  6\n",
      "\n",
      "Searching for candidate:  7\n",
      "\n",
      "Searching for candidate:  8\n",
      "\n",
      "Searching for candidate:  9\n",
      "\n",
      "Searching for candidate:  10\n",
      "\n",
      "Searching for candidate:  11\n",
      "\n",
      "Searching for candidate:  12\n",
      "\n",
      "Searching for candidate:  13\n",
      "\n",
      "Searching for candidate:  14\n",
      "\n",
      "Searching for candidate:  15\n",
      "\n",
      "Searching for candidate:  16\n",
      "\n",
      "Searching for candidate:  17\n",
      "\n",
      "Searching for candidate:  18\n",
      "\n",
      "Searching for candidate:  19\n",
      "\n",
      "Searching for candidate:  20\n",
      "\n",
      "Searching for candidate:  21\n",
      "\n",
      "Searching for candidate:  22\n",
      "\n",
      "Searching for candidate:  23\n",
      "\n",
      "Searching for candidate:  24\n",
      "\n",
      "Searching for candidate:  25\n",
      "\n",
      "Searching for candidate:  26\n",
      "\n",
      "Searching for candidate:  27\n",
      "\n",
      "Searching for candidate:  28\n",
      "\n",
      "Searching for candidate:  29\n",
      "\n",
      "Searching for candidate:  30\n",
      "\n",
      "Searching for candidate:  31\n",
      "\n",
      "Searching for candidate:  32\n",
      "\n",
      "Searching for candidate:  33\n",
      "\n",
      "Searching for candidate:  34\n",
      "\n",
      "Searching for candidate:  35\n",
      "\n",
      "Searching for candidate:  36\n",
      "\n",
      "Searching for candidate:  37\n",
      "\n",
      "Searching for candidate:  38\n",
      "\n",
      "Searching for candidate:  39\n",
      "\n",
      "Searching for candidate:  40\n",
      "\n",
      "Searching for candidate:  41\n",
      "\n",
      "Searching for candidate:  42\n",
      "\n",
      "Searching for candidate:  43\n",
      "\n",
      "Searching for candidate:  44\n",
      "\n",
      "Searching for candidate:  45\n",
      "\n",
      "Searching for candidate:  46\n",
      "\n",
      "Searching for candidate:  47\n",
      "\n",
      "Searching for candidate:  48\n",
      "\n",
      "Searching for candidate:  49\n",
      "\n",
      "Searching for candidate:  50\n",
      "\n",
      "Searching for candidate:  51\n",
      "\n",
      "Searching for candidate:  52\n",
      "\n",
      "Searching for candidate:  53\n",
      "\n",
      "Searching for candidate:  54\n",
      "\n",
      "Searching for candidate:  55\n",
      "\n",
      "Searching for candidate:  56\n",
      "\n",
      "Searching for candidate:  57\n",
      "\n",
      "Searching for candidate:  58\n",
      "\n",
      "Searching for candidate:  59\n",
      "\n",
      "Searching for candidate:  60\n",
      "\n",
      "Searching for candidate:  61\n",
      "\n",
      "Searching for candidate:  62\n",
      "\n",
      "Searching for candidate:  63\n",
      "\n",
      "Searching for candidate:  64\n",
      "\n",
      "Searching for candidate:  65\n",
      "\n",
      "Searching for candidate:  66\n",
      "\n",
      "Searching for candidate:  67\n",
      "\n",
      "Searching for candidate:  68\n",
      "\n",
      "Searching for candidate:  69\n",
      "\n",
      "Searching for candidate:  70\n",
      "\n",
      "Searching for candidate:  71\n",
      "\n",
      "Searching for candidate:  72\n",
      "\n",
      "Searching for candidate:  73\n",
      "\n",
      "Searching for candidate:  74\n",
      "\n",
      "Searching for candidate:  75\n",
      "\n",
      "Searching for candidate:  76\n",
      "\n",
      "Searching for candidate:  77\n",
      "\n",
      "Searching for candidate:  78\n",
      "\n",
      "Searching for candidate:  79\n",
      "\n",
      "Searching for candidate:  80\n",
      "\n",
      "Searching for candidate:  81\n",
      "\n",
      "Searching for candidate:  82\n",
      "\n",
      "Searching for candidate:  83\n",
      "\n",
      "Searching for candidate:  84\n",
      "\n",
      "Searching for candidate:  85\n",
      "\n",
      "Searching for candidate:  86\n",
      "\n",
      "Searching for candidate:  87\n",
      "\n",
      "Searching for candidate:  88\n",
      "\n",
      "Searching for candidate:  89\n",
      "\n",
      "Searching for candidate:  90\n",
      "\n",
      "Searching for candidate:  91\n",
      "\n",
      "Searching for candidate:  92\n",
      "\n",
      "Searching for candidate:  93\n",
      "\n",
      "Searching for candidate:  94\n",
      "\n",
      "Searching for candidate:  95\n",
      "\n",
      "Searching for candidate:  96\n",
      "\n",
      "Searching for candidate:  97\n",
      "\n",
      "Searching for candidate:  98\n",
      "\n",
      "Searching for candidate:  99\n",
      "\n",
      "Searching for candidate:  100\n",
      "\n",
      "Searching for candidate:  101\n",
      "\n",
      "Searching for candidate:  102\n",
      "\n",
      "Searching for candidate:  103\n",
      "\n",
      "Searching for candidate:  104\n",
      "\n",
      "Searching for candidate:  105\n",
      "\n",
      "Searching for candidate:  106\n",
      "\n",
      "Searching for candidate:  107\n",
      "\n",
      "Searching for candidate:  108\n",
      "\n",
      "Searching for candidate:  109\n",
      "\n",
      "Searching for candidate:  110\n",
      "\n",
      "Searching for candidate:  111\n",
      "\n",
      "Searching for candidate:  112\n",
      "\n",
      "Searching for candidate:  113\n",
      "\n",
      "Searching for candidate:  114\n",
      "\n",
      "Searching for candidate:  115\n",
      "\n",
      "Searching for candidate:  116\n",
      "\n",
      "Searching for candidate:  117\n",
      "\n",
      "Searching for candidate:  118\n",
      "\n",
      "Searching for candidate:  119\n",
      "\n",
      "Searching for candidate:  120\n",
      "\n",
      "Searching for candidate:  121\n",
      "\n",
      "Searching for candidate:  122\n",
      "\n",
      "Searching for candidate:  123\n",
      "\n",
      "Searching for candidate:  124\n",
      "\n",
      "Searching for candidate:  125\n",
      "\n",
      "Searching for candidate:  126\n",
      "\n",
      "Searching for candidate:  127\n",
      "\n",
      "Searching for candidate:  128\n",
      "\n",
      "Searching for candidate:  129\n",
      "\n",
      "Searching for candidate:  130\n",
      "\n",
      "Searching for candidate:  131\n",
      "\n",
      "Searching for candidate:  132\n",
      "\n",
      "Searching for candidate:  133\n",
      "\n",
      "Searching for candidate:  134\n",
      "\n",
      "Searching for candidate:  135\n",
      "\n",
      "Searching for candidate:  136\n",
      "\n",
      "Searching for candidate:  137\n",
      "\n",
      "Searching for candidate:  138\n",
      "\n",
      "Searching for candidate:  139\n",
      "\n",
      "Searching for candidate:  140\n",
      "\n",
      "Searching for candidate:  141\n",
      "\n",
      "Searching for candidate:  142\n",
      "\n",
      "Searching for candidate:  143\n",
      "\n",
      "Searching for candidate:  144\n",
      "\n",
      "Searching for candidate:  145\n",
      "\n",
      "Searching for candidate:  146\n",
      "\n",
      "Searching for candidate:  147\n",
      "\n",
      "Searching for candidate:  148\n",
      "\n",
      "Searching for candidate:  149\n",
      "\n",
      "Searching for candidate:  150\n",
      "\n",
      "Searching for candidate:  151\n",
      "\n",
      "Searching for candidate:  152\n",
      "\n",
      "Searching for candidate:  153\n",
      "\n",
      "Searching for candidate:  154\n",
      "\n",
      "Searching for candidate:  155\n",
      "\n",
      "Searching for candidate:  156\n",
      "\n",
      "Searching for candidate:  157\n",
      "\n",
      "Searching for candidate:  158\n",
      "\n",
      "Searching for candidate:  159\n",
      "\n",
      "Searching for candidate:  160\n",
      "\n",
      "Searching for candidate:  161\n",
      "\n",
      "Searching for candidate:  162\n",
      "\n",
      "Searching for candidate:  163\n",
      "\n",
      "Searching for candidate:  164\n",
      "\n",
      "Searching for candidate:  165\n",
      "\n",
      "Searching for candidate:  166\n",
      "\n",
      "Searching for candidate:  167\n",
      "\n",
      "Searching for candidate:  168\n",
      "\n",
      "Searching for candidate:  169\n",
      "\n",
      "Searching for candidate:  170\n",
      "\n",
      "Searching for candidate:  171\n",
      "\n",
      "Searching for candidate:  172\n",
      "\n",
      "Searching for candidate:  173\n",
      "\n",
      "Searching for candidate:  174\n",
      "\n",
      "Searching for candidate:  175\n",
      "\n",
      "Searching for candidate:  176\n",
      "\n",
      "Searching for candidate:  177\n",
      "\n",
      "Searching for candidate:  178\n",
      "\n",
      "Searching for candidate:  179\n",
      "\n",
      "Searching for candidate:  180\n",
      "\n",
      "Searching for candidate:  181\n",
      "\n",
      "Searching for candidate:  182\n",
      "\n",
      "Searching for candidate:  183\n",
      "\n",
      "Searching for candidate:  184\n",
      "\n",
      "Searching for candidate:  185\n",
      "\n",
      "Searching for candidate:  186\n",
      "\n",
      "Searching for candidate:  187\n",
      "\n",
      "Searching for candidate:  188\n",
      "\n",
      "Searching for candidate:  189\n",
      "\n",
      "Searching for candidate:  190\n",
      "\n",
      "Searching for candidate:  191\n",
      "\n",
      "Searching for candidate:  192\n",
      "\n",
      "Searching for candidate:  193\n",
      "\n",
      "Searching for candidate:  194\n",
      "\n",
      "\n",
      "Total clustering time:  439.46011770004407\n",
      "Process: sample; Metric: z_score; Co-cluster ref: cost; Z-score: 0\n",
      "Number of co-clusters:  53\n",
      "\n",
      "Overall entropy H: 1.1496737447957228\n",
      "Purity: 1.8352272727272727\n",
      "AVG relative co-clusters: 4.13±2.49\n",
      "\n",
      "######################################\n",
      "Number of trajectories: 352\n",
      "Number of unique check-ins: 310\n",
      "########################################\n",
      "Number of the most frequent elements:  58\n",
      "Searching for candidate:  1\n",
      "\n",
      "Searching for candidate:  2\n",
      "\n",
      "Searching for candidate:  3\n",
      "\n",
      "Searching for candidate:  4\n",
      "\n",
      "Searching for candidate:  5\n",
      "\n",
      "Searching for candidate:  6\n",
      "\n",
      "Searching for candidate:  7\n",
      "\n",
      "Searching for candidate:  8\n",
      "\n",
      "Searching for candidate:  9\n",
      "\n",
      "Searching for candidate:  10\n",
      "\n",
      "Searching for candidate:  11\n",
      "\n",
      "Searching for candidate:  12\n",
      "\n",
      "Searching for candidate:  13\n",
      "\n",
      "Searching for candidate:  14\n",
      "\n",
      "Searching for candidate:  15\n",
      "\n",
      "Searching for candidate:  16\n",
      "\n",
      "Searching for candidate:  17\n",
      "\n",
      "Searching for candidate:  18\n",
      "\n",
      "Searching for candidate:  19\n",
      "\n",
      "Searching for candidate:  20\n",
      "\n",
      "Searching for candidate:  21\n",
      "\n",
      "Searching for candidate:  22\n",
      "\n",
      "Searching for candidate:  23\n",
      "\n",
      "Searching for candidate:  24\n",
      "\n",
      "Searching for candidate:  25\n",
      "\n",
      "Searching for candidate:  26\n",
      "\n",
      "Searching for candidate:  27\n",
      "\n",
      "Searching for candidate:  28\n",
      "\n",
      "Searching for candidate:  29\n",
      "\n",
      "Searching for candidate:  30\n",
      "\n",
      "Searching for candidate:  31\n",
      "\n",
      "Searching for candidate:  32\n",
      "\n",
      "Searching for candidate:  33\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching for candidate:  34\n",
      "\n",
      "Searching for candidate:  35\n",
      "\n",
      "Searching for candidate:  36\n",
      "\n",
      "Searching for candidate:  37\n",
      "\n",
      "Searching for candidate:  38\n",
      "\n",
      "Searching for candidate:  39\n",
      "\n",
      "Searching for candidate:  40\n",
      "\n",
      "Searching for candidate:  41\n",
      "\n",
      "Searching for candidate:  42\n",
      "\n",
      "Searching for candidate:  43\n",
      "\n",
      "Searching for candidate:  44\n",
      "\n",
      "Searching for candidate:  45\n",
      "\n",
      "Searching for candidate:  46\n",
      "\n",
      "Searching for candidate:  47\n",
      "\n",
      "Searching for candidate:  48\n",
      "\n",
      "Searching for candidate:  49\n",
      "\n",
      "Searching for candidate:  50\n",
      "\n",
      "Searching for candidate:  51\n",
      "\n",
      "Searching for candidate:  52\n",
      "\n",
      "Searching for candidate:  53\n",
      "\n",
      "Searching for candidate:  54\n",
      "\n",
      "Searching for candidate:  55\n",
      "\n",
      "Searching for candidate:  56\n",
      "\n",
      "Searching for candidate:  57\n",
      "\n",
      "Searching for candidate:  58\n",
      "\n",
      "Searching for candidate:  59\n",
      "\n",
      "Searching for candidate:  60\n",
      "\n",
      "Searching for candidate:  61\n",
      "\n",
      "Searching for candidate:  62\n",
      "\n",
      "Searching for candidate:  63\n",
      "\n",
      "Searching for candidate:  64\n",
      "\n",
      "Searching for candidate:  65\n",
      "\n",
      "Searching for candidate:  66\n",
      "\n",
      "Searching for candidate:  67\n",
      "\n",
      "Searching for candidate:  68\n",
      "\n",
      "Searching for candidate:  69\n",
      "\n",
      "Searching for candidate:  70\n",
      "\n",
      "Searching for candidate:  71\n",
      "\n",
      "Searching for candidate:  72\n",
      "\n",
      "Searching for candidate:  73\n",
      "\n",
      "Searching for candidate:  74\n",
      "\n",
      "Searching for candidate:  75\n",
      "\n",
      "Searching for candidate:  76\n",
      "\n",
      "Searching for candidate:  77\n",
      "\n",
      "Searching for candidate:  78\n",
      "\n",
      "Searching for candidate:  79\n",
      "\n",
      "Searching for candidate:  80\n",
      "\n",
      "Searching for candidate:  81\n",
      "\n",
      "Searching for candidate:  82\n",
      "\n",
      "Searching for candidate:  83\n",
      "\n",
      "Searching for candidate:  84\n",
      "\n",
      "Searching for candidate:  85\n",
      "\n",
      "Searching for candidate:  86\n",
      "\n",
      "Searching for candidate:  87\n",
      "\n",
      "Searching for candidate:  88\n",
      "\n",
      "Searching for candidate:  89\n",
      "\n",
      "Searching for candidate:  90\n",
      "\n",
      "Searching for candidate:  91\n",
      "\n",
      "Searching for candidate:  92\n",
      "\n",
      "Searching for candidate:  93\n",
      "\n",
      "Searching for candidate:  94\n",
      "\n",
      "Searching for candidate:  95\n",
      "\n",
      "Searching for candidate:  96\n",
      "\n",
      "Searching for candidate:  97\n",
      "\n",
      "Searching for candidate:  98\n",
      "\n",
      "Searching for candidate:  99\n",
      "\n",
      "Searching for candidate:  100\n",
      "\n",
      "Searching for candidate:  101\n",
      "\n",
      "Searching for candidate:  102\n",
      "\n",
      "Searching for candidate:  103\n",
      "\n",
      "Searching for candidate:  104\n",
      "\n",
      "Searching for candidate:  105\n",
      "\n",
      "Searching for candidate:  106\n",
      "\n",
      "Searching for candidate:  107\n",
      "\n",
      "Searching for candidate:  108\n",
      "\n",
      "Searching for candidate:  109\n",
      "\n",
      "Searching for candidate:  110\n",
      "\n",
      "Searching for candidate:  111\n",
      "\n",
      "Searching for candidate:  112\n",
      "\n",
      "Searching for candidate:  113\n",
      "\n",
      "Searching for candidate:  114\n",
      "\n",
      "Searching for candidate:  115\n",
      "\n",
      "Searching for candidate:  116\n",
      "\n",
      "Searching for candidate:  117\n",
      "\n",
      "Searching for candidate:  118\n",
      "\n",
      "Searching for candidate:  119\n",
      "\n",
      "Searching for candidate:  120\n",
      "\n",
      "Searching for candidate:  121\n",
      "\n",
      "Searching for candidate:  122\n",
      "\n",
      "Searching for candidate:  123\n",
      "\n",
      "Searching for candidate:  124\n",
      "\n",
      "Searching for candidate:  125\n",
      "\n",
      "Searching for candidate:  126\n",
      "\n",
      "Searching for candidate:  127\n",
      "\n",
      "Searching for candidate:  128\n",
      "\n",
      "Searching for candidate:  129\n",
      "\n",
      "Searching for candidate:  130\n",
      "\n",
      "Searching for candidate:  131\n",
      "\n",
      "Searching for candidate:  132\n",
      "\n",
      "Searching for candidate:  133\n",
      "\n",
      "Searching for candidate:  134\n",
      "\n",
      "Searching for candidate:  135\n",
      "\n",
      "Searching for candidate:  136\n",
      "\n",
      "Searching for candidate:  137\n",
      "\n",
      "Searching for candidate:  138\n",
      "\n",
      "Searching for candidate:  139\n",
      "\n",
      "Searching for candidate:  140\n",
      "\n",
      "Searching for candidate:  141\n",
      "\n",
      "Searching for candidate:  142\n",
      "\n",
      "Searching for candidate:  143\n",
      "\n",
      "Searching for candidate:  144\n",
      "\n",
      "Searching for candidate:  145\n",
      "\n",
      "Searching for candidate:  146\n",
      "\n",
      "Searching for candidate:  147\n",
      "\n",
      "Searching for candidate:  148\n",
      "\n",
      "Searching for candidate:  149\n",
      "\n",
      "Searching for candidate:  150\n",
      "\n",
      "Searching for candidate:  151\n",
      "\n",
      "Searching for candidate:  152\n",
      "\n",
      "Searching for candidate:  153\n",
      "\n",
      "Searching for candidate:  154\n",
      "\n",
      "Searching for candidate:  155\n",
      "\n",
      "Searching for candidate:  156\n",
      "\n",
      "Searching for candidate:  157\n",
      "\n",
      "Searching for candidate:  158\n",
      "\n",
      "Searching for candidate:  159\n",
      "\n",
      "Searching for candidate:  160\n",
      "\n",
      "Searching for candidate:  161\n",
      "\n",
      "Searching for candidate:  162\n",
      "\n",
      "Searching for candidate:  163\n",
      "\n",
      "Searching for candidate:  164\n",
      "\n",
      "Searching for candidate:  165\n",
      "\n",
      "Searching for candidate:  166\n",
      "\n",
      "Searching for candidate:  167\n",
      "\n",
      "Searching for candidate:  168\n",
      "\n",
      "Searching for candidate:  169\n",
      "\n",
      "Searching for candidate:  170\n",
      "\n",
      "Searching for candidate:  171\n",
      "\n",
      "Searching for candidate:  172\n",
      "\n",
      "Searching for candidate:  173\n",
      "\n",
      "Searching for candidate:  174\n",
      "\n",
      "Searching for candidate:  175\n",
      "\n",
      "Searching for candidate:  176\n",
      "\n",
      "Searching for candidate:  177\n",
      "\n",
      "Searching for candidate:  178\n",
      "\n",
      "Searching for candidate:  179\n",
      "\n",
      "Searching for candidate:  180\n",
      "\n",
      "Searching for candidate:  181\n",
      "\n",
      "Searching for candidate:  182\n",
      "\n",
      "Searching for candidate:  183\n",
      "\n",
      "Searching for candidate:  184\n",
      "\n",
      "Searching for candidate:  185\n",
      "\n",
      "Searching for candidate:  186\n",
      "\n",
      "Searching for candidate:  187\n",
      "\n",
      "Searching for candidate:  188\n",
      "\n",
      "Searching for candidate:  189\n",
      "\n",
      "Searching for candidate:  190\n",
      "\n",
      "Searching for candidate:  191\n",
      "\n",
      "Searching for candidate:  192\n",
      "\n",
      "Searching for candidate:  193\n",
      "\n",
      "Searching for candidate:  194\n",
      "\n",
      "\n",
      "Total clustering time:  434.6655834999983\n",
      "Process: sample; Metric: z_score; Co-cluster ref: cost; Z-score: 1\n",
      "Number of co-clusters:  27\n",
      "\n",
      "Overall entropy H: 0.8312595857348953\n",
      "Purity: 1.1306818181818181\n",
      "AVG relative co-clusters: 5.18±2.74\n",
      "\n",
      "######################################\n",
      "Number of trajectories: 352\n",
      "Number of unique check-ins: 310\n",
      "########################################\n",
      "Number of the most frequent elements:  58\n",
      "Searching for candidate:  1\n",
      "\n",
      "Searching for candidate:  2\n",
      "\n",
      "Searching for candidate:  3\n",
      "\n",
      "Searching for candidate:  4\n",
      "\n",
      "Searching for candidate:  5\n",
      "\n",
      "Searching for candidate:  6\n",
      "\n",
      "Searching for candidate:  7\n",
      "\n",
      "Searching for candidate:  8\n",
      "\n",
      "Searching for candidate:  9\n",
      "\n",
      "Searching for candidate:  10\n",
      "\n",
      "Searching for candidate:  11\n",
      "\n",
      "Searching for candidate:  12\n",
      "\n",
      "Searching for candidate:  13\n",
      "\n",
      "Searching for candidate:  14\n",
      "\n",
      "Searching for candidate:  15\n",
      "\n",
      "Searching for candidate:  16\n",
      "\n",
      "Searching for candidate:  17\n",
      "\n",
      "Searching for candidate:  18\n",
      "\n",
      "Searching for candidate:  19\n",
      "\n",
      "Searching for candidate:  20\n",
      "\n",
      "Searching for candidate:  21\n",
      "\n",
      "Searching for candidate:  22\n",
      "\n",
      "Searching for candidate:  23\n",
      "\n",
      "Searching for candidate:  24\n",
      "\n",
      "Searching for candidate:  25\n",
      "\n",
      "Searching for candidate:  26\n",
      "\n",
      "Searching for candidate:  27\n",
      "\n",
      "Searching for candidate:  28\n",
      "\n",
      "Searching for candidate:  29\n",
      "\n",
      "Searching for candidate:  30\n",
      "\n",
      "Searching for candidate:  31\n",
      "\n",
      "Searching for candidate:  32\n",
      "\n",
      "Searching for candidate:  33\n",
      "\n",
      "Searching for candidate:  34\n",
      "\n",
      "Searching for candidate:  35\n",
      "\n",
      "Searching for candidate:  36\n",
      "\n",
      "Searching for candidate:  37\n",
      "\n",
      "Searching for candidate:  38\n",
      "\n",
      "Searching for candidate:  39\n",
      "\n",
      "Searching for candidate:  40\n",
      "\n",
      "Searching for candidate:  41\n",
      "\n",
      "Searching for candidate:  42\n",
      "\n",
      "Searching for candidate:  43\n",
      "\n",
      "Searching for candidate:  44\n",
      "\n",
      "Searching for candidate:  45\n",
      "\n",
      "Searching for candidate:  46\n",
      "\n",
      "Searching for candidate:  47\n",
      "\n",
      "Searching for candidate:  48\n",
      "\n",
      "Searching for candidate:  49\n",
      "\n",
      "Searching for candidate:  50\n",
      "\n",
      "Searching for candidate:  51\n",
      "\n",
      "Searching for candidate:  52\n",
      "\n",
      "Searching for candidate:  53\n",
      "\n",
      "Searching for candidate:  54\n",
      "\n",
      "Searching for candidate:  55\n",
      "\n",
      "Searching for candidate:  56\n",
      "\n",
      "Searching for candidate:  57\n",
      "\n",
      "Searching for candidate:  58\n",
      "\n",
      "Searching for candidate:  59\n",
      "\n",
      "Searching for candidate:  60\n",
      "\n",
      "Searching for candidate:  61\n",
      "\n",
      "Searching for candidate:  62\n",
      "\n",
      "Searching for candidate:  63\n",
      "\n",
      "Searching for candidate:  64\n",
      "\n",
      "Searching for candidate:  65\n",
      "\n",
      "Searching for candidate:  66\n",
      "\n",
      "Searching for candidate:  67\n",
      "\n",
      "Searching for candidate:  68\n",
      "\n",
      "Searching for candidate:  69\n",
      "\n",
      "Searching for candidate:  70\n",
      "\n",
      "Searching for candidate:  71\n",
      "\n",
      "Searching for candidate:  72\n",
      "\n",
      "Searching for candidate:  73\n",
      "\n",
      "Searching for candidate:  74\n",
      "\n",
      "Searching for candidate:  75\n",
      "\n",
      "Searching for candidate:  76\n",
      "\n",
      "Searching for candidate:  77\n",
      "\n",
      "Searching for candidate:  78\n",
      "\n",
      "Searching for candidate:  79\n",
      "\n",
      "Searching for candidate:  80\n",
      "\n",
      "Searching for candidate:  81\n",
      "\n",
      "Searching for candidate:  82\n",
      "\n",
      "Searching for candidate:  83\n",
      "\n",
      "Searching for candidate:  84\n",
      "\n",
      "Searching for candidate:  85\n",
      "\n",
      "Searching for candidate:  86\n",
      "\n",
      "Searching for candidate:  87\n",
      "\n",
      "Searching for candidate:  88\n",
      "\n",
      "Searching for candidate:  89\n",
      "\n",
      "Searching for candidate:  90\n",
      "\n",
      "Searching for candidate:  91\n",
      "\n",
      "Searching for candidate:  92\n",
      "\n",
      "Searching for candidate:  93\n",
      "\n",
      "Searching for candidate:  94\n",
      "\n",
      "Searching for candidate:  95\n",
      "\n",
      "Searching for candidate:  96\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching for candidate:  97\n",
      "\n",
      "Searching for candidate:  98\n",
      "\n",
      "Searching for candidate:  99\n",
      "\n",
      "Searching for candidate:  100\n",
      "\n",
      "Searching for candidate:  101\n",
      "\n",
      "Searching for candidate:  102\n",
      "\n",
      "Searching for candidate:  103\n",
      "\n",
      "Searching for candidate:  104\n",
      "\n",
      "Searching for candidate:  105\n",
      "\n",
      "Searching for candidate:  106\n",
      "\n",
      "Searching for candidate:  107\n",
      "\n",
      "Searching for candidate:  108\n",
      "\n",
      "Searching for candidate:  109\n",
      "\n",
      "Searching for candidate:  110\n",
      "\n",
      "Searching for candidate:  111\n",
      "\n",
      "Searching for candidate:  112\n",
      "\n",
      "Searching for candidate:  113\n",
      "\n",
      "Searching for candidate:  114\n",
      "\n",
      "Searching for candidate:  115\n",
      "\n",
      "Searching for candidate:  116\n",
      "\n",
      "Searching for candidate:  117\n",
      "\n",
      "Searching for candidate:  118\n",
      "\n",
      "Searching for candidate:  119\n",
      "\n",
      "Searching for candidate:  120\n",
      "\n",
      "Searching for candidate:  121\n",
      "\n",
      "Searching for candidate:  122\n",
      "\n",
      "Searching for candidate:  123\n",
      "\n",
      "Searching for candidate:  124\n",
      "\n",
      "Searching for candidate:  125\n",
      "\n",
      "Searching for candidate:  126\n",
      "\n",
      "Searching for candidate:  127\n",
      "\n",
      "Searching for candidate:  128\n",
      "\n",
      "Searching for candidate:  129\n",
      "\n",
      "Searching for candidate:  130\n",
      "\n",
      "Searching for candidate:  131\n",
      "\n",
      "Searching for candidate:  132\n",
      "\n",
      "Searching for candidate:  133\n",
      "\n",
      "Searching for candidate:  134\n",
      "\n",
      "Searching for candidate:  135\n",
      "\n",
      "Searching for candidate:  136\n",
      "\n",
      "Searching for candidate:  137\n",
      "\n",
      "Searching for candidate:  138\n",
      "\n",
      "Searching for candidate:  139\n",
      "\n",
      "Searching for candidate:  140\n",
      "\n",
      "Searching for candidate:  141\n",
      "\n",
      "Searching for candidate:  142\n",
      "\n",
      "Searching for candidate:  143\n",
      "\n",
      "Searching for candidate:  144\n",
      "\n",
      "Searching for candidate:  145\n",
      "\n",
      "Searching for candidate:  146\n",
      "\n",
      "Searching for candidate:  147\n",
      "\n",
      "Searching for candidate:  148\n",
      "\n",
      "Searching for candidate:  149\n",
      "\n",
      "Searching for candidate:  150\n",
      "\n",
      "Searching for candidate:  151\n",
      "\n",
      "Searching for candidate:  152\n",
      "\n",
      "Searching for candidate:  153\n",
      "\n",
      "Searching for candidate:  154\n",
      "\n",
      "Searching for candidate:  155\n",
      "\n",
      "Searching for candidate:  156\n",
      "\n",
      "Searching for candidate:  157\n",
      "\n",
      "Searching for candidate:  158\n",
      "\n",
      "Searching for candidate:  159\n",
      "\n",
      "Searching for candidate:  160\n",
      "\n",
      "Searching for candidate:  161\n",
      "\n",
      "Searching for candidate:  162\n",
      "\n",
      "Searching for candidate:  163\n",
      "\n",
      "Searching for candidate:  164\n",
      "\n",
      "Searching for candidate:  165\n",
      "\n",
      "Searching for candidate:  166\n",
      "\n",
      "Searching for candidate:  167\n",
      "\n",
      "Searching for candidate:  168\n",
      "\n",
      "Searching for candidate:  169\n",
      "\n",
      "Searching for candidate:  170\n",
      "\n",
      "Searching for candidate:  171\n",
      "\n",
      "Searching for candidate:  172\n",
      "\n",
      "Searching for candidate:  173\n",
      "\n",
      "Searching for candidate:  174\n",
      "\n",
      "Searching for candidate:  175\n",
      "\n",
      "Searching for candidate:  176\n",
      "\n",
      "Searching for candidate:  177\n",
      "\n",
      "Searching for candidate:  178\n",
      "\n",
      "Searching for candidate:  179\n",
      "\n",
      "Searching for candidate:  180\n",
      "\n",
      "Searching for candidate:  181\n",
      "\n",
      "Searching for candidate:  182\n",
      "\n",
      "Searching for candidate:  183\n",
      "\n",
      "Searching for candidate:  184\n",
      "\n",
      "Searching for candidate:  185\n",
      "\n",
      "Searching for candidate:  186\n",
      "\n",
      "Searching for candidate:  187\n",
      "\n",
      "Searching for candidate:  188\n",
      "\n",
      "Searching for candidate:  189\n",
      "\n",
      "Searching for candidate:  190\n",
      "\n",
      "Searching for candidate:  191\n",
      "\n",
      "Searching for candidate:  192\n",
      "\n",
      "Searching for candidate:  193\n",
      "\n",
      "Searching for candidate:  194\n",
      "\n",
      "\n",
      "Total clustering time:  427.5324599999585\n",
      "Process: sample; Metric: z_score; Co-cluster ref: combine; Z-score: -1\n",
      "Number of co-clusters:  193\n",
      "\n",
      "Overall entropy H: 2.1685486168417136\n",
      "Purity: 3.565340909090909\n",
      "AVG relative co-clusters: 2.20±1.89\n",
      "\n",
      "######################################\n",
      "Number of trajectories: 352\n",
      "Number of unique check-ins: 310\n",
      "########################################\n",
      "Number of the most frequent elements:  58\n",
      "Searching for candidate:  1\n",
      "\n",
      "Searching for candidate:  2\n",
      "\n",
      "Searching for candidate:  3\n",
      "\n",
      "Searching for candidate:  4\n",
      "\n",
      "Searching for candidate:  5\n",
      "\n",
      "Searching for candidate:  6\n",
      "\n",
      "Searching for candidate:  7\n",
      "\n",
      "Searching for candidate:  8\n",
      "\n",
      "Searching for candidate:  9\n",
      "\n",
      "Searching for candidate:  10\n",
      "\n",
      "Searching for candidate:  11\n",
      "\n",
      "Searching for candidate:  12\n",
      "\n",
      "Searching for candidate:  13\n",
      "\n",
      "Searching for candidate:  14\n",
      "\n",
      "Searching for candidate:  15\n",
      "\n",
      "Searching for candidate:  16\n",
      "\n",
      "Searching for candidate:  17\n",
      "\n",
      "Searching for candidate:  18\n",
      "\n",
      "Searching for candidate:  19\n",
      "\n",
      "Searching for candidate:  20\n",
      "\n",
      "Searching for candidate:  21\n",
      "\n",
      "Searching for candidate:  22\n",
      "\n",
      "Searching for candidate:  23\n",
      "\n",
      "Searching for candidate:  24\n",
      "\n",
      "Searching for candidate:  25\n",
      "\n",
      "Searching for candidate:  26\n",
      "\n",
      "Searching for candidate:  27\n",
      "\n",
      "Searching for candidate:  28\n",
      "\n",
      "Searching for candidate:  29\n",
      "\n",
      "Searching for candidate:  30\n",
      "\n",
      "Searching for candidate:  31\n",
      "\n",
      "Searching for candidate:  32\n",
      "\n",
      "Searching for candidate:  33\n",
      "\n",
      "Searching for candidate:  34\n",
      "\n",
      "Searching for candidate:  35\n",
      "\n",
      "Searching for candidate:  36\n",
      "\n",
      "Searching for candidate:  37\n",
      "\n",
      "Searching for candidate:  38\n",
      "\n",
      "Searching for candidate:  39\n",
      "\n",
      "Searching for candidate:  40\n",
      "\n",
      "Searching for candidate:  41\n",
      "\n",
      "Searching for candidate:  42\n",
      "\n",
      "Searching for candidate:  43\n",
      "\n",
      "Searching for candidate:  44\n",
      "\n",
      "Searching for candidate:  45\n",
      "\n",
      "Searching for candidate:  46\n",
      "\n",
      "Searching for candidate:  47\n",
      "\n",
      "Searching for candidate:  48\n",
      "\n",
      "Searching for candidate:  49\n",
      "\n",
      "Searching for candidate:  50\n",
      "\n",
      "Searching for candidate:  51\n",
      "\n",
      "Searching for candidate:  52\n",
      "\n",
      "Searching for candidate:  53\n",
      "\n",
      "Searching for candidate:  54\n",
      "\n",
      "Searching for candidate:  55\n",
      "\n",
      "Searching for candidate:  56\n",
      "\n",
      "Searching for candidate:  57\n",
      "\n",
      "Searching for candidate:  58\n",
      "\n",
      "Searching for candidate:  59\n",
      "\n",
      "Searching for candidate:  60\n",
      "\n",
      "Searching for candidate:  61\n",
      "\n",
      "Searching for candidate:  62\n",
      "\n",
      "Searching for candidate:  63\n",
      "\n",
      "Searching for candidate:  64\n",
      "\n",
      "Searching for candidate:  65\n",
      "\n",
      "Searching for candidate:  66\n",
      "\n",
      "Searching for candidate:  67\n",
      "\n",
      "Searching for candidate:  68\n",
      "\n",
      "Searching for candidate:  69\n",
      "\n",
      "Searching for candidate:  70\n",
      "\n",
      "Searching for candidate:  71\n",
      "\n",
      "Searching for candidate:  72\n",
      "\n",
      "Searching for candidate:  73\n",
      "\n",
      "Searching for candidate:  74\n",
      "\n",
      "Searching for candidate:  75\n",
      "\n",
      "Searching for candidate:  76\n",
      "\n",
      "Searching for candidate:  77\n",
      "\n",
      "Searching for candidate:  78\n",
      "\n",
      "Searching for candidate:  79\n",
      "\n",
      "Searching for candidate:  80\n",
      "\n",
      "Searching for candidate:  81\n",
      "\n",
      "Searching for candidate:  82\n",
      "\n",
      "Searching for candidate:  83\n",
      "\n",
      "Searching for candidate:  84\n",
      "\n",
      "Searching for candidate:  85\n",
      "\n",
      "Searching for candidate:  86\n",
      "\n",
      "Searching for candidate:  87\n",
      "\n",
      "Searching for candidate:  88\n",
      "\n",
      "Searching for candidate:  89\n",
      "\n",
      "Searching for candidate:  90\n",
      "\n",
      "Searching for candidate:  91\n",
      "\n",
      "Searching for candidate:  92\n",
      "\n",
      "Searching for candidate:  93\n",
      "\n",
      "Searching for candidate:  94\n",
      "\n",
      "Searching for candidate:  95\n",
      "\n",
      "Searching for candidate:  96\n",
      "\n",
      "Searching for candidate:  97\n",
      "\n",
      "Searching for candidate:  98\n",
      "\n",
      "Searching for candidate:  99\n",
      "\n",
      "Searching for candidate:  100\n",
      "\n",
      "Searching for candidate:  101\n",
      "\n",
      "Searching for candidate:  102\n",
      "\n",
      "Searching for candidate:  103\n",
      "\n",
      "Searching for candidate:  104\n",
      "\n",
      "Searching for candidate:  105\n",
      "\n",
      "Searching for candidate:  106\n",
      "\n",
      "Searching for candidate:  107\n",
      "\n",
      "Searching for candidate:  108\n",
      "\n",
      "Searching for candidate:  109\n",
      "\n",
      "Searching for candidate:  110\n",
      "\n",
      "Searching for candidate:  111\n",
      "\n",
      "Searching for candidate:  112\n",
      "\n",
      "Searching for candidate:  113\n",
      "\n",
      "Searching for candidate:  114\n",
      "\n",
      "Searching for candidate:  115\n",
      "\n",
      "Searching for candidate:  116\n",
      "\n",
      "Searching for candidate:  117\n",
      "\n",
      "Searching for candidate:  118\n",
      "\n",
      "Searching for candidate:  119\n",
      "\n",
      "Searching for candidate:  120\n",
      "\n",
      "Searching for candidate:  121\n",
      "\n",
      "Searching for candidate:  122\n",
      "\n",
      "Searching for candidate:  123\n",
      "\n",
      "Searching for candidate:  124\n",
      "\n",
      "Searching for candidate:  125\n",
      "\n",
      "Searching for candidate:  126\n",
      "\n",
      "Searching for candidate:  127\n",
      "\n",
      "Searching for candidate:  128\n",
      "\n",
      "Searching for candidate:  129\n",
      "\n",
      "Searching for candidate:  130\n",
      "\n",
      "Searching for candidate:  131\n",
      "\n",
      "Searching for candidate:  132\n",
      "\n",
      "Searching for candidate:  133\n",
      "\n",
      "Searching for candidate:  134\n",
      "\n",
      "Searching for candidate:  135\n",
      "\n",
      "Searching for candidate:  136\n",
      "\n",
      "Searching for candidate:  137\n",
      "\n",
      "Searching for candidate:  138\n",
      "\n",
      "Searching for candidate:  139\n",
      "\n",
      "Searching for candidate:  140\n",
      "\n",
      "Searching for candidate:  141\n",
      "\n",
      "Searching for candidate:  142\n",
      "\n",
      "Searching for candidate:  143\n",
      "\n",
      "Searching for candidate:  144\n",
      "\n",
      "Searching for candidate:  145\n",
      "\n",
      "Searching for candidate:  146\n",
      "\n",
      "Searching for candidate:  147\n",
      "\n",
      "Searching for candidate:  148\n",
      "\n",
      "Searching for candidate:  149\n",
      "\n",
      "Searching for candidate:  150\n",
      "\n",
      "Searching for candidate:  151\n",
      "\n",
      "Searching for candidate:  152\n",
      "\n",
      "Searching for candidate:  153\n",
      "\n",
      "Searching for candidate:  154\n",
      "\n",
      "Searching for candidate:  155\n",
      "\n",
      "Searching for candidate:  156\n",
      "\n",
      "Searching for candidate:  157\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching for candidate:  158\n",
      "\n",
      "Searching for candidate:  159\n",
      "\n",
      "Searching for candidate:  160\n",
      "\n",
      "Searching for candidate:  161\n",
      "\n",
      "Searching for candidate:  162\n",
      "\n",
      "Searching for candidate:  163\n",
      "\n",
      "Searching for candidate:  164\n",
      "\n",
      "Searching for candidate:  165\n",
      "\n",
      "Searching for candidate:  166\n",
      "\n",
      "Searching for candidate:  167\n",
      "\n",
      "Searching for candidate:  168\n",
      "\n",
      "Searching for candidate:  169\n",
      "\n",
      "Searching for candidate:  170\n",
      "\n",
      "Searching for candidate:  171\n",
      "\n",
      "Searching for candidate:  172\n",
      "\n",
      "Searching for candidate:  173\n",
      "\n",
      "Searching for candidate:  174\n",
      "\n",
      "Searching for candidate:  175\n",
      "\n",
      "Searching for candidate:  176\n",
      "\n",
      "Searching for candidate:  177\n",
      "\n",
      "Searching for candidate:  178\n",
      "\n",
      "Searching for candidate:  179\n",
      "\n",
      "Searching for candidate:  180\n",
      "\n",
      "Searching for candidate:  181\n",
      "\n",
      "Searching for candidate:  182\n",
      "\n",
      "Searching for candidate:  183\n",
      "\n",
      "Searching for candidate:  184\n",
      "\n",
      "Searching for candidate:  185\n",
      "\n",
      "Searching for candidate:  186\n",
      "\n",
      "Searching for candidate:  187\n",
      "\n",
      "Searching for candidate:  188\n",
      "\n",
      "Searching for candidate:  189\n",
      "\n",
      "Searching for candidate:  190\n",
      "\n",
      "Searching for candidate:  191\n",
      "\n",
      "Searching for candidate:  192\n",
      "\n",
      "Searching for candidate:  193\n",
      "\n",
      "Searching for candidate:  194\n",
      "\n",
      "\n",
      "Total clustering time:  430.7172583999927\n",
      "Process: sample; Metric: z_score; Co-cluster ref: combine; Z-score: 0\n",
      "Number of co-clusters:  81\n",
      "\n",
      "Overall entropy H: 1.59635361081467\n",
      "Purity: 2.491477272727273\n",
      "AVG relative co-clusters: 3.67±2.14\n",
      "\n",
      "######################################\n",
      "Number of trajectories: 352\n",
      "Number of unique check-ins: 310\n",
      "########################################\n",
      "Number of the most frequent elements:  58\n",
      "Searching for candidate:  1\n",
      "\n",
      "Searching for candidate:  2\n",
      "\n",
      "Searching for candidate:  3\n",
      "\n",
      "Searching for candidate:  4\n",
      "\n",
      "Searching for candidate:  5\n",
      "\n",
      "Searching for candidate:  6\n",
      "\n",
      "Searching for candidate:  7\n",
      "\n",
      "Searching for candidate:  8\n",
      "\n",
      "Searching for candidate:  9\n",
      "\n",
      "Searching for candidate:  10\n",
      "\n",
      "Searching for candidate:  11\n",
      "\n",
      "Searching for candidate:  12\n",
      "\n",
      "Searching for candidate:  13\n",
      "\n",
      "Searching for candidate:  14\n",
      "\n",
      "Searching for candidate:  15\n",
      "\n",
      "Searching for candidate:  16\n",
      "\n",
      "Searching for candidate:  17\n",
      "\n",
      "Searching for candidate:  18\n",
      "\n",
      "Searching for candidate:  19\n",
      "\n",
      "Searching for candidate:  20\n",
      "\n",
      "Searching for candidate:  21\n",
      "\n",
      "Searching for candidate:  22\n",
      "\n",
      "Searching for candidate:  23\n",
      "\n",
      "Searching for candidate:  24\n",
      "\n",
      "Searching for candidate:  25\n",
      "\n",
      "Searching for candidate:  26\n",
      "\n",
      "Searching for candidate:  27\n",
      "\n",
      "Searching for candidate:  28\n",
      "\n",
      "Searching for candidate:  29\n",
      "\n",
      "Searching for candidate:  30\n",
      "\n",
      "Searching for candidate:  31\n",
      "\n",
      "Searching for candidate:  32\n",
      "\n",
      "Searching for candidate:  33\n",
      "\n",
      "Searching for candidate:  34\n",
      "\n",
      "Searching for candidate:  35\n",
      "\n",
      "Searching for candidate:  36\n",
      "\n",
      "Searching for candidate:  37\n",
      "\n",
      "Searching for candidate:  38\n",
      "\n",
      "Searching for candidate:  39\n",
      "\n",
      "Searching for candidate:  40\n",
      "\n",
      "Searching for candidate:  41\n",
      "\n",
      "Searching for candidate:  42\n",
      "\n",
      "Searching for candidate:  43\n",
      "\n",
      "Searching for candidate:  44\n",
      "\n",
      "Searching for candidate:  45\n",
      "\n",
      "Searching for candidate:  46\n",
      "\n",
      "Searching for candidate:  47\n",
      "\n",
      "Searching for candidate:  48\n",
      "\n",
      "Searching for candidate:  49\n",
      "\n",
      "Searching for candidate:  50\n",
      "\n",
      "Searching for candidate:  51\n",
      "\n",
      "Searching for candidate:  52\n",
      "\n",
      "Searching for candidate:  53\n",
      "\n",
      "Searching for candidate:  54\n",
      "\n",
      "Searching for candidate:  55\n",
      "\n",
      "Searching for candidate:  56\n",
      "\n",
      "Searching for candidate:  57\n",
      "\n",
      "Searching for candidate:  58\n",
      "\n",
      "Searching for candidate:  59\n",
      "\n",
      "Searching for candidate:  60\n",
      "\n",
      "Searching for candidate:  61\n",
      "\n",
      "Searching for candidate:  62\n",
      "\n",
      "Searching for candidate:  63\n",
      "\n",
      "Searching for candidate:  64\n",
      "\n",
      "Searching for candidate:  65\n",
      "\n",
      "Searching for candidate:  66\n",
      "\n",
      "Searching for candidate:  67\n",
      "\n",
      "Searching for candidate:  68\n",
      "\n",
      "Searching for candidate:  69\n",
      "\n",
      "Searching for candidate:  70\n",
      "\n",
      "Searching for candidate:  71\n",
      "\n",
      "Searching for candidate:  72\n",
      "\n",
      "Searching for candidate:  73\n",
      "\n",
      "Searching for candidate:  74\n",
      "\n",
      "Searching for candidate:  75\n",
      "\n",
      "Searching for candidate:  76\n",
      "\n",
      "Searching for candidate:  77\n",
      "\n",
      "Searching for candidate:  78\n",
      "\n",
      "Searching for candidate:  79\n",
      "\n",
      "Searching for candidate:  80\n",
      "\n",
      "Searching for candidate:  81\n",
      "\n",
      "Searching for candidate:  82\n",
      "\n",
      "Searching for candidate:  83\n",
      "\n",
      "Searching for candidate:  84\n",
      "\n",
      "Searching for candidate:  85\n",
      "\n",
      "Searching for candidate:  86\n",
      "\n",
      "Searching for candidate:  87\n",
      "\n",
      "Searching for candidate:  88\n",
      "\n",
      "Searching for candidate:  89\n",
      "\n",
      "Searching for candidate:  90\n",
      "\n",
      "Searching for candidate:  91\n",
      "\n",
      "Searching for candidate:  92\n",
      "\n",
      "Searching for candidate:  93\n",
      "\n",
      "Searching for candidate:  94\n",
      "\n",
      "Searching for candidate:  95\n",
      "\n",
      "Searching for candidate:  96\n",
      "\n",
      "Searching for candidate:  97\n",
      "\n",
      "Searching for candidate:  98\n",
      "\n",
      "Searching for candidate:  99\n",
      "\n",
      "Searching for candidate:  100\n",
      "\n",
      "Searching for candidate:  101\n",
      "\n",
      "Searching for candidate:  102\n",
      "\n",
      "Searching for candidate:  103\n",
      "\n",
      "Searching for candidate:  104\n",
      "\n",
      "Searching for candidate:  105\n",
      "\n",
      "Searching for candidate:  106\n",
      "\n",
      "Searching for candidate:  107\n",
      "\n",
      "Searching for candidate:  108\n",
      "\n",
      "Searching for candidate:  109\n",
      "\n",
      "Searching for candidate:  110\n",
      "\n",
      "Searching for candidate:  111\n",
      "\n",
      "Searching for candidate:  112\n",
      "\n",
      "Searching for candidate:  113\n",
      "\n",
      "Searching for candidate:  114\n",
      "\n",
      "Searching for candidate:  115\n",
      "\n",
      "Searching for candidate:  116\n",
      "\n",
      "Searching for candidate:  117\n",
      "\n",
      "Searching for candidate:  118\n",
      "\n",
      "Searching for candidate:  119\n",
      "\n",
      "Searching for candidate:  120\n",
      "\n",
      "Searching for candidate:  121\n",
      "\n",
      "Searching for candidate:  122\n",
      "\n",
      "Searching for candidate:  123\n",
      "\n",
      "Searching for candidate:  124\n",
      "\n",
      "Searching for candidate:  125\n",
      "\n",
      "Searching for candidate:  126\n",
      "\n",
      "Searching for candidate:  127\n",
      "\n",
      "Searching for candidate:  128\n",
      "\n",
      "Searching for candidate:  129\n",
      "\n",
      "Searching for candidate:  130\n",
      "\n",
      "Searching for candidate:  131\n",
      "\n",
      "Searching for candidate:  132\n",
      "\n",
      "Searching for candidate:  133\n",
      "\n",
      "Searching for candidate:  134\n",
      "\n",
      "Searching for candidate:  135\n",
      "\n",
      "Searching for candidate:  136\n",
      "\n",
      "Searching for candidate:  137\n",
      "\n",
      "Searching for candidate:  138\n",
      "\n",
      "Searching for candidate:  139\n",
      "\n",
      "Searching for candidate:  140\n",
      "\n",
      "Searching for candidate:  141\n",
      "\n",
      "Searching for candidate:  142\n",
      "\n",
      "Searching for candidate:  143\n",
      "\n",
      "Searching for candidate:  144\n",
      "\n",
      "Searching for candidate:  145\n",
      "\n",
      "Searching for candidate:  146\n",
      "\n",
      "Searching for candidate:  147\n",
      "\n",
      "Searching for candidate:  148\n",
      "\n",
      "Searching for candidate:  149\n",
      "\n",
      "Searching for candidate:  150\n",
      "\n",
      "Searching for candidate:  151\n",
      "\n",
      "Searching for candidate:  152\n",
      "\n",
      "Searching for candidate:  153\n",
      "\n",
      "Searching for candidate:  154\n",
      "\n",
      "Searching for candidate:  155\n",
      "\n",
      "Searching for candidate:  156\n",
      "\n",
      "Searching for candidate:  157\n",
      "\n",
      "Searching for candidate:  158\n",
      "\n",
      "Searching for candidate:  159\n",
      "\n",
      "Searching for candidate:  160\n",
      "\n",
      "Searching for candidate:  161\n",
      "\n",
      "Searching for candidate:  162\n",
      "\n",
      "Searching for candidate:  163\n",
      "\n",
      "Searching for candidate:  164\n",
      "\n",
      "Searching for candidate:  165\n",
      "\n",
      "Searching for candidate:  166\n",
      "\n",
      "Searching for candidate:  167\n",
      "\n",
      "Searching for candidate:  168\n",
      "\n",
      "Searching for candidate:  169\n",
      "\n",
      "Searching for candidate:  170\n",
      "\n",
      "Searching for candidate:  171\n",
      "\n",
      "Searching for candidate:  172\n",
      "\n",
      "Searching for candidate:  173\n",
      "\n",
      "Searching for candidate:  174\n",
      "\n",
      "Searching for candidate:  175\n",
      "\n",
      "Searching for candidate:  176\n",
      "\n",
      "Searching for candidate:  177\n",
      "\n",
      "Searching for candidate:  178\n",
      "\n",
      "Searching for candidate:  179\n",
      "\n",
      "Searching for candidate:  180\n",
      "\n",
      "Searching for candidate:  181\n",
      "\n",
      "Searching for candidate:  182\n",
      "\n",
      "Searching for candidate:  183\n",
      "\n",
      "Searching for candidate:  184\n",
      "\n",
      "Searching for candidate:  185\n",
      "\n",
      "Searching for candidate:  186\n",
      "\n",
      "Searching for candidate:  187\n",
      "\n",
      "Searching for candidate:  188\n",
      "\n",
      "Searching for candidate:  189\n",
      "\n",
      "Searching for candidate:  190\n",
      "\n",
      "Searching for candidate:  191\n",
      "\n",
      "Searching for candidate:  192\n",
      "\n",
      "Searching for candidate:  193\n",
      "\n",
      "Searching for candidate:  194\n",
      "\n",
      "\n",
      "Total clustering time:  448.3606426999904\n",
      "Process: sample; Metric: z_score; Co-cluster ref: combine; Z-score: 1\n",
      "Number of co-clusters:  33\n",
      "\n",
      "Overall entropy H: 1.0230999684127997\n",
      "Purity: 1.4090909090909092\n",
      "AVG relative co-clusters: 5.23±2.51\n",
      "\n"
     ]
    }
   ],
   "source": [
    "VERBOSE = False\n",
    "k = -1 #max number of co-cluster that could be found. -1: default [driven by cost function]\n",
    "e_obj = 0 # maximum error tolerance for object. -1: default [accept the maximum error]\n",
    "e_att = 0\n",
    "element_analysis = True\n",
    "cc_prune_ref = 'rows' # 1. 'rows'; 2. 'cost'; 3. 'combine'\n",
    "cc_ref_list = ['rows','cost','combine']\n",
    "cc_type_process = 'sample' # 1. incremental [evaluate the candidate during the process]; 2. sample [consider the set of candidates]\n",
    "cc_type_analysis = 'z_score' # # 1. mean; 2. z_score\n",
    "metric_stat_list = ['mean','z_score']\n",
    "#Rows and cost are inverse among them.\n",
    "#Rows grow positively while cost negatively.\n",
    "cc_z_threshold_r = -1 #e.g., -1, we want the right-side, so we keep values equal or bigger than 1 sd bellow the avg\n",
    "cc_z_threshold_c = 1 #e.g., 1, we want the left-side, so we keep values equal or smaller than 1 sd above the avg\n",
    "# cc_z_threshold\n",
    "z_thres_list = [-1,0,1]\n",
    "\n",
    "# input_data_pd = pd.read_csv(\"./data/toy_example/toy2_traj.dat\", header=None, names=[\"transation\"])\n",
    "# input_data_pd = pd.read_csv(\"./data/real_application/foursquare_NY/fs_ny_week_sequences.dat\", header=None, names=[\"transation\"])\n",
    "# input_data_pd = pd.read_csv(\"./data/real_application/foursquare_NY/preprocessed/fs_ny_top_10_week_sequences.dat\", header=None, names=[\"transation\"])\n",
    "\n",
    "# input_data_pd = './data/toy_example/toy2_traj.dat'\n",
    "# input_data_pd = './data/real_application/foursquare_NY/fs_ny_week_sequences.dat'\n",
    "# input_data_pd = './data/real_application/foursquare_NY/preprocessed/fs_ny_top_10_week_sequences.dat'\n",
    "# path = './data/real_application/foursquare_NY/preprocessed/'\n",
    "datasets = ['fs_ny_top_users_193.dat','fs_ny_top_users_81.dat','fs_ny_top_users_10.dat']\n",
    "clustering_perf = Performance()\n",
    "# D,co_clusters = TRACOCLUS(input_data_pd,cc_prune_ref,k,e_obj,e_att)\n",
    "for i in range(2,len(datasets)):\n",
    "    print(datasets[i])\n",
    "    for cc_prune_ref in cc_ref_list:\n",
    "        if cc_type_analysis == 'mean':\n",
    "            D,co_clusters = TRACOCLUS(datasets[i],cc_prune_ref,k,e_obj,e_att)\n",
    "        else:\n",
    "            for cc_z_threshold in z_thres_list:\n",
    "                D,co_clusters = TRACOCLUS(datasets[i],cc_prune_ref,k,e_obj,e_att)\n",
    "# TRACOCLUS(input_data_pd,k,e_obj,e_att)\n",
    "# print('\\nNumber of found co-clusters: ',len(co_clusters))\n",
    "# print('Final co-clusters: ',co_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0 [Absolute:22 | Relative:0.06 | Cost: -41 | Oc: 0.00]\n",
      "Attributes sequence \"Home_(private)-Metro_Station-Metro_Station\" and trajectories \"'71', '44', '54', '49', '297', '51', '73', '61',[...]\".\n",
      "\n",
      "Cluster 1 [Absolute:15 | Relative:0.04 | Cost: -19 | Oc: 0.14]\n",
      "Attributes sequence \"Metro_Station-Metro_Station-Home_(private)\" and trajectories \"'289', '315', '286', '290', '309', '54', '75', '43',[...]\".\n",
      "\n",
      "Cluster 2 [Absolute:36 | Relative:0.10 | Cost: -30 | Oc: 0.07]\n",
      "Attributes sequence \"Deli_/_Bodega-Metro_Station\" and trajectories \"'315', '77', '304', '73', '79', '61', '64', '311',[...]\".\n",
      "\n",
      "Cluster 4 [Absolute:8 | Relative:0.02 | Cost: -27 | Oc: 0.00]\n",
      "Attributes sequence \"Metro_Station-Metro_Station-Metro_Station-Metro_Station-Office\" and trajectories \"'162', '164', '158', '156', '159', '157', '160', '163'\".\n",
      "\n",
      "Cluster 7 [Absolute:12 | Relative:0.03 | Cost: -14 | Oc: 0.05]\n",
      "Attributes sequence \"Metro_Station-Park-Convenience_Store\" and trajectories \"'71', '64', '74', '72', '77', '43', '81', '45',[...]\".\n",
      "\n",
      "Cluster 8 [Absolute:8 | Relative:0.02 | Cost: -8 | Oc: 0.05]\n",
      "Attributes sequence \"Metro_Station-Pizza_Place-Bakery\" and trajectories \"'69', '70', '64', '62', '82', '66', '79', '55'\".\n",
      "\n",
      "Cluster 10 [Absolute:12 | Relative:0.03 | Cost: -3 | Oc: 0.11]\n",
      "Attributes sequence \"Bank-Metro_Station\" and trajectories \"'289', '313', '167', '161', '49', '43', '188', '184',[...]\".\n",
      "\n",
      "Cluster 12 [Absolute:19 | Relative:0.05 | Cost: -12 | Oc: 0.06]\n",
      "Attributes sequence \"Building-Metro_Station\" and trajectories \"'315', '286', '305', '294', '298', '295', '155', '312',[...]\".\n",
      "\n",
      "Cluster 13 [Absolute:10 | Relative:0.03 | Cost: -11 | Oc: 0.07]\n",
      "Attributes sequence \"Metro_Station-Building-Coffee_Shop\" and trajectories \"'289', '313', '299', '303', '311', '290', '288', '308',[...]\".\n",
      "\n",
      "Cluster 15 [Absolute:12 | Relative:0.03 | Cost: -13 | Oc: 0.07]\n",
      "Attributes sequence \"Metro_Station-Coffee_Shop-Building\" and trajectories \"'289', '301', '286', '290', '309', '305', '292', '304',[...]\".\n",
      "\n",
      "Cluster 16 [Absolute:19 | Relative:0.05 | Cost: -21 | Oc: 0.29]\n",
      "Attributes sequence \"Metro_Station-Metro_Station-Fast_Food_Restaurant\" and trajectories \"'168', '172', '176', '184', '173', '158', '157', '174',[...]\".\n",
      "\n",
      "Cluster 18 [Absolute:17 | Relative:0.05 | Cost: -26 | Oc: 0.41]\n",
      "Attributes sequence \"IT_Services-Metro_Station-Metro_Station-Metro_Station-Metro_Station\" and trajectories \"'171', '158', '157', '155', '160', '163', '169', '180',[...]\".\n",
      "\n",
      "Cluster 20 [Absolute:19 | Relative:0.05 | Cost: -14 | Oc: 0.14]\n",
      "Attributes sequence \"Metro_Station-Metro_Station-Train\" and trajectories \"'176', '175', '73', '79', '60', '157', '160', '61',[...]\".\n",
      "\n",
      "Cluster 22 [Absolute:15 | Relative:0.04 | Cost: -21 | Oc: 0.05]\n",
      "Attributes sequence \"Deli_/_Bodega-Home_(private)-Home_(private)\" and trajectories \"'69', '70', '50', '63', '75', '72', '77', '82',[...]\".\n",
      "\n",
      "Cluster 25 [Absolute:34 | Relative:0.10 | Cost: -29 | Oc: 0.20]\n",
      "Attributes sequence \"Home_(private)-Office\" and trajectories \"'319', '29', '330', '348', '337', '342', '324', '320',[...]\".\n",
      "\n",
      "Cluster 26 [Absolute:37 | Relative:0.11 | Cost: -27 | Oc: 0.05]\n",
      "Attributes sequence \"Chinese_Restaurant-Deli_/_Bodega\" and trajectories \"'102', '315', '106', '87', '119', '109', '105', '91',[...]\".\n",
      "\n",
      "Cluster 27 [Absolute:20 | Relative:0.06 | Cost: -14 | Oc: 0.08]\n",
      "Attributes sequence \"Office-Home_(private)\" and trajectories \"'319', '330', '339', '344', '36', '318', '328', '322',[...]\".\n",
      "\n",
      "Cluster 28 [Absolute:14 | Relative:0.04 | Cost: -10 | Oc: 0.13]\n",
      "Attributes sequence \"Home_(private)-Chinese_Restaurant-Home_(private)\" and trajectories \"'70', '71', '56', '74', '72', '62', '81', '58',[...]\".\n",
      "\n",
      "Cluster 29 [Absolute:22 | Relative:0.06 | Cost: -18 | Oc: 0.13]\n",
      "Attributes sequence \"Office-Hotel\" and trajectories \"'265', '41', '5', '35', '37', '279', '270', '3',[...]\".\n",
      "\n",
      "Cluster 31 [Absolute:8 | Relative:0.02 | Cost: -5 | Oc: 0.06]\n",
      "Attributes sequence \"Office-Deli_/_Bodega\" and trajectories \"'220', '93', '190', '206', '202', '208', '214', '198'\".\n",
      "\n",
      "Cluster 32 [Absolute:8 | Relative:0.02 | Cost: -5 | Oc: 0.04]\n",
      "Attributes sequence \"Home_(private)-American_Restaurant\" and trajectories \"'319', '344', '32', '42', '13', '14', '325', '1'\".\n",
      "\n",
      "Cluster 34 [Absolute:10 | Relative:0.03 | Cost: -1 | Oc: 0.10]\n",
      "Attributes sequence \"Park-Deli_/_Bodega\" and trajectories \"'56', '74', '75', '72', '98', '60', '55', '78',[...]\".\n",
      "\n",
      "Cluster 36 [Absolute:14 | Relative:0.04 | Cost: -10 | Oc: 0.03]\n",
      "Attributes sequence \"Park-Home_(private)\" and trajectories \"'329', '32', '30', '5', '321', '62', '348', '76',[...]\".\n",
      "\n",
      "Cluster 37 [Absolute:42 | Relative:0.12 | Cost: -33 | Oc: 0.09]\n",
      "Attributes sequence \"American_Restaurant-Hotel\" and trajectories \"'29', '247', '250', '237', '241', '3', '252', '1',[...]\".\n",
      "\n",
      "Cluster 38 [Absolute:11 | Relative:0.03 | Cost: -11 | Oc: 0.09]\n",
      "Attributes sequence \"Deli_/_Bodega-Deli_/_Bodega-Pizza_Place\" and trajectories \"'69', '74', '72', '77', '152', '88', '76', '79',[...]\".\n",
      "\n",
      "Cluster 39 [Absolute:8 | Relative:0.02 | Cost: -3 | Oc: 0.04]\n",
      "Attributes sequence \"Home_(private)-Pizza_Place\" and trajectories \"'71', '144', '56', '36', '75', '49', '202', '79'\".\n",
      "\n",
      "Cluster 40 [Absolute:9 | Relative:0.03 | Cost: -2 | Oc: 0.15]\n",
      "Attributes sequence \"Building-Home_(private)\" and trajectories \"'351', '29', '311', '309', '218', '33', '295', '38', '314'\".\n",
      "\n",
      "Cluster 42 [Absolute:11 | Relative:0.03 | Cost: -15 | Oc: 0.14]\n",
      "Attributes sequence \"Smoke_Shop-Bus_Line-Home_(private)-Home_(private)\" and trajectories \"'50', '52', '48', '44', '43', '51', '42', '45',[...]\".\n",
      "\n",
      "Cluster 43 [Absolute:10 | Relative:0.03 | Cost: -5 | Oc: 0.06]\n",
      "Attributes sequence \"Gas_Station-Deli_/_Bodega\" and trajectories \"'106', '94', '87', '92', '93', '86', '103', '96',[...]\".\n",
      "\n",
      "Cluster 44 [Absolute:13 | Relative:0.04 | Cost: -5 | Oc: 0.09]\n",
      "Attributes sequence \"Deli_/_Bodega-Residential_Building_(Apartment_/_Condo)\" and trajectories \"'129', '127', '130', '71', '74', '72', '77', '62',[...]\".\n",
      "\n",
      "Cluster 45 [Absolute:12 | Relative:0.03 | Cost: -20 | Oc: 0.02]\n",
      "Attributes sequence \"Bank-Hotel-Plaza\" and trajectories \"'281', '265', '285', '277', '278', '269', '266', '282',[...]\".\n",
      "\n",
      "Cluster 48 [Absolute:17 | Relative:0.05 | Cost: -10 | Oc: 0.07]\n",
      "Attributes sequence \"Park-Hotel\" and trajectories \"'2', '10', '35', '16', '23', '27', '3', '7',[...]\".\n",
      "\n",
      "Cluster 49 [Absolute:8 | Relative:0.02 | Cost: -15 | Oc: 0.07]\n",
      "Attributes sequence \"Deli_/_Bodega-Bus_Line-Home_(private)-Home_(private)\" and trajectories \"'56', '59', '44', '58', '55', '57', '47', '61'\".\n",
      "\n",
      "Cluster 50 [Absolute:8 | Relative:0.02 | Cost: -1 | Oc: 0.11]\n",
      "Attributes sequence \"Bus_Line-Deli_/_Bodega\" and trajectories \"'112', '70', '49', '98', '88', '300', '55', '47'\".\n",
      "\n",
      "Cluster 56 [Absolute:14 | Relative:0.04 | Cost: -6 | Oc: 0.14]\n",
      "Attributes sequence \"Home_(private)-Bar\" and trajectories \"'201', '351', '347', '339', '327', '328', '322', '343',[...]\".\n",
      "\n",
      "Cluster 61 [Absolute:13 | Relative:0.04 | Cost: -44 | Oc: 0.02]\n",
      "Attributes sequence \"Nightclub-Nightclub-Music_Venue-Hotel-Hotel\" and trajectories \"'228', '222', '231', '247', '251', '250', '230', '224',[...]\".\n",
      "\n",
      "Cluster 62 [Absolute:8 | Relative:0.02 | Cost: -12 | Oc: 0.03]\n",
      "Attributes sequence \"Residential_Building_(Apartment_/_Condo)-School-Deli_/_Bodega\" and trajectories \"'153', '127', '130', '126', '123', '152', '145', '147'\".\n",
      "\n",
      "Cluster 64 [Absolute:10 | Relative:0.03 | Cost: -2 | Oc: 0.06]\n",
      "Attributes sequence \"Home_(private)-Grocery_Store\" and trajectories \"'135', '59', '81', '45', '60', '55', '216', '51',[...]\".\n",
      "\n",
      "Cluster 69 [Absolute:10 | Relative:0.03 | Cost: -2 | Oc: 0.13]\n",
      "Attributes sequence \"Bus_Line-Hotel\" and trajectories \"'5', '22', '11', '4', '33', '14', '21', '6',[...]\".\n",
      "\n",
      "Cluster 72 [Absolute:15 | Relative:0.04 | Cost: -37 | Oc: 0.05]\n",
      "Attributes sequence \"Hotel-Hotel-Airport-Gourmet_Shop\" and trajectories \"'232', '228', '240', '225', '231', '233', '224', '237',[...]\".\n",
      "\n",
      "Cluster 75 [Absolute:30 | Relative:0.09 | Cost: -21 | Oc: 0.09]\n",
      "Attributes sequence \"Chinese_Restaurant-Pizza_Place\" and trajectories \"'112', '87', '92', '109', '115', '110', '120', '91',[...]\".\n",
      "\n",
      "Cluster 77 [Absolute:23 | Relative:0.07 | Cost: -17 | Oc: 0.04]\n",
      "Attributes sequence \"Office-Bank\" and trajectories \"'281', '136', '277', '275', '123', '41', '5', '35',[...]\".\n",
      "\n",
      "Cluster 81 [Absolute:13 | Relative:0.04 | Cost: -4 | Oc: 0.10]\n",
      "Attributes sequence \"Office-American_Restaurant\" and trajectories \"'9', '15', '29', '136', '341', '25', '16', '33',[...]\".\n",
      "\n",
      "Cluster 82 [Absolute:13 | Relative:0.04 | Cost: -14 | Oc: 0.13]\n",
      "Attributes sequence \"Chinese_Restaurant-Chinese_Restaurant-Gas_Station\" and trajectories \"'102', '106', '109', '85', '100', '86', '96', '91',[...]\".\n",
      "\n",
      "Cluster 84 [Absolute:9 | Relative:0.03 | Cost: -14 | Oc: 0.12]\n",
      "Attributes sequence \"Hotel-Hotel-Gourmet_Shop-American_Restaurant\" and trajectories \"'254', '240', '230', '250', '239', '224', '223', '236', '248'\".\n",
      "\n",
      "Cluster 89 [Absolute:17 | Relative:0.05 | Cost: -4 | Oc: 0.20]\n",
      "Attributes sequence \"Gourmet_Shop-Hotel\" and trajectories \"'228', '225', '247', '250', '241', '244', '232', '222',[...]\".\n",
      "\n",
      "Cluster 91 [Absolute:16 | Relative:0.05 | Cost: -15 | Oc: 0.12]\n",
      "Attributes sequence \"Plaza-Residential_Building_(Apartment_/_Condo)-Office\" and trajectories \"'281', '265', '258', '270', '271', '261', '264', '273',[...]\".\n",
      "\n",
      "Cluster 92 [Absolute:17 | Relative:0.05 | Cost: -7 | Oc: 0.10]\n",
      "Attributes sequence \"Chinese_Restaurant-Supermarket\" and trajectories \"'102', '106', '112', '122', '143', '119', '109', '105',[...]\".\n",
      "\n",
      "Cluster 98 [Absolute:9 | Relative:0.03 | Cost: -14 | Oc: 0.15]\n",
      "Attributes sequence \"Residential_Building_(Apartment_/_Condo)-Office-Pub-Bank\" and trajectories \"'265', '264', '278', '275', '269', '266', '268', '280', '270'\".\n",
      "\n",
      "Cluster 101 [Absolute:12 | Relative:0.03 | Cost: -3 | Oc: 0.08]\n",
      "Attributes sequence \"American_Restaurant-Park\" and trajectories \"'15', '29', '22', '10', '328', '0', '23', '13',[...]\".\n",
      "\n",
      "Cluster 104 [Absolute:8 | Relative:0.02 | Cost: -1 | Oc: 0.17]\n",
      "Attributes sequence \"Office-Post_Office\" and trajectories \"'319', '36', '344', '323', '327', '328', '340', '338'\".\n",
      "\n",
      "Cluster 106 [Absolute:11 | Relative:0.03 | Cost: -4 | Oc: 0.10]\n",
      "Attributes sequence \"Park-Building\" and trajectories \"'135', '29', '165', '292', '294', '151', '297', '298',[...]\".\n",
      "\n",
      "Cluster 111 [Absolute:19 | Relative:0.05 | Cost: -6 | Oc: 0.12]\n",
      "Attributes sequence \"Gas_Station-Pizza_Place\" and trajectories \"'106', '104', '92', '109', '123', '115', '105', '10',[...]\".\n",
      "\n",
      "Cluster 114 [Absolute:9 | Relative:0.03 | Cost: -5 | Oc: 0.06]\n",
      "Attributes sequence \"Park-Music_Venue\" and trajectories \"'9', '29', '5', '22', '4', '3', '14', '21', '1'\".\n",
      "\n",
      "Cluster 120 [Absolute:26 | Relative:0.07 | Cost: -11 | Oc: 0.09]\n",
      "Attributes sequence \"American_Restaurant-Music_Venue\" and trajectories \"'2', '228', '225', '231', '247', '16', '224', '246',[...]\".\n",
      "\n",
      "Cluster 127 [Absolute:13 | Relative:0.04 | Cost: -7 | Oc: 0.07]\n",
      "Attributes sequence \"Gas_Station-Salon_/_Barbershop\" and trajectories \"'87', '104', '119', '115', '110', '98', '90', '111',[...]\".\n",
      "\n",
      "Cluster 128 [Absolute:8 | Relative:0.02 | Cost: -1 | Oc: 0.12]\n",
      "Attributes sequence \"Pizza_Place-Smoke_Shop\" and trajectories \"'69', '56', '54', '49', '43', '60', '79', '68'\".\n",
      "\n",
      "Cluster 130 [Absolute:8 | Relative:0.02 | Cost: -1 | Oc: 0.11]\n",
      "Attributes sequence \"Park-Speakeasy\" and trajectories \"'29', '25', '40', '0', '3', '7', '14', '18'\".\n",
      "\n",
      "Cluster 132 [Absolute:8 | Relative:0.02 | Cost: -8 | Oc: 0.17]\n",
      "Attributes sequence \"Bank-Bank-Donut_Shop\" and trajectories \"'261', '256', '263', '258', '259', '262', '257', '260'\".\n",
      "\n",
      "Cluster 139 [Absolute:10 | Relative:0.03 | Cost: -15 | Oc: 0.04]\n",
      "Attributes sequence \"Park-Radio_Station-Cafeteria\" and trajectories \"'50', '71', '52', '70', '61', '54', '51', '68',[...]\".\n",
      "\n",
      "Cluster 144 [Absolute:8 | Relative:0.02 | Cost: -2 | Oc: 0.18]\n",
      "Attributes sequence \"Gas_Station-Donut_Shop\" and trajectories \"'143', '151', '128', '142', '124', '146', '342', '140'\".\n",
      "\n",
      "Cluster 151 [Absolute:13 | Relative:0.04 | Cost: -9 | Oc: 0.06]\n",
      "Attributes sequence \"Park-Paper_/_Office_Supplies_Store\" and trajectories \"'69', '50', '63', '56', '48', '44', '62', '42',[...]\".\n",
      "\n",
      "Cluster 153 [Absolute:9 | Relative:0.03 | Cost: -3 | Oc: 0.09]\n",
      "Attributes sequence \"Residential_Building_(Apartment_/_Condo)-Bank\" and trajectories \"'281', '265', '284', '261', '278', '282', '280', '271', '260'\".\n",
      "\n",
      "Cluster 159 [Absolute:9 | Relative:0.03 | Cost: -3 | Oc: 0.07]\n",
      "Attributes sequence \"Fast_Food_Restaurant-IT_Services\" and trajectories \"'180', '183', '177', '176', '159', '185', '170', '178', '160'\".\n",
      "\n",
      "Cluster 166 [Absolute:10 | Relative:0.03 | Cost: -3 | Oc: 0.07]\n",
      "Attributes sequence \"Beach-Fast_Food_Restaurant\" and trajectories \"'167', '162', '163', '176', '175', '158', '157', '170',[...]\".\n",
      "\n",
      "Cluster 170 [Absolute:10 | Relative:0.03 | Cost: -1 | Oc: 0.14]\n",
      "Attributes sequence \"Laundry_Service-Supermarket\" and trajectories \"'106', '112', '114', '119', '110', '113', '111', '108',[...]\".\n",
      "\n",
      "Cluster 171 [Absolute:9 | Relative:0.03 | Cost: -2 | Oc: 0.18]\n",
      "Attributes sequence \"Other_Nightlife-Music_Venue\" and trajectories \"'2', '41', '12', '0', '19', '3', '7', '6', '1'\".\n",
      "\n",
      "Cluster 178 [Absolute:10 | Relative:0.03 | Cost: -3 | Oc: 0.07]\n",
      "Attributes sequence \"Speakeasy-Strip_Club\" and trajectories \"'9', '15', '29', '2', '22', '11', '23', '7',[...]\".\n",
      "\n",
      "Cluster 181 [Absolute:8 | Relative:0.02 | Cost: -2 | Oc: 0.08]\n",
      "Attributes sequence \"Airport-Nightclub\" and trajectories \"'225', '240', '243', '230', '250', '233', '237', '253'\".\n",
      "\n",
      "Cluster 184 [Absolute:8 | Relative:0.02 | Cost: -6 | Oc: 0.00]\n",
      "Attributes sequence \"Other_Nightlife-Cocktail_Bar\" and trajectories \"'20', '29', '41', '22', '37', '23', '13', '31'\".\n",
      "\n",
      "Cluster 187 [Absolute:10 | Relative:0.03 | Cost: -2 | Oc: 0.17]\n",
      "Attributes sequence \"Garden-Caribbean_Restaurant\" and trajectories \"'106', '112', '114', '105', '110', '113', '116', '108',[...]\".\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# clustering_perf.test_norm_dist()\n",
    "# clustering_perf.test_skewness()\n",
    "# df = pd.read_csv('data/real_application/foursquare_NY/fs_ny_top_users_10.csv', sep=\";\")\n",
    "# clustering_perf.analysis_entropy_purity(create_df_map_traj_user(df))\n",
    "clustering_perf.get_clusters()\n",
    "# clustering_perf.show_boxplot()\n",
    "# clustering_perf.plot_cost()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O valor da estatística de shapiro-wilk = 0.9266944527626038\n",
      "O valor do p-value de shapiro-wilk = 0.4161774218082428\n",
      "0.17709753067016487\n",
      "0.9123891112746063\n"
     ]
    }
   ],
   "source": [
    "import scipy.stats as stats\n",
    "y = [1.90642, 2.22488, 2.10288, 1.69742, 1.52229, 3.15435, 2.61826, 1.98492, 1.42738, 1.99568]\n",
    "shapiro_stat, shapiro_p_valor = stats.shapiro(y)\n",
    "print('O valor da estatística de shapiro-wilk = '+str(shapiro_stat))\n",
    "print('O valor do p-value de shapiro-wilk = '+str(shapiro_p_valor))\n",
    "mean = np.mean(y)\n",
    "std = np.std(y,ddof=1)\n",
    "ks_stat, ks_p_value = stats.kstest(y,cdf='norm',args=(mean,std), N=len(y))\n",
    "print(ks_stat)\n",
    "print(ks_p_value)\n",
    "# a = [-4,-3,-2,-1,0,1,2,3,4]\n",
    "# print(np.mean(a),np.std(a))\n",
    "# print('Número de desvios padrões (Z-score): ',(1.5-np.mean(a)/np.std(a)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "def populate_queue(poi_freq_dict):\n",
    "#     print([{k:v} for k,v in poi_freq_dict.items()])\n",
    "    queue = deque()\n",
    "    [queue.append([k,v]) for k,v in poi_freq_dict.items()]\n",
    "    return queue  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_sequence(trajectory_dataset_dict_list, candidate_trajectories_sequence_set, test_traj_sequence):\n",
    "    '''This method receive 3 parameters: \n",
    "       1) trajectory dataset as a dict->list | x['key']:[...];\n",
    "       2) trajectories indeces that contains the tested check-ins as a set;\n",
    "       3) the given tested sequence of check-ins as a string\n",
    "    '''\n",
    "    new_set_trajectories = set()\n",
    "    position_pois_per_traj_list = {}\n",
    "#     test_traj_sequence = test_traj_sequence.strip()\n",
    "    # we will test if the test_traj_sequence exist in the candidate_trajectories that contains the elements.\n",
    "    for traj_id in candidate_trajectories_sequence_set:\n",
    "\n",
    "        try:\n",
    "#             traj_dataset = '-'.join(trajectory_dataset_dict_list[traj_id]).strip()\n",
    "            test_subsequence, positions_at_traj = is_subsequence(trajectory_dataset_dict_list[traj_id],test_traj_sequence.split('-'))\n",
    "            if test_subsequence:\n",
    "#                 print('OK->',end=' ')\n",
    "#                 print(traj_id,positions_at_traj)\n",
    "                new_set_trajectories.add(traj_id)\n",
    "                position_pois_per_traj_list[traj_id] = positions_at_traj\n",
    "        except Exception as error:\n",
    "            print(error)\n",
    "#         print('{}-> {}'.format(traj_id,trajectory_dataset_dict_list[traj_id]))\n",
    "#     print('Sequence \"{}\" is present in trajectories: {}'.format(test_traj_sequence,new_set_trajectories))\n",
    "    return new_set_trajectories, position_pois_per_traj_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_subsequence(sequence, subsequence):\n",
    "    '''This sub method receive two arrays: \n",
    "       first one is the sequence and second one is the tested subsequence.'''\n",
    "    n = len(sequence)\n",
    "    m = len(subsequence)\n",
    "    position_poi_sequence = []\n",
    "    \n",
    "    # Two pointers to traverse the arrays\n",
    "    i = 0; j = 0;\n",
    " \n",
    "    # Traverse both arrays simultaneously\n",
    "    while (i < n and j < m):\n",
    " \n",
    "        # If element matches\n",
    "        # increment both pointers\n",
    "        if (sequence[i] == subsequence[j]):\n",
    "            position_poi_sequence.append(str(i))\n",
    "            i += 1\n",
    "            j += 1\n",
    " \n",
    "            # If subsequence is completely\n",
    "            # traversed\n",
    "            if (j == m):\n",
    "                return True, position_poi_sequence\n",
    "         \n",
    "        # If not,\n",
    "        # increment i and reset j\n",
    "        else:\n",
    "            position_poi_sequence = []\n",
    "            i = i - j + 1\n",
    "            j = 0\n",
    "         \n",
    "    return False,None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = {'0':['1','4','6','1','10'],'1':['3','6','7'],'2':['7','9','5'],'3':['4','6','1','10']\n",
    "                ,'4':['9','5']}\n",
    "test_candidate = set(['0','1','2','3','4'])\n",
    "test_sequence = '1-10'\n",
    "mySet, myPos = check_sequence(test_dataset,test_candidate,test_sequence)\n",
    "print([rows+test_sequence.split('-')[poi_id]+poi_pos for rows in mySet \n",
    " for poi_id in range(len(test_sequence.split('-'))) for poi_pos in myPos[rows][poi_id]])\n",
    "form_elements(mySet,test_sequence,myPos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "def form_elements(trajs_index_set, tested_sequence, poi_positions_trajectories_dict_list):\n",
    "    '''\n",
    "    This method returns a set of elements.\n",
    "    Each element is formed by the traj ID, poi ID in the sequence and its respective position at traj ID.\n",
    "    Ex: set(['013', '0104', '312', '3103'])\n",
    "        '013': 0-> traj ID, 1-> poi ID, and 3-> position of poi ID at traj ID\n",
    "    '''\n",
    "    tested_sequence = tested_sequence.split('-')\n",
    "    return set([trajID+tested_sequence[poi_id]+poi_pos for trajID in trajs_index_set \n",
    "                for poi_id in range(len(tested_sequence)) \n",
    "                for poi_pos in poi_positions_trajectories_dict_list[trajID][poi_id]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusA = set([1,2,3,4,5])\n",
    "dict_cc = {'0': {'cc_elements':set([5,6,7,8,9])},'1': {'cc_elements':set([4,5,6,7,8])},\n",
    "           '2': {'cc_elements':set([5,4,3,2,1])}}\n",
    "overlap_coefficient(clusA,dict_cc)\n",
    "# print(overlap_coefficient(clusA,dict_cc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "def overlap_coefficient(clusterA, discovered_cc):\n",
    "    max_overlap = 0\n",
    "    \n",
    "    for key, value in discovered_cc.items():\n",
    "#         print(key,value)\n",
    "        elements_intersection = len(clusterA.intersection(discovered_cc[key]['cc_elements']))\n",
    "#         print(elements_intersection)\n",
    "        curr_overlap = elements_intersection/np.min([len(clusterA),len(discovered_cc[key]['cc_elements'])])\n",
    "#         print(curr_overlap)\n",
    "        \n",
    "        if curr_overlap > max_overlap:\n",
    "            max_overlap = curr_overlap\n",
    "            \n",
    "    return max_overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = {'c1':10,'c2':40,'c3':20,'c4':10,'c5':5,'c6':30,'c7':15,'c8':30,'c9':40,'c10':38}\n",
    "t_values = list(t.values())\n",
    "print(t_values,type(t_values))\n",
    "t_mean = np.mean(t_values)\n",
    "print(t_mean)\n",
    "# looking = True\n",
    "print('Before: ',t)\n",
    "# while looking:\n",
    "tmp = {}\n",
    "for key, value in t.items():\n",
    "    if value > t_mean:\n",
    "        tmp.update({key:value})\n",
    "#         looking = True\n",
    "#         break\n",
    "#     looking = False\n",
    "t = tmp\n",
    "print('After: ',t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def TRACOCLUS(input_data, avg_cc_analysis, k=-1, e_obj=-1, e_att=-1):\n",
    "#     input_D = pd.read_csv(input_data, header=None, names=[\"transation\"])\n",
    "    \n",
    "    input_D = ''\n",
    "    split = input_data.split('.')\n",
    "    if split[-1] == 'dat':\n",
    "        path = './data/real_application/foursquare_NY/preprocessed/'\n",
    "        input_D = pd.read_csv(path+input_data, header=None, names=[\"transation\"])\n",
    "    else:\n",
    "        path = './data/real_application/foursquare_NY/'\n",
    "        input_D = pd.read_csv(path+input_data, header=None, names=[\"transation\"])\n",
    "    \n",
    "    ### variable declaration\n",
    "    if k == -1:\n",
    "        k=sys.maxsize\n",
    "    if e_obj == -1:\n",
    "        e_obj = 1\n",
    "    if e_att == -1:\n",
    "        e_att = 1\n",
    "    \n",
    "    cost_model = sys.float_info.max # initial cost function of the model\n",
    "    num_of_coclusters = 0\n",
    "    D = []\n",
    "    final_coclusters = [] # store the attribute and objects clusters. final_coclusters[[C1_att,C1_obj],[Ck_att,Ck_obj]]\n",
    "    pattern_model = [set(),set()]# Union between the found co-clusters [list of obj,list of att]\n",
    "    cost_per_cocluster = []# stores the cost to build the cocluster\n",
    "    history_cost_model = []\n",
    "    ###\n",
    "    \n",
    "#     D,N,data_dict,data_res_dict,map_id_to_attribute = get_data(input_D)\n",
    "    \n",
    "    # Gamma: store the found co-clusters\n",
    "    overlap_coef_threshold = 0.5\n",
    "    INITIAL_COST = 100.0\n",
    "    final_coclusters = {}\n",
    "    final_clustered_elements = set()\n",
    "    final_coclustering_cost = 0\n",
    "    final_coclustering_size = {} # stores the clusters and its num of rows\n",
    "    coclustering_sizes_remove = [] # stores the cluster to be removed from final_coclustering_size\n",
    "#     avg_cc_analysis = \"combine\" # 1. 'index_rows_set'; 2. 'cost_function'; 3. combine\n",
    "#     avg_cc_analysis = cc_analysis # 1. 'index_rows_set'; 2. 'cost_function'\n",
    "    final_coclustering_avg_row_size = 0\n",
    "    total_of_iterations = 0\n",
    "#     clustering_perf = Performance(sns,plt)\n",
    "#     clustering_perf = Performance()\n",
    "\n",
    "    # Initialize main data structures\n",
    "    map_id_to_attribute_dict, S_poi_freq_dict, poi_at_trajs_dict_set, trajs_data_dict_list = get_data(input_D)\n",
    "    clustering_perf.set_variables(len(trajs_data_dict_list))\n",
    "#     S_poi_freq_dict = sort_attributes(S_poi_freq_dict)\n",
    "    \n",
    "    ### select att-values at most elements by log2 of the length of the set\n",
    "#     i = num_elements_to_test('log2',len(S_poi_freq_dict))\n",
    "#     print('Limit log2: ',i)\n",
    "#     for key, value in S_poi_freq_dict.items():\n",
    "#         if i < 0:\n",
    "#             break\n",
    "#         else:\n",
    "#             max_list_with_log2[key]=value\n",
    "#             i-=1\n",
    "    \n",
    "    ## select att-values by its frequence that are higher than the average\n",
    "    if element_analysis:#if true it selects just the elements with frequency equal or bigger than the AVG; otherwise use all elements\n",
    "        max_list_of_elems = {}\n",
    "        average_freq = np.mean(list(S_poi_freq_dict.values()))\n",
    "        for key, value in S_poi_freq_dict.items():\n",
    "            if value > average_freq:\n",
    "                max_list_of_elems[key]=value\n",
    "\n",
    "        S_poi_freq_dict = max_list_of_elems.copy()\n",
    "    print('Number of the most frequent elements: ',len(S_poi_freq_dict))\n",
    "    \n",
    "    start = timer()\n",
    "    for iter_k in range(k):\n",
    "#     for iter_k in tqdm(range(len(S_poi_freq_dict)*len(S_poi_freq_dict)), colour='blue', desc='Searching for candidates'):\n",
    "        print('Searching for candidate: ',iter_k+1)\n",
    "        print('')\n",
    "        \n",
    "#         print('S: ',S_poi_freq_dict)\n",
    "        S_poi_freq_dict = sort_attributes(S_poi_freq_dict)\n",
    "#         S_poi_freq_dict = sort_attributes(max_list_with_log2)\n",
    "#         print('Current main list S: ',S_poi_freq_dict)\n",
    "        S_uppercase_queue_list = populate_queue(S_poi_freq_dict)\n",
    "        \n",
    "        ### Initialize the current co-cluster 'cocluster_*' (CC) and candidate co-cluster 'cc_candidate' (CC*)\n",
    "        cocluster_sequence_str = ''\n",
    "        cocluster_attributes_list = ''\n",
    "        cocluster_index_rows_set = set()\n",
    "        cocluster_elements_set = set()\n",
    "#         cocluster_cost_function = sys.maxsize\n",
    "        cocluster_cost_function = INITIAL_COST\n",
    "        cocluster_max_overlapped_coef = 1\n",
    "        cc_candidate = {}\n",
    "#         num_of_attributes = len(s_poi_freq_queue_list)\n",
    "\n",
    "        clustering_perf.append_result(total_of_iterations,iter_k,final_coclustering_cost)\n",
    "    \n",
    "#         num_att_to_test_S = len(S_uppercase_queue_list)\n",
    "#         while(num_att_to_test_S > 0):\n",
    "#             num_att_to_test_S -= 1\n",
    "#         while S_uppercase_queue_list: # loop it while queue is not empty\n",
    "        limit = num_elements_to_test('length',len(S_uppercase_queue_list))\n",
    "#         limit = num_elements_to_test('log2',len(S_uppercase_queue_list))\n",
    "        for iter_elements_freq in range(0,limit):\n",
    "#         for iter_elements_freq in tqdm(range(limit), colour='blue', desc='Testing element reference'):\n",
    "            \n",
    "#             if cocluster_sequence_str == '':\n",
    "        \n",
    "            S_poi_node_queue = S_uppercase_queue_list.popleft()\n",
    "#             head_sequence_str = S_poi_node_queue[0]\n",
    "#             trajectories_head_sequence_set = poi_at_trajs_dict_set[S_poi_node_queue[0]]\n",
    "#             tail_sequence_str = S_poi_node_queue[0]\n",
    "#             trajectories_tail_sequence_set = poi_at_trajs_dict_set[S_poi_node_queue[0]]\n",
    "            S_uppercase_queue_list.append(S_poi_node_queue)\n",
    "            s_lowercase_queue_list = S_uppercase_queue_list.copy()\n",
    "#             sequence_cc = S_poi_node_queue[0]\n",
    "            sequence_cc = {'cs_sequence_cc': S_poi_node_queue[0],\n",
    "                           'cs_traj_ids_set_cc': poi_at_trajs_dict_set[S_poi_node_queue[0]],\n",
    "                           'cs_elements_cc': set(),\n",
    "                           'clustered_elements': final_clustered_elements}\n",
    "\n",
    "            num_attributes_to_test_s = len(s_lowercase_queue_list)\n",
    "            while(num_attributes_to_test_s > 0): # if it completes one loop the process stops\n",
    "\n",
    "                s_poi_node_queue = s_lowercase_queue_list.popleft()\n",
    "#                     poi_node_queue = s_poi_freq_queue_list[0]\n",
    "                #s_lowercase_queue_list.append(s_poi_node_queue)# original: comentado para inserir apenas no update\n",
    "                cc_candidate = candidate_cocluster(trajs_data_dict_list, poi_at_trajs_dict_set,\n",
    "                                                   sequence_cc, s_poi_node_queue)\n",
    "\n",
    "                if ((cc_candidate != None) and (cc_candidate['cost_function'] <= cocluster_cost_function) and \n",
    "                    (candidate_deviation(avg_cc_analysis,cc_candidate,final_coclustering_size,\n",
    "                                         ('pass' if cc_type_process != 'incremental' else cc_type_process))) and \n",
    "                    (overlap_coefficient(cc_candidate['elements_set'],final_coclusters) <= overlap_coef_threshold)):\n",
    "                    \n",
    "                    over_coef_cc_candidate=overlap_coefficient(cc_candidate['elements_set'],final_coclusters)\n",
    "#                     print('Current co-cluster CC was improved!')\n",
    "\n",
    "                    ### update CC\n",
    "                    cocluster_sequence_str = cc_candidate['sequence_str']\n",
    "                    cocluster_attributes_list = cc_candidate['sequence_str'].split('-')\n",
    "                    cocluster_index_rows_set = cc_candidate['index_rows_set'].copy()\n",
    "                    cocluster_elements_set = cc_candidate['elements_set'].copy()\n",
    "                    cocluster_cost_function = cc_candidate['cost_function']\n",
    "                    cocluster_max_overlapped_coef = over_coef_cc_candidate\n",
    "\n",
    "                    ### update sequence_cc\n",
    "                    sequence_cc['cs_sequence_cc'] = cocluster_sequence_str\n",
    "                    sequence_cc['cs_traj_ids_set_cc'] = cocluster_index_rows_set\n",
    "                    sequence_cc['cs_elements_cc'] = cocluster_elements_set\n",
    "\n",
    "#                     update_queue_s(cocluster_sequence_str, sequence_cc['cs_sequence_cc'],\n",
    "#                                    s_lowercase_queue_list, s_poi_node_queue)\n",
    "                    update_queue_s(cocluster_sequence_str, s_lowercase_queue_list, s_poi_node_queue)\n",
    "\n",
    "                    num_attributes_to_test_s = len(s_lowercase_queue_list)# reassign the counter to restart\n",
    "\n",
    "\n",
    "#                     trajectories_head_sequence_set = cocluster_index_rows_set\n",
    "#                     head_sequence_str = cocluster_sequence_str\n",
    "#                     trajectories_tail_sequence_set = cocluster_index_rows_set\n",
    "#                     tail_sequence_str = cocluster_sequence_str\n",
    "\n",
    "\n",
    "                    total_of_iterations += 1\n",
    "        \n",
    "    #                         clustering_perf.append_result(total_of_iterations,iter_k,cocluster_cost_function)\n",
    "#                     else:# inserting back the element without update\n",
    "#                         s_lowercase_queue_list.append(s_poi_node_queue)\n",
    "#                         num_attributes_to_test_s -= 1\n",
    "#                         total_of_iterations += 1\n",
    "                else:# inserting back the element without update\n",
    "                    s_lowercase_queue_list.append(s_poi_node_queue)\n",
    "#                     print('Current co-cluster CC was NOT improved!')\n",
    "#                     trajectories_head_sequence_set = tmp_traj_set\n",
    "#                     head_sequence_str = tmp_head_sequence_str\n",
    "#                     trajectories_tail_sequence_set = tmp_traj_set\n",
    "#                     tail_sequence_str = tmp_tail_sequence_str\n",
    "                    num_attributes_to_test_s -= 1\n",
    "                    total_of_iterations += 1\n",
    "#                         clustering_perf.append_result(total_of_iterations,iter_k,cocluster_cost_function)\n",
    "\n",
    "#                 print('Queue s* AFTER to update: ',s_lowercase_queue_list)\n",
    "#                 print('')\n",
    "\n",
    "                ### Performance purpose ###\n",
    "                if cocluster_cost_function != INITIAL_COST:\n",
    "                    clustering_perf.append_result(total_of_iterations,iter_k,\n",
    "                                                  (final_coclustering_cost+cocluster_cost_function))\n",
    "                else:\n",
    "                    clustering_perf.append_result(total_of_iterations,iter_k,final_coclustering_cost)\n",
    "\n",
    "            ## END while POIs_to_test (POIs_queue) ##\n",
    "            #########################################\n",
    "\n",
    "            ### check if CC was identified. If don't, it tries the next element p\n",
    "            if cocluster_sequence_str == '':\n",
    "                sequence_cc['cs_sequence_cc'] = ''\n",
    "                sequence_cc['cs_sequence_cc'] = set()\n",
    "                \n",
    "            else: # co-cluster identified Step to store the found cocluster K\n",
    "#                 final_coclusters.update({str(iter_k):{'cc_objs':cocluster_index_rows_set,\n",
    "#                                                       'cc_atts':cocluster_sequence_str,\n",
    "#                                                       'cc_elements':cocluster_elements_set,\n",
    "#                                                       'cc_cost':cocluster_cost_function}})\n",
    "#                 final_clustered_elements = final_clustered_elements.union(cocluster_elements_set)\n",
    "#                 final_coclustering_cost += cocluster_cost_function\n",
    "#                 print('Main list S BEFORE to update: ',S_poi_freq_dict)\n",
    "#                 update_uppercase_S(cocluster_attributes_list, cocluster_index_rows_set, S_poi_freq_dict)\n",
    "#                 print('Main list S AFTER to update: ',S_poi_freq_dict)\n",
    "#                 partial = timer()\n",
    "#                 print('Cluster \"{}\" finished at time \"{}\".'.format((iter_k+1),(partial-start))\n",
    "                break\n",
    "            \n",
    "        ### END while S\n",
    "        #\n",
    "        \n",
    "        ## into loop of iteration_k\n",
    "        partial = timer()\n",
    "        if VERBOSE:\n",
    "            print('Cluster \"{}\" finished at time \"{}\".'.format(iter_k+1,partial-start))\n",
    "        \n",
    "        ### there is not any good co-cluster to identify anymore. Stop searching\n",
    "        if (cocluster_cost_function >= 0) or (cocluster_max_overlapped_coef > overlap_coef_threshold):\n",
    "            if VERBOSE:\n",
    "                print('There is not any good co-cluster to identify anymore.')\n",
    "                \n",
    "            clustering_perf.store_dist(final_coclustering_size)\n",
    "            if cc_type_process == 'sample':\n",
    "                candidate_deviation(avg_cc_analysis,final_coclusters,final_coclustering_size,'sample')\n",
    "            break\n",
    "        else:\n",
    "            if VERBOSE:\n",
    "                    print('Co-cluster sequence \"{}\" present in \"{}\" trajectories.'.format(cocluster_sequence_str,\n",
    "                                                                                          len(cocluster_index_rows_set)))\n",
    "            final_coclusters.update({str(iter_k):{'cc_objs':cocluster_index_rows_set,\n",
    "                                                      'cc_atts':cocluster_sequence_str,\n",
    "                                                      'cc_elements':cocluster_elements_set,\n",
    "                                                      'cc_cost':cocluster_cost_function,\n",
    "                                                      'cc_over_coef':cocluster_max_overlapped_coef}})\n",
    "            final_clustered_elements = final_clustered_elements.union(cocluster_elements_set)\n",
    "            final_coclustering_cost += cocluster_cost_function\n",
    "            update_uppercase_S(cocluster_attributes_list, cocluster_index_rows_set, S_poi_freq_dict)\n",
    "            \n",
    "            ### storing the candidates reference values to evaluate the candidate later\n",
    "            if avg_cc_analysis == \"rows\":\n",
    "#                 print('Rows')\n",
    "                final_coclustering_size.update({str(iter_k):len(cocluster_index_rows_set)})\n",
    "            elif avg_cc_analysis == \"cost\":\n",
    "#                 print('Cost')\n",
    "                final_coclustering_size.update({str(iter_k):cocluster_cost_function})\n",
    "            else:\n",
    "                final_coclustering_size.update({str(iter_k):{'rows':len(cocluster_index_rows_set),\n",
    "                                                             'cost':cocluster_cost_function}})\n",
    "        \n",
    "    ## out of loop iteraton k\n",
    "    end = timer()\n",
    "    print('\\nTotal clustering time: ',str(end-start))\n",
    "    if cc_type_analysis == 'mean':\n",
    "        print('Process: {}; Metric: {}; Co-cluster ref: {}'.format(cc_type_process,cc_type_analysis,avg_cc_analysis))\n",
    "    else:\n",
    "        print('Process: {}; Metric: {}; Co-cluster ref: {}; Z-score: {}'.format(cc_type_process,cc_type_analysis,avg_cc_analysis,cc_z_threshold))\n",
    "    clustering_perf.summary_clusters(final_coclusters, map_id_to_attribute_dict, trajs_data_dict_list)\n",
    "    clustering_perf.calculate_entropy_purity(input_data)\n",
    "            \n",
    "    return D,final_coclusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 10.142857142857142  Var: 9.963197585235825  Round: 10.0\n"
     ]
    }
   ],
   "source": [
    "f = [34,5,6,7,8,9,2]\n",
    "print('Mean:',np.mean(f),' Var:',np.std(f), ' Round:',np.round(np.std(f)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def avg_cluster_size(ref_analysis, test_value, set_of_clusters):\n",
    "# def avg_cluster_size(ref_analysis,set_of_clusters):\n",
    "def candidate_deviation(ref,value_ref,set_of_clusters,cc_type_process='incremental'):\n",
    "    '''\n",
    "    Method to return the avg number of the reference in the set of co-clusters.\n",
    "    If the set is bigger than 1 it calculates the avg, otherwise it is 0.\n",
    "    Parameters:\n",
    "        ref_analysis: 1. index_rows_set -> considers the rows; 2. cost_function -> considers the cost.\n",
    "        test_value: The value to test.\n",
    "        set_of_clusters: The current set of co-clusters containing its values for the ref_analysis    \n",
    "    '''\n",
    "   \n",
    "    if len(set_of_clusters) >= 2:\n",
    "        try:# single ref\n",
    "            mean = np.mean(list(set_of_clusters.values()))\n",
    "            std = np.std(list(set_of_clusters.values()))\n",
    "        except:# double ref\n",
    "            sum_rows = []\n",
    "            sum_cost = []\n",
    "            for key,value in set_of_clusters.items():\n",
    "                sum_rows.append(set_of_clusters[key]['rows'])\n",
    "                sum_cost.append(set_of_clusters[key]['cost'])\n",
    "            mean_rows = np.mean(sum_rows)\n",
    "            mean_cost = np.mean(sum_cost)\n",
    "            std_rows = np.std(sum_rows)\n",
    "            std_cost = np.std(sum_cost)\n",
    "        \n",
    "        if cc_type_process == 'incremental':\n",
    "            if ref == \"rows\":\n",
    "                ### normal mean\n",
    "                if cc_type_analysis == 'mean':\n",
    "                    return len(value_ref['index_rows_set']) >= np.floor(mean)\n",
    "                else:\n",
    "                ### z-score: we consider values greater than -1 once it is a positive distribution\n",
    "                    try:\n",
    "                        z = (len(value_ref['index_rows_set'])-mean)/std\n",
    "                    except:\n",
    "                        z = (value_ref-mean)/std\n",
    "                    print('Z-score(rows): ',z)\n",
    "                    return z >= cc_z_threshold\n",
    "            elif ref == \"cost\":\n",
    "                ### normal mean\n",
    "                if cc_type_analysis == 'mean':\n",
    "                    return value_ref['cost_function'] <= np.ceil(mean)\n",
    "                else:\n",
    "                ### z-score: we consider values smaller than 1 once it is a negative distribution\n",
    "                    try:\n",
    "                        z = (value_ref['cost_function']-mean)/std\n",
    "                    except:\n",
    "                        z = (value_ref-mean)/std\n",
    "                    print('Z-score(cost): ',z)\n",
    "                    return z <= -cc_z_threshold\n",
    "            else:#combine\n",
    "                ### normal mean\n",
    "                if cc_type_analysis == 'mean':\n",
    "#                     print('Mean(rows):',mean_rows,' Mean(cost):',mean_cost)\n",
    "                    return ((len(value_ref['index_rows_set']) >= np.floor(mean_rows)) or \n",
    "                            (value_ref['cost_function'] <= np.ceil(mean_cost)))\n",
    "                else:\n",
    "                ### z-score\n",
    "                    z_rows = (len(value_ref['index_rows_set'])-mean_rows)/std_rows\n",
    "                    z_cost = (value_ref['cost_function']-mean_cost)/std_cost\n",
    "#                     print('Z-score(rows): ',z_rows,' Z-score(cost): ',z_cost)\n",
    "                    return ((z_rows >= -cc_z_threshold) or (z_cost <= cc_z_threshold))\n",
    "                \n",
    "        elif cc_type_process == 'sample':\n",
    "            candidates_to_remove = []\n",
    "            try:# single ref: rows OR cost\n",
    "                mean\n",
    "                if cc_type_analysis == 'mean':\n",
    "                    print('Mean:',mean)\n",
    "                    for key,value in set_of_clusters.items():\n",
    "#                         print('Candidate-'+key+' Mean:',mean,' Value ref:',value,end='')\n",
    "                        if ref == 'rows' and value < mean:\n",
    "#                             print(' -> Remove')\n",
    "                            candidates_to_remove.append(key)\n",
    "                        elif ref == 'cost' and value > mean:\n",
    "#                             print(' -> Remove')\n",
    "                            candidates_to_remove.append(key)\n",
    "                        else:\n",
    "#                             print(' -> Keep')\n",
    "                            pass\n",
    "                else:#z-score\n",
    "                    for key,value in set_of_clusters.items():\n",
    "                        z = (value-mean)/std\n",
    "#                         print('Candidate-'+key+' Z-score:',z,end='')\n",
    "                        if ref == 'rows' and z < cc_z_threshold:\n",
    "                            candidates_to_remove.append(key)\n",
    "#                             print(' -> Remove')\n",
    "                        elif ref == 'cost' and z > -cc_z_threshold:\n",
    "                            candidates_to_remove.append(key)\n",
    "#                             print(' -> Remove')\n",
    "                        else:\n",
    "#                             print(' -> Keep')\n",
    "                            pass\n",
    "\n",
    "            except:#double ref combine: rows AND cost\n",
    "                if cc_type_analysis == 'mean':\n",
    "                    for key,value in set_of_clusters.items():\n",
    "#                         print('Candidate-'+key+' Mean(rows):',mean_rows,' Mean(cost):',mean_cost,end='')\n",
    "                        if (set_of_clusters[key]['rows'] < mean_rows) and (set_of_clusters[key]['cost'] > mean_cost):\n",
    "#                             print(' -> Remove')\n",
    "                            candidates_to_remove.append(key)\n",
    "                        else:\n",
    "#                             print(' -> Keep')\n",
    "                            pass\n",
    "\n",
    "                else:#z-score\n",
    "                    for key,value in set_of_clusters.items():\n",
    "                        z_rows = (set_of_clusters[key]['rows']-mean_rows)/std_rows\n",
    "                        z_cost = (set_of_clusters[key]['cost']-mean_cost)/std_cost\n",
    "#                         print('Candidate-'+key+' Z-score(row):',z_rows,' Z-score(cost):',z_cost,end='')\n",
    "                        if (z_rows < cc_z_threshold) and (z_cost > -cc_z_threshold):\n",
    "#                             print(' -> Remove')\n",
    "                            candidates_to_remove.append(key)\n",
    "                        else:\n",
    "#                             print(' -> Keep')\n",
    "                            pass\n",
    "                        \n",
    "#             print(\"Remove candidates: \",candidates_to_remove)\n",
    "#             print(\"Number of candidates to remove: \",len(candidates_to_remove))\n",
    "            for candidate in candidates_to_remove:#at this point, value_ref is the set of candidates\n",
    "                del value_ref[candidate]\n",
    "\n",
    "        else: # just pass step. Stores the candidate co-clusters and analyse them with sample analysis if desirable\n",
    "            return True               \n",
    "                \n",
    "    else:# pass step to reach a minimum number of elements to perform computation\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 {'r': 4, 'c': 7}\n",
      "1 {'r': 5, 'c': 9}\n"
     ]
    }
   ],
   "source": [
    "q = {'0':{'r':4,'c':7},'1':{'r':5,'c':9}}\n",
    "for key, value in q.items():\n",
    "    print(key,value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = 'None'\n",
    "print(q)\n",
    "if q == None:\n",
    "    print(\"None\")\n",
    "else:\n",
    "    print('Diff none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "def candidate_cocluster(trajs_data_dict_list, poi_at_trajs_dict_set, sequence_cc, s_poi_node_queue):\n",
    "    INITIAL_COST = 100.0\n",
    "    ### Current sequence\n",
    "    ### The method tries to form two sequence, if the sequence is valid the method picks the best one\n",
    "    head_sequence_str = sequence_cc['cs_sequence_cc']\n",
    "    trajectories_head_sequence_set = sequence_cc['cs_traj_ids_set_cc']\n",
    "\n",
    "    tail_sequence_str = sequence_cc['cs_sequence_cc']\n",
    "    trajectories_tail_sequence_set = sequence_cc['cs_traj_ids_set_cc']\n",
    "\n",
    "    ### Try to expand the candidate sequence one element at a time if it forms a frequent sequence\n",
    "    ### Step to test ELEMENT at the HEAD ###\n",
    "    tmp_head_sequence_str = head_sequence_str\n",
    "    head_sequence_str = s_poi_node_queue[0]+'-'+head_sequence_str\n",
    "#     if VERBOSE:\n",
    "#         print('-> Head sequence: ',head_sequence_str)\n",
    "    tmp_traj_set = trajectories_head_sequence_set\n",
    "    trajectories_head_sequence_set = trajectories_head_sequence_set.intersection(poi_at_trajs_dict_set[s_poi_node_queue[0]])\n",
    "    trajectories_head_sequence_set, position_poi_per_traj_head = check_sequence(trajs_data_dict_list,\n",
    "                                                                                trajectories_head_sequence_set,\n",
    "                                                                                head_sequence_str)\n",
    "\n",
    "    if len(trajectories_head_sequence_set) > 0:\n",
    "#         if VERBOSE:\n",
    "#             print('Number of rows with this sequence: {}'.format(len(trajectories_head_sequence_set)))\n",
    "        elements_head_sequence = form_elements(trajectories_head_sequence_set,\n",
    "                                               head_sequence_str,\n",
    "                                               position_poi_per_traj_head)    \n",
    "        overlapped_elements = elements_head_sequence.intersection(sequence_cc['clustered_elements'])\n",
    "        cost_head_sequence = cost_function(len(trajectories_head_sequence_set),\n",
    "                                           len(head_sequence_str.split('-')),\n",
    "                                           len(overlapped_elements))\n",
    "#         overlap_coef_head = overlap_coefficient(elements_head_sequence,final_coclusters)\n",
    "#         print('Head cost: {} and overlap_coef: {}.'.format(cost_head_sequence,\n",
    "#                                                            overlap_coef_head))\n",
    "    else:\n",
    "#         if VERBOSE:\n",
    "#             print('Tested head sequence \"{}\" does NOT exist!'.format(head_sequence_str))\n",
    "        trajectories_head_sequence_set = tmp_traj_set\n",
    "        head_sequence_str = tmp_head_sequence_str\n",
    "        cost_head_sequence = INITIAL_COST #\n",
    "        overlap_coef_head = 1\n",
    "    #### END test HEAD sequence ####\n",
    "\n",
    "    #### Step test ELEMENT at the TAIL ####\n",
    "    tmp_tail_sequence_str = tail_sequence_str\n",
    "    tail_sequence_str = tail_sequence_str+'-'+s_poi_node_queue[0]\n",
    "#     if VERBOSE:\n",
    "#         print('-> Tail sequence: ',tail_sequence_str)\n",
    "    tmp_traj_set = trajectories_tail_sequence_set\n",
    "    trajectories_tail_sequence_set = trajectories_tail_sequence_set.intersection(poi_at_trajs_dict_set[s_poi_node_queue[0]])\n",
    "    trajectories_tail_sequence_set, position_poi_per_traj_tail = check_sequence(trajs_data_dict_list,\n",
    "                                                                                trajectories_tail_sequence_set,\n",
    "                                                                                tail_sequence_str)\n",
    "\n",
    "    if (len(trajectories_tail_sequence_set) > 0):\n",
    "#         if VERBOSE:\n",
    "#             print('Number of rows with this sequence: {}'.format(len(trajectories_tail_sequence_set)))\n",
    "        elements_tail_sequence = form_elements(trajectories_tail_sequence_set,\n",
    "                                               tail_sequence_str,\n",
    "                                               position_poi_per_traj_tail)\n",
    "        overlapped_elements = elements_tail_sequence.intersection(sequence_cc['clustered_elements'])\n",
    "        cost_tail_sequence = cost_function(len(trajectories_tail_sequence_set),\n",
    "                                           len(tail_sequence_str.split('-')),\n",
    "                                           len(overlapped_elements))\n",
    "#         overlap_coef_tail = overlap_coefficient(elements_tail_sequence,final_coclusters)\n",
    "#         print('Tail cost: {} and overlap_coef: {}.'.format(cost_tail_sequence,\n",
    "#                                                            overlap_coef_tail))\n",
    "    else:\n",
    "#         if VERBOSE:\n",
    "#             print('Tested tail sequence \"{}\" does NOT exist!'.format(tail_sequence_str))\n",
    "        trajectories_tail_sequence_set = tmp_traj_set\n",
    "        tail_sequence_str = tmp_tail_sequence_str\n",
    "        cost_tail_sequence = INITIAL_COST\n",
    "        overlap_coef_tail = 1\n",
    "    #### END test TAIL sequence ####\n",
    "    \n",
    "#     print('Current co-cluster cost: ',cocluster_cost_function)\n",
    "#     print('Queue s* BEFORE to upadate: ',s_lowercase_queue_list)\n",
    "\n",
    "    ### Step to test the best sequence if exist a sequence\n",
    "    if (cost_head_sequence < cost_tail_sequence) and (cost_head_sequence < 0):\n",
    "#         print('Co-cluster improved with HEAD sequence.')\n",
    "\n",
    "        # update the nodes of queue s.\n",
    "#         update_queue_s(cocluster_sequence_str, head_sequence_str,\n",
    "#                        s_lowercase_queue_list, s_poi_node_queue)\n",
    "#         update_queue_s(candidate_sequence['cs_sequence_cc'], head_sequence_str,\n",
    "#                        s_lowercase_queue_list, s_poi_node_queue)\n",
    "\n",
    "#         cocluster_sequence_str = head_sequence_str\n",
    "#         cocluster_attributes_list = head_sequence_str.split('-')\n",
    "#         cocluster_index_rows_set = trajectories_head_sequence_set.copy()\n",
    "#         cocluster_elements_set = elements_head_sequence.copy()\n",
    "#         cocluster_cost_function = cost_head_sequence\n",
    "#         cocluster_max_overlapped_coef = overlap_coef_head\n",
    "        \n",
    "        cc_candidate = {'sequence_str': head_sequence_str,\n",
    "                        'attributes_list': head_sequence_str.split('-'),\n",
    "                        'index_rows_set': trajectories_head_sequence_set.copy(),\n",
    "                        'elements_set': elements_head_sequence.copy(),\n",
    "                        'cost_function': cost_head_sequence}        \n",
    "        \n",
    "        return cc_candidate\n",
    "\n",
    "    elif (cost_tail_sequence < cost_head_sequence) and (cost_tail_sequence < 0):\n",
    "#         if VERBOSE:\n",
    "#             print('Co-cluster improved with TAIL sequence.')\n",
    "\n",
    "        # update the nodes of queue s.\n",
    "#         update_queue_s(cocluster_sequence_str,tail_sequence_str,\n",
    "#                        s_lowercase_queue_list,s_poi_node_queue)\n",
    "#         update_queue_s(candidate_sequence['cs_sequence_cc'], tail_sequence_str,\n",
    "#                        s_lowercase_queue_list, s_poi_node_queue)\n",
    "\n",
    "#         cocluster_sequence_str = tail_sequence_str\n",
    "#         cocluster_attributes_list = tail_sequence_str.split('-')\n",
    "#         cocluster_index_rows_set = trajectories_tail_sequence_set.copy()\n",
    "#         cocluster_elements_set = elements_tail_sequence.copy()\n",
    "#         cocluster_cost_function = cost_tail_sequence\n",
    "#         cocluster_max_overlapped_coef = overlap_coef_tail\n",
    "        \n",
    "        cc_candidate = {'sequence_str': tail_sequence_str,\n",
    "                        'attributes_list': tail_sequence_str.split('-'),\n",
    "                        'index_rows_set': trajectories_tail_sequence_set.copy(),\n",
    "                        'elements_set': elements_tail_sequence.copy(),\n",
    "                        'cost_function': cost_tail_sequence}        \n",
    "        \n",
    "        return cc_candidate\n",
    "    \n",
    "    else:# it does not found any sequence formed by the elements\n",
    "#         cc_candidate = {'sequence_str': None}\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Performance():\n",
    "#     perf_df_clustering_output_measures = pd.DataFrame(columns = ['Iteration_i','Candidate_iteration_k',\n",
    "#                                                             'Candidate_cost'])\n",
    "    \n",
    "    df_quality_clustering = pd.DataFrame(columns= ['Dataset','Clustering_approach','Cocluster_reference',\n",
    "                                                   'Cocluster_statistic','Num_of_candidates','Num_of_clusters',\n",
    "                                                   'Overall_entropy','Purity'])\n",
    "\n",
    "#     def __init__(self,sns,plt):\n",
    "#         self.sns = sns\n",
    "#         self.plt = plt\n",
    "# #         df_clustering_output_measures = pd.DataFrame(columns = ['Iteration_i','Cluster_iteration_k',\n",
    "#                                                             'Cocluster_cost',])\n",
    "    \n",
    "    def compute_measures_at_once(self):\n",
    "        '''\n",
    "        Method to compute the measures at once for given dataset.\n",
    "        It is aimed to avoid unecessary recomputation for the candidates.\n",
    "        '''\n",
    "        pass\n",
    "        \n",
    "    \n",
    "    \n",
    "    def set_variables(self,num_objs):\n",
    "        self.perf_df_clustering_output_measures = pd.DataFrame(columns = ['Iteration_i','Candidate_iteration_k',\n",
    "                                                                          'Candidate_cost'])\n",
    "        self.total_num_of_objs_df = num_objs\n",
    "    \n",
    "    def append_result(self,it_i,cc_it_k,cc_cost):\n",
    "        self.perf_df_clustering_output_measures = self.perf_df_clustering_output_measures.append({'Iteration_i':int(it_i),\n",
    "                                                                                        'Candidate_iteration_k':'Candidate_'+str(cc_it_k),\n",
    "                                                                                        'Candidate_cost':float(cc_cost)},\n",
    "                                                                                        ignore_index=True)\n",
    "    \n",
    "    def plot_cost(self):\n",
    "        '''\n",
    "        Method to show the cost function value along the iterations.\n",
    "        '''\n",
    "#         print(self.df_clustering_output_measures.head())\n",
    "#         self.df_clustering_output_measures['Cocluster_cost'] = self.df_clustering_output_measures['Cocluster_cost'] / self.df_clustering_output_measures['Cocluster_cost'].abs().max()\n",
    "#         print(self.df_clustering_output_measures.head())\n",
    "        a4_dims = (11.7, 8.27)\n",
    "        fig, ax = plt.subplots(figsize=a4_dims)\n",
    "        sns.lineplot(data=self.perf_df_clustering_output_measures, x=\"Iteration_i\", y=\"Candidate_cost\"\n",
    "                     , hue=\"Candidate_iteration_k\")#, style=\"Cluster_iteration_k\", markers=True, dashes=False)\n",
    "        \n",
    "        if self.perf_df_clustering_output_measures['Candidate_iteration_k'].nunique() > 15:\n",
    "            plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0)\n",
    "#         self.plt.show()\n",
    "\n",
    "    def summary_clusters(self, cc_dict, map_id_to_att,trajs_data_dict_list):\n",
    "        '''\n",
    "        Method to map back the attributes to its original value and put it avaible as final result visualization.\n",
    "        '''\n",
    "        self.perf_cc_clusters = {}\n",
    "        \n",
    "        for cluster_k,value in cc_dict.items():\n",
    "#             print('Cluster ',cluster_k)\n",
    "            remap_seq_output = []\n",
    "            for att_id in cc_dict[cluster_k]['cc_atts'].split('-'):\n",
    "                remap_seq_output.append(map_id_to_att[att_id])\n",
    "            sequence = '-'.join(remap_seq_output).strip()\n",
    "#             print('Attributes sequence \"{}\" and trajectories \"{}\".'.format(sequence,\n",
    "#                                                                            cc_dict[cluster_k]['cc_objs']))\n",
    "            self.perf_cc_clusters.update({cluster_k:{'cc_atts':sequence,'cc_objs':cc_dict[cluster_k]['cc_objs'],\n",
    "                                                     'cc_cost':cc_dict[cluster_k]['cc_cost'],\n",
    "                                                     'cc_over_coef':cc_dict[cluster_k]['cc_over_coef']}})\n",
    "#             self.set_of_objects = self.set_of_objects.union(set(cc_dict[cluster_k]['cc_objs']))\n",
    "        \n",
    "#         self.perf_cc_clusters.update({'num_of_objects': len(self.set_of_objects)})\n",
    "        print('Number of co-clusters: ',len(self.perf_cc_clusters))\n",
    "        if VERBOSE:\n",
    "            for key, value in self.perf_cc_clusters.items():\n",
    "                print('Co-cluster-{}, Sequence: {}, Num of trajs: {}, Cost: {}'.format(key,\n",
    "                                                                           self.perf_cc_clusters[key]['cc_atts'],\n",
    "                                                                           len(self.perf_cc_clusters[key]['cc_objs']),\n",
    "                                                                           self.perf_cc_clusters[key]['cc_cost']))\n",
    "#         self.perf_cc_clusters.update({'num_of_objects': len(trajs_data_dict_list)})\n",
    "    \n",
    "    def get_clusters(self):\n",
    "        '''\n",
    "        Method to show the found co-clusters as follows:\n",
    "        1. It shows the current co-cluster K with the absolute number of objects into it and the relative number regarding\n",
    "        the total number of objects in the dataset;\n",
    "        2. It shows the co-cluster sequence of elements and the objects containing it.\n",
    "        '''\n",
    "        for cluster_k, value in self.perf_cc_clusters.items():\n",
    "            if cluster_k != 'num_of_objects':\n",
    "                self.relative = len(self.perf_cc_clusters[cluster_k]['cc_objs'])/self.total_num_of_objs_df\n",
    "                print('Cluster {0} [Absolute:{1} | Relative:{2:1.2f} | Cost: {3} | Oc: {4:1.2f}]'.format(cluster_k,\n",
    "                                                                                               len(self.perf_cc_clusters[cluster_k]['cc_objs']),\n",
    "                                                                                               self.relative,\n",
    "                                                                                               self.perf_cc_clusters[cluster_k]['cc_cost'],\n",
    "                                                                                               self.perf_cc_clusters[cluster_k]['cc_over_coef']))\n",
    "                \n",
    "                if len(self.perf_cc_clusters[cluster_k]['cc_objs']) < 10:\n",
    "                    print('Attributes sequence \"{}\" and trajectories \"{}\".'.format(self.perf_cc_clusters[cluster_k]['cc_atts'],\n",
    "                                                                                   str(self.perf_cc_clusters[cluster_k]['cc_objs']).strip('{}')))\n",
    "                else:\n",
    "                    print('Attributes sequence \"{}\" and trajectories \"{},[...]\".'.format(self.perf_cc_clusters[cluster_k]['cc_atts'],\n",
    "                                                                                str(list(self.perf_cc_clusters[cluster_k]['cc_objs'])[0:8]).strip('[]')))\n",
    "                print('')\n",
    "    \n",
    "    def store_dist(self,set_of_candidates):\n",
    "        self.set_of_candidates = set_of_candidates\n",
    "    \n",
    "    def __get_entropy_purity(self):\n",
    "        print('')\n",
    "        print('Overall entropy H: '+str(self.overall_entropy))\n",
    "        print('Purity: '+str(self.purity))\n",
    "        print('AVG relative co-clusters: {:.2f}\\u00B1{:.2f}'.format(np.mean(self.relative_clusters_value),\n",
    "                                                                    np.std(self.relative_clusters_value)))\n",
    "        print('')\n",
    "    \n",
    "    def calculate_entropy_purity(self, file_dataset):\n",
    "        \n",
    "        self.split = file_dataset.split('.')\n",
    "        if self.split[-1] == 'dat':\n",
    "            self.path = './data/real_application/foursquare_NY/'\n",
    "            self.df_trajs_users = create_df_map_traj_user(pd.read_csv(self.path+self.split[0]+'.csv', sep=\";\"))\n",
    "        else:\n",
    "            self.path = './data/real_application/foursquare_NY/'\n",
    "            self.df_trajs_users = create_df_map_traj_user(pd.read_csv(self.path+file_dataset, sep=\";\"))\n",
    "            \n",
    "#         input_D = ''\n",
    "#         split = input_data.split('.')\n",
    "#         if split[-1] == 'dat':\n",
    "#             path = './data/real_application/foursquare_NY/preprocessed/'\n",
    "#             input_D = pd.read_csv(path+input_data, header=None, names=[\"transation\"])\n",
    "#         else:\n",
    "#             path = './data/real_application/foursquare_NY/'\n",
    "#             input_D = pd.read_csv(path+input_data, header=None, names=[\"transation\"])\n",
    "        \n",
    "        self.relative_clusters_value = []\n",
    "        self.entropy_per_cluster = []\n",
    "        self.num_of_objs_per_cluster = []\n",
    "        self.total_num_of_objs = len(self.df_trajs_users)\n",
    "        self.overall_entropy = 0\n",
    "        self.max_prob_per_cluster = []\n",
    "        self.purity = 0\n",
    "        \n",
    "        for cluster_k, value in self.perf_cc_clusters.items():\n",
    "            self.users = {}\n",
    "            if cluster_k != 'num_of_objects':\n",
    "                self.num_of_objs_k = len(self.perf_cc_clusters[cluster_k]['cc_objs'])\n",
    "                self.relative_clusters_value.append((self.num_of_objs_k/self.total_num_of_objs)*100)\n",
    "#                 print('Cluster-'+str(cluster_k)+' | # of trajs: '+str(self.num_of_objs_k))\n",
    "                self.trajs = list(map(int,self.perf_cc_clusters[cluster_k]['cc_objs']))\n",
    "                self.df_cluster = self.df_trajs_users[self.df_trajs_users['Tid'].isin(self.trajs)]\n",
    "##                 self.users = self.df_cluster['User'].value_counts().to_dict()\n",
    "                self.users = self.df_cluster['User'].value_counts()\n",
    "                self.h_k = entropy(self.users,base=2)\n",
    "##                 self.users = self.users.to_dict()\n",
    "                #print(self.users,end=' | ')\n",
    "                #print(\"Entropy h_k: \"+str(self.h_k))\n",
    "                self.entropy_per_cluster.append(self.h_k)\n",
    "                self.num_of_objs_per_cluster.append(self.num_of_objs_k)\n",
    "##                 self.total_num_of_objs += self.num_of_objs_k\n",
    "##                self.max_prob_per_cluster.append(np.array(list(self.users.values())).max())\n",
    "                self.max_prob_per_cluster.append(list(self.users)[0])\n",
    "        \n",
    "        self.overall_entropy = np.sum((np.array(self.entropy_per_cluster)*\n",
    "                                       (np.array(self.num_of_objs_per_cluster)/self.total_num_of_objs)))\n",
    "        self.purity = np.array(self.max_prob_per_cluster).sum()/self.total_num_of_objs\n",
    "        self.__get_entropy_purity()\n",
    "    \n",
    "    def show_boxplot(self):\n",
    "        '''\n",
    "        Method to show the distribution values of the candidates.\n",
    "        '''\n",
    "        #         array = np.random.uniform(size=20)\n",
    "        self.array = list(self.set_of_candidates.values())\n",
    "        self.ref = ''\n",
    "        if np.mean(self.array) < 0:\n",
    "            self.ref = 'Cost ref'\n",
    "        else:\n",
    "            self.ref = 'Rows ref'\n",
    "        ax = sns.boxplot(data=self.array)\n",
    "        ax = sns.swarmplot(data=self.array, color=\".25\")\n",
    "        plt.xticks([0],[self.ref])\n",
    "#         plt.xlabel(\"Reference\")\n",
    "        plt.ylabel(\"Values\")\n",
    "        plt.title(self.ref+\" distribution\")\n",
    "    #     plt.show(ax)\n",
    "    \n",
    "    def test_norm_dist(self):\n",
    "        import scipy.stats as stats\n",
    "        try:\n",
    "            self.mean = np.mean(list(self.set_of_candidates.values()))\n",
    "            self.std = np.std(list(self.set_of_candidates.values()),ddof=1)\n",
    "            self.dist_values = list(self.set_of_candidates.values())\n",
    "#             self.shapiro_stat, self.shapiro_p_value = stats.shapiro(self.dist_values)\n",
    "#     #         print('O valor da estatística de shapiro-wilk = '+str(self.shapiro_stat))\n",
    "#     #         print('O valor do p-value de shapiro-wilk = '+str(self.shapiro_p_value))\n",
    "#             if self.shapiro_p_value >=0.5:\n",
    "#                 print('Com 95% de confiança, os dados são similares a uma distribuição normal segundo o teste de Shapiro-Wilk.')\n",
    "#             else:\n",
    "#                 print('Com 95% de confiança, os dados NÃO são similares a uma distribuição normal segundo o teste de Shapiro-Wilk.')\n",
    "#             print('')\n",
    "            self.__shapiro_wilk_test()\n",
    "            self.__kolomogorov_smirnov_test()\n",
    "            self.__anderson_darling_test()\n",
    "            print('')\n",
    "        except Exception as inst:\n",
    "            print('Please, test the variable individually.')\n",
    "            print('Error:',inst)\n",
    "#             self.dist_values_rows = []\n",
    "#             self.dist_values_cost = []\n",
    "\n",
    "#             for key,value in self.set_of_candidates.items():\n",
    "#                 self.dist_values_rows.append(self.set_of_candidates[key]['rows'])\n",
    "#                 self.dist_values_cost.append(self.set_of_candidates[key]['cost'])\n",
    "            \n",
    "#             self.shapiro_stat_rows, self.shapiro_p_value_rows = stats.shapiro(self.dist_values_rows)\n",
    "#             self.shapiro_stat_cost, self.shapiro_p_value_cost = stats.shapiro(self.dist_values_cost)\n",
    "    \n",
    "    def __shapiro_wilk_test(self):\n",
    "        self.shapiro_stat, self.shapiro_p_value = stats.shapiro(self.dist_values)\n",
    "#         print('O valor da estatística de shapiro-wilk = '+str(self.shapiro_stat))\n",
    "#         print('O valor do p-value de shapiro-wilk = '+str(self.shapiro_p_value))\n",
    "        if self.shapiro_p_value >=0.5:\n",
    "            print('Segundo o teste de Shapiro-Wilk, com 95% de confiança, os dados são similares a uma distribuição normal.')\n",
    "        else:\n",
    "            print('Segundo o teste de Shapiro-Wilk, com 95% de confiança, os dados NÃO são similares a uma distribuição normal.')\n",
    "    \n",
    "    def __kolomogorov_smirnov_test(self):\n",
    "        self.ks_stat, self.ks_p_value = stats.kstest(self.dist_values,cdf='norm', args=(self.mean,self.std), N=len(self.dist_values))\n",
    "        self.ks_critico = self.__kolmogorov_smirnov_critico(len(self.dist_values))\n",
    "        if self.ks_critico >= self.ks_stat:\n",
    "            print('Segundo o teste Kolomogorov-Smirnov, com 95% de confiança, os dados são similares a uma distribuição normal.')\n",
    "        else:\n",
    "            print('Segundo o teste Kolomogorov-Smirnov, com 95% de confiança, os dados NÃO são similares a uma distribuição normal.')\n",
    "    # Checking the critical value of the Kolmogorov-Smirnov test\n",
    "    def __kolmogorov_smirnov_critico(self,n):\n",
    "        # table of critical values for the kolmogorov-smirnov test - 95% confidence\n",
    "        # Source: https://www.soest.hawaii.edu/GG/FACULTY/ITO/GG413/K_S_Table_one_Sample.pdf\n",
    "        # Source: http://www.real-statistics.com/statistics-tables/kolmogorov-smirnov-table/\n",
    "        # alpha = 0.05 (95% confidential level)\n",
    "\n",
    "        if n <= 40:\n",
    "            # valores entre 1 e 40\n",
    "            self.kolmogorov_critico = [0.97500, 0.84189, 0.70760, 0.62394, 0.56328, 0.51926, 0.48342, 0.45427, 0.43001, 0.40925, \n",
    "                          0.39122, 0.37543, 0.36143, 0.34890, 0.33760, 0.32733, 0.31796, 0.30936, 0.30143, 0.29408, \n",
    "                          0.28724, 0.28087, 0.27490, 0.26931, 0.26404, 0.25907, 0.25438, 0.24993, 0.24571, 0.24170, \n",
    "                          0.23788, 0.23424, 0.23076, 0.22743, 0.22425, 0.22119, 0.21826, 0.21544, 0.21273, 0.21012]\n",
    "            self.ks_critico = self.kolmogorov_critico[n - 1]\n",
    "        elif n > 40:\n",
    "            # valores acima de 40:\n",
    "            self.kolmogorov_critico = 1.36/(np.sqrt(n))\n",
    "            self.ks_critico = self.kolmogorov_critico\n",
    "        else:\n",
    "            pass            \n",
    "\n",
    "        return self.ks_critico\n",
    "    \n",
    "    def __anderson_darling_test(self):\n",
    "        self.ad_stat, self.ad_critico, self.ad_teorico = stats.anderson(self.dist_values,'norm')\n",
    "        if self.ad_stat < self.ad_critico[2]:\n",
    "            print('Segundo o teste de Anderson-Darling, com 95% de confiança, os dados são similares a uma distribuição normal.')\n",
    "        else:\n",
    "            print('Segundo o teste de Anderson-Darling, com 95% de confiança, os dados NÃO são similares a uma distribuição normal.')\n",
    "\n",
    "    def test_skewness(self):\n",
    "        self.dist_values = list(self.set_of_candidates.values())\n",
    "        self.mean = np.mean(self.dist_values)\n",
    "        self.median = np.median(self.dist_values)\n",
    "        vals,counts = np.unique(self.dist_values, return_counts=True)\n",
    "        index = np.argmax(counts)\n",
    "        self.mode = vals[index]\n",
    "        \n",
    "        \n",
    "        if (self.mean == self.median) and (self.mean == self.mode):\n",
    "            print('Distribuição normal | Mean:{} = Median: {} = Mode: {}.'.format(self.mean,self.median,self.mode))\n",
    "        #positive values\n",
    "        if (self.mean < self.median) and (self.median < self.mode):\n",
    "            print('Assimetria à Esquerda (negativa) | Mean:{} < Median: {} < Mode: {}.'.format(self.mean,self.median,self.mode))\n",
    "        if (self.mode < self.median) and (self.median < self.mean):\n",
    "            print('Assimetria à Direita (positiva) | Mode:{} < Median: {} < Mean: {}.'.format(self.mode,self.median,self.mean))\n",
    "        #negativa values\n",
    "        if self.mean < 0:\n",
    "            print('mean:',self.mean,' median:',self.median,' mode:',self.mode)\n",
    "            if (self.mean > self.median) and (self.median > self.mode):\n",
    "                print('Assimetria à Esquerda (negativa) | Mean:{} < Median: {} < Mode: {}.'.format(self.mean,self.median,self.mode))\n",
    "            if (self.mode > self.median) and (self.median > self.mean):\n",
    "                print('Assimetria à Direita (positiva) | Mode:{} < Median: {} < Mean: {}.'.format(self.mode,self.median,self.mean))\n",
    "        print('')\n",
    "\n",
    "\n",
    "\n",
    "#### Modificação do candidate deviation método. Esta modificação é para fazer os cálculos das medidas sem ter que\n",
    "#### recalcular os candidatos no mesmo dataset. Os candidatos não mudam no modo de descoberta automática.\n",
    "def short_path_metrics(ref,value_ref,set_of_clusters,cc_type_process='incremental'):\n",
    "    '''\n",
    "    Method to return the avg number of the reference in the set of co-clusters.\n",
    "    If the set is bigger than 1 it calculates the avg, otherwise it is 0.\n",
    "    Parameters:\n",
    "        ref_analysis: 1. index_rows_set -> considers the rows; 2. cost_function -> considers the cost.\n",
    "        test_value: The value to test.\n",
    "        set_of_clusters: The current set of co-clusters containing its values for the ref_analysis    \n",
    "    '''\n",
    "   \n",
    "    if len(set_of_clusters) >= 2:\n",
    "        try:# single ref\n",
    "            mean = np.mean(list(set_of_clusters.values()))\n",
    "            std = np.std(list(set_of_clusters.values()))\n",
    "        except:# double ref\n",
    "            sum_rows = []\n",
    "            sum_cost = []\n",
    "            for key,value in set_of_clusters.items():\n",
    "                sum_rows.append(set_of_clusters[key]['rows'])\n",
    "                sum_cost.append(set_of_clusters[key]['cost'])\n",
    "            mean_rows = np.mean(sum_rows)\n",
    "            mean_cost = np.mean(sum_cost)\n",
    "            std_rows = np.std(sum_rows)\n",
    "            std_cost = np.std(sum_cost)\n",
    "        \n",
    "        if cc_type_process == 'incremental':\n",
    "            if ref == \"rows\":\n",
    "                ### normal mean\n",
    "                if cc_type_analysis == 'mean':\n",
    "                    return len(value_ref['index_rows_set']) >= np.floor(mean)\n",
    "                else:\n",
    "                ### z-score: we consider values greater than -1 once it is a positive distribution\n",
    "                    try:\n",
    "                        z = (len(value_ref['index_rows_set'])-mean)/std\n",
    "                    except:\n",
    "                        z = (value_ref-mean)/std\n",
    "                    print('Z-score(rows): ',z)\n",
    "                    return z >= cc_z_threshold\n",
    "            elif ref == \"cost\":\n",
    "                ### normal mean\n",
    "                if cc_type_analysis == 'mean':\n",
    "                    return value_ref['cost_function'] <= np.ceil(mean)\n",
    "                else:\n",
    "                ### z-score: we consider values smaller than 1 once it is a negative distribution\n",
    "                    try:\n",
    "                        z = (value_ref['cost_function']-mean)/std\n",
    "                    except:\n",
    "                        z = (value_ref-mean)/std\n",
    "                    print('Z-score(cost): ',z)\n",
    "                    return z <= -cc_z_threshold\n",
    "            else:#combine\n",
    "                ### normal mean\n",
    "                if cc_type_analysis == 'mean':\n",
    "#                     print('Mean(rows):',mean_rows,' Mean(cost):',mean_cost)\n",
    "                    return ((len(value_ref['index_rows_set']) >= np.floor(mean_rows)) or \n",
    "                            (value_ref['cost_function'] <= np.ceil(mean_cost)))\n",
    "                else:\n",
    "                ### z-score\n",
    "                    z_rows = (len(value_ref['index_rows_set'])-mean_rows)/std_rows\n",
    "                    z_cost = (value_ref['cost_function']-mean_cost)/std_cost\n",
    "#                     print('Z-score(rows): ',z_rows,' Z-score(cost): ',z_cost)\n",
    "                    return ((z_rows >= -cc_z_threshold) or (z_cost <= cc_z_threshold))\n",
    "                \n",
    "        elif cc_type_process == 'sample':\n",
    "            candidates_to_remove = []\n",
    "            try:# single ref: rows OR cost\n",
    "                mean\n",
    "                if cc_type_analysis == 'mean':\n",
    "                    print('Mean:',mean)\n",
    "                    for key,value in set_of_clusters.items():\n",
    "#                         print('Candidate-'+key+' Mean:',mean,' Value ref:',value,end='')\n",
    "                        if ref == 'rows' and value < mean:\n",
    "#                             print(' -> Remove')\n",
    "                            candidates_to_remove.append(key)\n",
    "                        elif ref == 'cost' and value > mean:\n",
    "#                             print(' -> Remove')\n",
    "                            candidates_to_remove.append(key)\n",
    "                        else:\n",
    "#                             print(' -> Keep')\n",
    "                            pass\n",
    "                else:#z-score\n",
    "                    for key,value in set_of_clusters.items():\n",
    "                        z = (value-mean)/std\n",
    "#                         print('Candidate-'+key+' Z-score:',z,end='')\n",
    "                        if ref == 'rows' and z < cc_z_threshold:\n",
    "                            candidates_to_remove.append(key)\n",
    "#                             print(' -> Remove')\n",
    "                        elif ref == 'cost' and z > -cc_z_threshold:\n",
    "                            candidates_to_remove.append(key)\n",
    "#                             print(' -> Remove')\n",
    "                        else:\n",
    "#                             print(' -> Keep')\n",
    "                            pass\n",
    "\n",
    "            except:#double ref combine: rows AND cost\n",
    "                if cc_type_analysis == 'mean':\n",
    "                    for key,value in set_of_clusters.items():\n",
    "#                         print('Candidate-'+key+' Mean(rows):',mean_rows,' Mean(cost):',mean_cost,end='')\n",
    "                        if (set_of_clusters[key]['rows'] < mean_rows) and (set_of_clusters[key]['cost'] > mean_cost):\n",
    "#                             print(' -> Remove')\n",
    "                            candidates_to_remove.append(key)\n",
    "                        else:\n",
    "#                             print(' -> Keep')\n",
    "                            pass\n",
    "\n",
    "                else:#z-score\n",
    "                    for key,value in set_of_clusters.items():\n",
    "                        z_rows = (set_of_clusters[key]['rows']-mean_rows)/std_rows\n",
    "                        z_cost = (set_of_clusters[key]['cost']-mean_cost)/std_cost\n",
    "#                         print('Candidate-'+key+' Z-score(row):',z_rows,' Z-score(cost):',z_cost,end='')\n",
    "                        if (z_rows < cc_z_threshold) and (z_cost > -cc_z_threshold):\n",
    "#                             print(' -> Remove')\n",
    "                            candidates_to_remove.append(key)\n",
    "                        else:\n",
    "#                             print(' -> Keep')\n",
    "                            pass\n",
    "                        \n",
    "#             print(\"Remove candidates: \",candidates_to_remove)\n",
    "#             print(\"Number of candidates to remove: \",len(candidates_to_remove))\n",
    "            for candidate in candidates_to_remove:#at this point, value_ref is the set of candidates\n",
    "                del value_ref[candidate]\n",
    "\n",
    "        else: # just pass step. Stores the candidate co-clusters and analyse them with sample analysis if desirable\n",
    "            return True               \n",
    "                \n",
    "    else:# pass step to reach a minimum number of elements to perform computation\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 999,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_boxplot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 998,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_boxplot():\n",
    "    array = np.random.uniform(size=20)\n",
    "    ax = sns.boxplot(data = array)\n",
    "    ax = sns.swarmplot(data=array, color=\".25\")\n",
    "    plt.xticks([0],['SDF'])\n",
    "    plt.xlabel(\"Reference\")\n",
    "#     plt.show(ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = {}\n",
    "f['1'] = {}\n",
    "f['1'].update({'cc_objs':[]})\n",
    "f['1'].update({'cc_atts':[]})\n",
    "f['1'].update({'cc_elements':[]})\n",
    "print(f)\n",
    "print(f['1']['cc_objs'])\n",
    "f.update({'2':{}})\n",
    "print(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def update_queue_s(cocluster_sequence_str, tested_sequence_str, s_poi_freq_queue_list, poi_node_queue):\n",
    "def update_queue_s(cocluster_sequence_str, s_poi_freq_queue_list, poi_node_queue):\n",
    "    '''\n",
    "    Method to update the nodes in queue s. It decrements the value of a given node in s.\n",
    "    The input are:\n",
    "        1. The current string sequence of a cocluster;\n",
    "        2. The tested string sequence to improve a cocluster;\n",
    "        3. The queue s;\n",
    "        4. A single node of queue s.\n",
    "    '''\n",
    "    # update list s when the first sequence is identified\n",
    "#     if cocluster_sequence_str == '':\n",
    "    tmp_split = cocluster_sequence_str.split('-')\n",
    "    if len(tmp_split) == 2:\n",
    "#         tmp_split = tested_sequence_str.split('-')\n",
    "        s_poi_freq_queue_list.append(poi_node_queue)\n",
    "        for attribute in tmp_split:\n",
    "            for node_s in s_poi_freq_queue_list:\n",
    "                if attribute == node_s[0]:\n",
    "                    node_s[1] -= 1\n",
    "                    if node_s[1] <= 0: # all occurences were used, then remove the element from the queue\n",
    "                        print('Element with 0 removed.')\n",
    "                        s_poi_freq_queue_list.remove(node_s)\n",
    "                    break\n",
    "    else: # update a single node in case a sequence is already discovered\n",
    "        poi_node_queue[1] -= 1\n",
    "        if poi_node_queue[1] <= 0: # all occurences were used, then remove the element from the queue\n",
    "            s_poi_freq_queue_list.remove(node_s)\n",
    "        else:\n",
    "            s_poi_freq_queue_list.append(poi_node_queue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_uppercase_S(cc_atts, cc_objs, S_dict):\n",
    "    '''\n",
    "    Method to update the dictonary S. It decrements the frequency of the given attributes in S.\n",
    "    S is updated regarding the frequency of an attribute times the number of objects that it appears in a\n",
    "    co-cluster.\n",
    "    E.g., Given a co-clsuter with sequence Home-Work-Home with 5 trajectories. Then, in S, Home is \n",
    "    decremented with value 10 (2*5) and Work with value 5 (1*5).\n",
    "    \n",
    "    The input are:\n",
    "        1. Co-cluster attributes;\n",
    "        2. Co-cluster objects;\n",
    "        3. The dictionary S of attributes and its frequency.\n",
    "    '''\n",
    "    tmp_dict = {}\n",
    "    for attribute in cc_atts: # groups repeation\n",
    "#         S_poi_freq_dict[attribute] -= 1\n",
    "        try:\n",
    "            tmp_dict[attribute] += 1\n",
    "        except:\n",
    "            tmp_dict.update({attribute:1})\n",
    "    for attribute, value in tmp_dict.items():\n",
    "        S_dict[attribute] -= (tmp_dict[attribute]*len(cc_objs))\n",
    "        if S_dict[attribute] <= 0:\n",
    "            S_dict.pop(attribute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a1 = ['a','b','c','d']\n",
    "a2 = [1,2,3,4]\n",
    "[str(i)+str(j) for i in a1 for j in a2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([1,1,1,0,0,0,0])\n",
    "b = np.array([1,1,3,0,0,0,0])\n",
    "c = np.outer(a,b)\n",
    "print(c)\n",
    "d = (c*0)+1\n",
    "print(d)\n",
    "print(c+d)\n",
    "e = d*4\n",
    "print(e)\n",
    "f = d-e\n",
    "print(f)\n",
    "print(sum(sum(f)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def myFunc(e):\n",
    "    return e[:][1]\n",
    "\n",
    "er = [['f',2],['h',5],['t',1]]\n",
    "print(er)\n",
    "er.sort()\n",
    "print(er)\n",
    "er.sort(reverse=True, key=myFunc)\n",
    "print(er)\n",
    "er[0][1] -= 1\n",
    "print(er)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t= [1,2,3,4,5,6,7,8]\n",
    "print(t)\n",
    "push_to_end = 3\n",
    "complete_cicle = False\n",
    "reload = True\n",
    "print(t.pop(2))\n",
    "print(t)\n",
    "t= [1,2,3,4,5,6,7,8]\n",
    "print(t)\n",
    "# while(reload and complete_cicle != True):\n",
    "#     for i in range(len(t)):\n",
    "#         if t[i] == push_to_end:\n",
    "#             tmp = t.pop(i)\n",
    "#             t.append(tmp)\n",
    "#             complete_cicle == True\n",
    "#         else:\n",
    "#             print(t[i])\n",
    "#         if push_to_end == t[i] and complete_cicle == True:\n",
    "#             reload = False\n",
    "#             break\n",
    "            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support functions for the algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(input_data):\n",
    "    '''\n",
    "    This method will assign the variables used by the algorithm.\n",
    "    \n",
    "    INPUT\n",
    "        input_data: A panda dataframe of the input data file.\n",
    "    \n",
    "    OUTPUT\n",
    "        D: A binary matrix from the input data.\n",
    "        N: A noise binary matrix with the same size of D.\n",
    "        data_dict: A dictionary to store D as a vertical representation.\n",
    "        data_res_dict: A copy of data_dict used to sort the attributes of D and find unconvered elements.\n",
    "        \n",
    "    '''\n",
    "    \n",
    "    data_pd = input_data #txt file with sequence of check-ins (POI)\n",
    "    frequence_per_poi_dict = {} # store the frequence of a POI as \"POI\": num_of_occurrences\n",
    "    poi_at_trajs_dict_set = {}  # store a set with each index line (tid trajectory) that contains a given POI.\n",
    "                            # \"POI\": set(0,1,4,...); It is the S variable\n",
    "#     global data_res_dict\n",
    "    uncover_poi_dict = {} # It is the s* variable\n",
    "#     global D # input data as a binary matrix\n",
    "#     global N # noise matrix with the same size of D\n",
    "    num_of_objects = 0\n",
    "    num_of_attributes = 0\n",
    "    map_id_to_attribute = {} # map the \n",
    "    map_attribute_to_id = {} # map the\n",
    "    trajectory_dict = {} # it stores the trajectories with its check-ins. \"TID\": [POI1,POI2,...]\n",
    "#     max_val_att = 0 \n",
    "    att_id = 0 # assign an ID to each attribute\n",
    "    \n",
    "    # read each line\n",
    "    for index, row in data_pd.iterrows():\n",
    "        num_of_objects+=1\n",
    "        object_data = row[0].split(\" \")\n",
    "#         trajectory_dict[str(index)] = {}\n",
    "#         trajectory_dict[str(index)] = object_data\n",
    "        trajectory_dict[str(index)] = []\n",
    "        \n",
    "#         for attribute in object_data: # we look at each item of the given transaction\n",
    "        for att_j in range(len(object_data)): # we look at each item of the given transaction\n",
    "            attribute = object_data[att_j]\n",
    "            \n",
    "            if attribute != \"\":\n",
    "#                 if int(attribute) > max_val_att:\n",
    "#                     max_val_att = int(attribute)\n",
    "#                 if attribute not in map_unique_attributes_dataset:\n",
    "#                 if attribute not in map_attribute_to_id.keys():\n",
    "    \n",
    "                if attribute not in map_attribute_to_id: # mapping\n",
    "#                     unique_attributes_dataset.append(attribute)\n",
    "                    map_attribute_to_id[attribute] = str(att_id)\n",
    "                    map_id_to_attribute[str(att_id)] = attribute\n",
    "                    att_id += 1\n",
    "                \n",
    "                # substitute the check-in by its ID\n",
    "                trajectory_dict[str(index)].append(map_attribute_to_id[attribute])\n",
    "                \n",
    "                # store the indeces containing a given POI\n",
    "                if map_attribute_to_id[attribute] in poi_at_trajs_dict_set:\n",
    "#                     data_dict[map_attribute_to_id[attribute]].append(index)\n",
    "                    poi_at_trajs_dict_set[map_attribute_to_id[attribute]].add(str(index))\n",
    "                else:\n",
    "#                     data_dict[map_attribute_to_id[attribute]] = [index]\n",
    "                    poi_at_trajs_dict_set[map_attribute_to_id[attribute]] = set([str(index)])\n",
    "                \n",
    "                # store the frequence for each POI\n",
    "                if map_attribute_to_id[attribute] in frequence_per_poi_dict:\n",
    "                    current_value = frequence_per_poi_dict[map_attribute_to_id[attribute]]\n",
    "                    frequence_per_poi_dict[map_attribute_to_id[attribute]] = current_value + 1\n",
    "                else:\n",
    "                    frequence_per_poi_dict[map_attribute_to_id[attribute]] = 1\n",
    "            \n",
    "                    \n",
    "    uncover_poi_dict = poi_at_trajs_dict_set.copy()\n",
    "#     num_of_attributes = len(data_dict)\n",
    "#     num_of_attributes = max_val_att+1\n",
    "#     num_of_attributes = len(map_attribute_to_id)\n",
    "    print(\"######################################\")\n",
    "    print(\"Number of trajectories: \"+str(index+1))\n",
    "    print(\"Number of unique check-ins: \"+str(len(map_attribute_to_id)))\n",
    "    print(\"########################################\")\n",
    "    if VERBOSE:\n",
    "        print(\"Map_attribute_to_id:\"+str(map_attribute_to_id))\n",
    "        print(\"\")\n",
    "        print(\"Map_id_to_attribute:\"+str(map_id_to_attribute))\n",
    "        print(\"\")\n",
    "        print(\"Frequence_per_poi:\"+str(frequence_per_poi_dict))\n",
    "        print(\"\")\n",
    "        print(\"Trajectories: \"+str(trajectory_dict))\n",
    "        print(\"\")\n",
    "        print(\"POI occurring at trajectories: \"+str(poi_at_trajs_dict_set))\n",
    "        print(\"Get data is DONE!\")\n",
    "        \n",
    "    \n",
    "#     D = np.zeros((num_of_objects,num_of_attributes),dtype=int)\n",
    "#     for key, values in poi_at_trajs_dict.items():\n",
    "#         print(\"key:\"+str(key)+\" Values:\"+str(values))\n",
    "#         for line in values:\n",
    "# #             D[line][int(key)] = 1\n",
    "# #             D[line][map_unique_attributes_dataset[key]] = 1\n",
    "# #             print(line,key)\n",
    "# #             print(type(line),type(key))\n",
    "#             D[line][int(key)] = 1\n",
    "#     N = np.zeros((num_of_objects,num_of_attributes),dtype=int)\n",
    "    \n",
    "#     return D, N, poi_at_trajs_dict, data_res_dict, map_id_to_attribute\n",
    "    return map_id_to_attribute, frequence_per_poi_dict, poi_at_trajs_dict_set, trajectory_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 943,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Tid  Traj_length  User\n",
      "1    1           81   185\n",
      "3    3           77   185\n",
      "6    6           71   185\n",
      "{185: 3}\n",
      "185\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('data/real_application/foursquare_NY/fs_ny_top_users_10.csv', sep=\";\")\n",
    "df_tmp = create_df_map_traj_user(df)\n",
    "print(df_tmp[df_tmp['Tid'].isin([1,3,6])])\n",
    "e = df_tmp[df_tmp['Tid'].isin([1,3,6])]['User'].value_counts()\n",
    "print(e.to_dict())\n",
    "print(df_tmp[df_tmp['Tid']==1]['User'].values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_df_map_traj_user(df):\n",
    "def create_df_map_traj_user(df=pd.DataFrame):\n",
    "    '''\n",
    "    Method to support the calculation of the quality result.\n",
    "    It returns a dataframe with the users and their trajectories with its respective length.\n",
    "    '''\n",
    "    try:\n",
    "        #     df = pd.read_csv('data/real_application/foursquare_NY/fs_ny_top_users_10.csv', sep=\";\")\n",
    "        df_map_traj_user = pd.DataFrame(columns=['Tid','Traj_length','User'])\n",
    "        tids = []\n",
    "        user = ''\n",
    "        traj_length = 0\n",
    "\n",
    "        sequence = []\n",
    "        past_tid = None\n",
    "        curr_tid = None\n",
    "        num_of_seqs = 0\n",
    "        map_element_id = 0\n",
    "        unique_elements = {}\n",
    "        map_id_to_element = {}\n",
    "\n",
    "        for i in range(len(df)):\n",
    "            curr_tid = df.loc[i,\"new_tid\"]\n",
    "            if curr_tid not in tids:\n",
    "                tids.append(int(curr_tid))\n",
    "                user = int(df.loc[i,\"label\"])\n",
    "                traj_length = len(df[df['new_tid'] == curr_tid])\n",
    "                # append rows to an empty DataFrame\n",
    "                df_map_traj_user = df_map_traj_user.append({'Tid' : curr_tid, 'Traj_length' : traj_length, 'User' : user},ignore_index = True)\n",
    "        df_map_traj_user['Tid'] = df_map_traj_user['Tid'].astype(int, errors='ignore')\n",
    "        df_map_traj_user['Traj_length'] = df_map_traj_user['Traj_length'].astype(int, errors='ignore')\n",
    "        df_map_traj_user['User'] = df_map_traj_user['User'].astype(int, errors='ignore')\n",
    "\n",
    "    #     print(df_map_traj_user.shape)\n",
    "    #     print(df_map_traj_user.head())\n",
    "    #     print('Todo DataFrame (traj_length):',' mean=',df_map_traj_user['Traj_length'].mean(),\n",
    "    #           ' std=',df_map_traj_user['Traj_length'].std())\n",
    "    #     u_185 = df_map_traj_user[df_map_traj_user['User']==185]\n",
    "    #     print(u_185)\n",
    "    #     print('User 185:',' mean=',u_185['Traj_length'].mean(),' std=',u_185['Traj_length'].std())\n",
    "    #     df_map_traj_user.groupby(['label']).nunique()['new_tid'].mean()\n",
    "        r = (df_map_traj_user.groupby(['User'])['Traj_length']\n",
    "             .agg([np.count_nonzero,np.mean,np.std])\n",
    "             .rename(columns={'count_nonzero':'Count_trajs',\n",
    "                              'mean':'AVG_traj_length',\n",
    "                              'std':'STD_traj_length'}))\n",
    "    #     print('Número médio de trajs por usuário = {:.2f} com DP = {:.2f}'.format(r['Count_trajs'].mean(),\n",
    "    #                                                                        r['Count_trajs'].std()))\n",
    "    #     print('Tamanho médio das trajs por usuário = {:.2f} com DP médio = {:.2f}'.format(r['AVG_traj_length'].mean(),\n",
    "    #                                                                        r['STD_traj_length'].mean()))\n",
    "        return df_map_traj_user\n",
    "    except:\n",
    "        raise('Please, check the input data format.')\n",
    "        return None\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "my_fila = deque([{'hotel':4},{'casa':7},{'trabalho':9},{'padaria':2}])\n",
    "my_fila2 = deque()\n",
    "my_fila2.append({'hotel':4})\n",
    "my_fila2.append({'padaria':2})\n",
    "print('Fila 1: ',type(my_fila))\n",
    "print('Fila 1: ',my_fila)\n",
    "print('Fila 2: ',my_fila2)\n",
    "print(my_fila)\n",
    "my_fila.append({'festa':1})\n",
    "print(my_fila)\n",
    "my_fila.appendleft({'aeroporto':1})\n",
    "print(my_fila)\n",
    "print(my_fila[1])\n",
    "my_fila.insert(1,{'padaria':3})\n",
    "print(my_fila)\n",
    "print(len(my_fila))\n",
    "print(my_fila.pop())\n",
    "print(type(my_fila[2]))\n",
    "r = my_fila[4]\n",
    "print(r)\n",
    "print(list(r.keys())[0])\n",
    "print(my_fila.index(my_fila[4],2,len(my_fila)))\n",
    "print('Fila 1: ',my_fila)\n",
    "print('Fila 2: ',my_fila2)\n",
    "my_fila.pop()#delete from the right end\n",
    "my_fila.popleft()#delete from the left end\n",
    "print('Fila 1: ',my_fila)\n",
    "f = my_fila.popleft()\n",
    "print('Fila 1: ',my_fila)\n",
    "print('Element poped: ',f)\n",
    "my_fila.append(f)\n",
    "print(my_fila)\n",
    "# my_fila.popleft()\n",
    "# print(my_fila)\n",
    "# my_fila.popleft()\n",
    "# print(my_fila)\n",
    "# my_fila.popleft()\n",
    "# print(my_fila)\n",
    "# my_fila.popleft()\n",
    "# print(my_fila)\n",
    "# print(my_fila)\n",
    "# while my_fila:\n",
    "#     fx = my_fila.popleft()\n",
    "#     print(fx)\n",
    "#     print(my_fila)\n",
    "# for p in my_fila:\n",
    "#     print(p)\n",
    "print(num_elements_to_test('log2',len(my_fila)))\n",
    "print(num_elements_to_test('log10',len(my_fila)))\n",
    "print(num_elements_to_test('length',len(my_fila)))\n",
    "print(my_fila)\n",
    "my_fila.remove({'casa':7})\n",
    "print(my_fila)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_elements_to_test(option,number):\n",
    "    \n",
    "    if option == 'log2':\n",
    "        return int(round(np.log2(number)))\n",
    "    elif option == 'log10':\n",
    "        return int(round(np.log10(number)))\n",
    "    elif option == 'length':# Attention! The number for length must to be at most length of structure. e.g. array, dic.\n",
    "        return int(round(number))\n",
    "    else:\n",
    "        return print('Choose a valid option!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Too noisy (line,col)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def not_too_noisy(count_presence, C, e_obj, e_att, att_data_dict, E, dimension):\n",
    "    num_of_atts = len(C[0])\n",
    "    num_of_objs = len(C[1])\n",
    "    if dimension == \"obj\":\n",
    "        # obj must be present in at least (1-e_obj).||C_a||\n",
    "        return count_presence >= ((1-e_obj) * num_of_atts) # return true if the obj is not too noisy\n",
    "    else:\n",
    "        # col must be present in at least (1-e_tt).||C_o||\n",
    "        return count_presence >= ((1-e_att) * num_of_objs) # return true if the att is not too noisy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cost function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost_function(numOfObj, numOfAtt, cov=0, noise=0):\n",
    "    if VERBOSE:\n",
    "        print('Num. objs: {0:2d}, Num. att: {1:2d}, Num. covered: {2:2d}, Num. noise: {3:2d}'.format(numOfObj,numOfAtt,cov,noise))\n",
    "#     return ((numOfObj+numOfAtt) - (numOfObj*numOfAtt)) + cov + (2*noise)\n",
    "    return ((numOfObj+numOfAtt) - (numOfObj*numOfAtt)) + cov + noise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sort attributes in dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dict_freq = {'10':10,'45':45,'65':9,'87':2,'0':100}\n",
    "sorted_attributes = sort_attributes(test_dict_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_attributes(data_res):\n",
    "    \n",
    "    try:\n",
    "        ##usar este for caso o value seja uma lista\n",
    "        freq_res_dict = {}\n",
    "        for key,value in data_res.items():\n",
    "            freq_res_dict[key] = len(value)\n",
    "\n",
    "        # Create a list of tuples sorted by index 1 i.e. value field     \n",
    "        listofTuples = sorted(freq_res_dict.items() , reverse=True, key=lambda x: x[1])# usar se value for lista\n",
    "        # Iterate over the sorted sequence\n",
    "        # for elem in listofTuples :\n",
    "        #     print(elem[0] , \" ::\" , elem[1] )\n",
    "    #     print(listofTuples)\n",
    "        sorted_attributes = [elem[0] for elem in listofTuples]\n",
    "    except:\n",
    "        ## este é usado caso value seja um número\n",
    "        sorted_attributes = {k: v for k, v in sorted(data_res.items(), reverse=True, key=lambda item: item[1])}\n",
    "    \n",
    "#     if VERBOSE:\n",
    "#         print(\"Sorted att: \",sorted_attributes)\n",
    "    return sorted_attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update residual dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_residual_dataset(res_data, attributes_cocluster, objects_cocluster):\n",
    "    for key, value in res_data.items():\n",
    "        if key in attributes_cocluster:\n",
    "            diff_objs = set(res_data[key]).difference(set(objects_cocluster))\n",
    "            res_data[key] = list(diff_objs)\n",
    "    return res_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save results - check path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_path(path_method):\n",
    "    current_dir = os.getcwd()\n",
    "    print(current_dir)\n",
    "    res = os.path.exists(path_method)\n",
    "    # clean the folder to save new data\n",
    "    if res:\n",
    "        #check if it is empty\n",
    "        dir_empty = os.listdir(path_method)\n",
    "        if len(dir_empty) != 0:\n",
    "    #         shutil.rmtree(\"OutputAnalysis/kmeans/\")\n",
    "            rm = !rm -r --preserve-root './OutputAnalysis/ococlus/'*\n",
    "            if not rm:\n",
    "                print(\"OCoClus' folder was cleaned.\")\n",
    "    #             os.chdir(path_method)\n",
    "            else:\n",
    "                print(\"sad\")\n",
    "                print(rm)\n",
    "        else:\n",
    "    #         print(\"Empty!\")\n",
    "            pass\n",
    "    #         os.chdir(path_method)\n",
    "    else: # nothing exist so create it\n",
    "        # trying to insert to flase directory \n",
    "        try: \n",
    "    #         os.chdir(fd) \n",
    "            os.mkdir(path_method)\n",
    "            print(\"The path was created: \"+path_method)\n",
    "\n",
    "        # Caching the exception     \n",
    "        except: \n",
    "            print(\"Something wrong with specified directory. Exception- \", sys.exc_info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save clustering result into a txt file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def writeFileOutput(cols, rows, dataset, method='OCoClus', fileName='OCoClusResult'):\n",
    "def writeFileOutput(co_clusters, dataset, method='OCoClus', fileName='OCoClusResult'):\n",
    "    text = \"\"\n",
    "#    for c in range(len(data.rows_)):\n",
    "#        res = [i for i, val in enumerate(data.columns_[c]) if val]\n",
    "#        for j in res:\n",
    "#            text += str(j)+\" \"\n",
    "\n",
    "#        res = [i for i, val in enumerate(data.rows_[c]) if val]\n",
    "#        text += \"[\"\n",
    "#        for j in res:\n",
    "#            text += str(j)+\" \"\n",
    "#        text += \"]\\n\"\n",
    "    \n",
    "    num_of_clusters = len(co_clusters)\n",
    "    \n",
    "#     for c in range(len(cols)):\n",
    "    for c in range(num_of_clusters):\n",
    "#         for i in cols[c]:\n",
    "        for i in co_clusters[c][0]: # get the attributes in cluster c\n",
    "            text += str(i)+\" \"\n",
    "        \n",
    "        text += \"(\"+str(len(co_clusters[c][1]))+\") [\" # get the number of objects in clusters c\n",
    "        for j in range(len(co_clusters[c][1])): # save in the file each obj\n",
    "            if j+1 != len(co_clusters[c][1]):\n",
    "                text += str(co_clusters[c][1][j])+\" \"\n",
    "            else:\n",
    "                text += str(co_clusters[c][1][j])\n",
    "        text += \"]\\n\"\n",
    "    \n",
    "    #print(text)\n",
    "    if method == 'Dhillon':\n",
    "        f = open('./datasets/outputs/'+fileName+'.txt', 'w+')#saving at dataset folder\n",
    "        f.write(text)\n",
    "        f.close()\n",
    "        print(\"Output file saved in: \"+\"./datasets/outputs/\"+fileName+\".txt\")\n",
    "    elif method == 'Kluger':\n",
    "        f = open('./datasets/outputs/'+fileName+'.txt', 'w+')#saving at dataset folder\n",
    "        f.write(text)\n",
    "        f.close()\n",
    "        print(\"Output file saved in: \"+\"./datasets/outputs/\"+fileName+\".txt\")\n",
    "    elif method == 'OCoClus':\n",
    "        f = open('./OutputAnalysis/ococlus/'+dataset+'/'+fileName+'.txt', 'w+')#saving at dataset folder\n",
    "        f.write(text)\n",
    "        f.close()\n",
    "        print(\"Output file saved in: \"+\"./OutputAnalysis/ococlus/\"+dataset+\"/\"+fileName+\".txt\")\n",
    "    else:\n",
    "        print(\"The output file was not generated. Method option not recognized.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation measure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reconstruction error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Rec_error(data,clusters):\n",
    "    '''\n",
    "    This evaluation measure is computed during the algorithm life time.\n",
    "    '''\n",
    "    reconstructed_ococlus = np.zeros(data.shape,dtype=int)\n",
    "    for nc in range(len(clusters)):\n",
    "        for i in clusters[nc][1]: # object cluster\n",
    "            for j in clusters[nc][0]: # attribute cluster\n",
    "                reconstructed_ococlus[int(i)][int(j)] = 1\n",
    "    print(\"Reconstruction error: \",np.sum(np.bitwise_xor(data,reconstructed_ococlus)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Omega format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_clustering_output_omega(co_clusters):\n",
    "# def build_clustering_output_omega(rowClusters,columnClusters):\n",
    "    '''\n",
    "    Build the clustering output format to use in the omega index evaluation from Remy Cazabet version.\n",
    "    It is optional and we just present this version as a complementary information. If you are interested,\n",
    "    check it out on his team work group at https://github.com/isaranto/omega_index.\n",
    "    '''\n",
    "    \n",
    "    num_of_clusters = len(co_clusters)    \n",
    "    clustering = {}\n",
    "    \n",
    "    for nc in range(num_of_clusters):\n",
    "        rowCluster = co_clusters[nc][1]\n",
    "        columnCluster = co_clusters[nc][0]\n",
    "        clustering[\"c\"+str(nc)] = []\n",
    "        \n",
    "        for i in rowCluster:\n",
    "            for j in columnCluster:\n",
    "                clustering[\"c\"+str(nc)].append((\"01\"+str(i)+\"02\"+str(j)))\n",
    "        \n",
    "    return clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### eXascale Infolab \n",
    "We used the xmeasure and OvpNMI project that pushished evaluation measures for overlapping task. We can check it on https://github.com/eXascaleInfolab/xmeasures or https://exascale.info/. Look their project on github to know how to use it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xmeasures_format(dict_gt):\n",
    "    '''\n",
    "    This function build the xmeasure format to use it on their evaluation measure.\n",
    "    '''\n",
    "    newData = []\n",
    "    for i in range(len(dict_gt)):\n",
    "#         print(dict_gt['c'+str(i)])\n",
    "        stringLine = dict_gt['c'+str(i)][0]\n",
    "        for j in range(1,len(dict_gt['c'+str(i)])):\n",
    "#             stringLine = stringLine+\" \"+dict_gt['c'+str(i)][j]\n",
    "            stringLine += \" \"+dict_gt['c'+str(i)][j]\n",
    "        newData.append(stringLine)\n",
    "    \n",
    "    return newData"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
